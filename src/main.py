"""
Whisper è½‰éŒ„æœå‹™ - æ–°æ‡‰ç”¨å…¥å£
æ¡ç”¨æ¸…æ™°çš„ä¸‰å±¤æ¶æ§‹è¨­è¨ˆ
"""

import os
import asyncio
import signal
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timezone, timedelta

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from faster_whisper import WhisperModel
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è³‡æ–™åº«å’Œ Repositories
from src.database.mongodb import MongoDB
from src.database.repositories.task_repo import TaskRepository
from src.database.repositories.tag_repo import TagRepository
from src.database.repositories.audit_log_repo import AuditLogRepository

# Routers
from src.routers import auth as auth_router
from src.routers import oauth as oauth_router
from src.routers import tasks as tasks_router
from src.routers import transcriptions as transcriptions_router
from src.routers import tags as tags_router
from src.routers import audio as audio_router
from src.routers import summaries as summaries_router
from src.routers import admin as admin_router

# Services
from src.services.utils.diarization_processor import DiarizationProcessor

# Utils
from src.utils.audit_logger import init_audit_logger

# å…±äº«ç‹€æ…‹
from src.utils.shared_state import (
    transcription_tasks,
    task_cancelled,
    task_temp_dirs,
    task_diarization_processes,
    tasks_lock
)

# è¨­å®š
DEFAULT_MODEL = "medium"
# OUTPUT_DIR å·²ç§»é™¤ - æ–‡å­—æª”å’Œ segments ç¾åœ¨å­˜å„²åœ¨ MongoDB ä¸­

# æ™‚å€è¨­å®š (UTC+8 å°åŒ—æ™‚é–“)
TZ_UTC8 = timezone(timedelta(hours=8))

# å…¨åŸŸæœå‹™å¯¦ä¾‹
whisper_model = None
current_model_name = None
diarization_pipeline = None
task_repo = None
tag_repo = None
audit_log_repo = None
main_loop = None
executor = ThreadPoolExecutor(max_workers=2)  # é™ä½ä¸¦ç™¼æ•¸é¿å…è¨˜æ†¶é«”çˆ†ç‚¸

# æª¢æŸ¥ Diarization æ˜¯å¦å¯ç”¨
try:
    from pyannote.audio import Pipeline
    DIARIZATION_AVAILABLE = True
except ImportError:
    DIARIZATION_AVAILABLE = False
    print("âš ï¸  pyannote.audio æœªå®‰è£ï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")


# ========== å‰µå»º FastAPI æ‡‰ç”¨ ==========

app = FastAPI(
    title="Whisper è½‰éŒ„æœå‹™",
    description="åŸºæ–¼ä¸‰å±¤æ¶æ§‹çš„éŸ³æª”è½‰éŒ„æœå‹™",
    version="3.0.0"
)

# CORS ä¸­é–“ä»¶
cors_origins_str = os.getenv("CORS_ORIGINS", "*")
cors_origins = [origin.strip() for origin in cors_origins_str.split(",")] if cors_origins_str != "*" else ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# ========== è¨»å†Šæ‰€æœ‰è·¯ç”± ==========

app.include_router(auth_router.router)
app.include_router(oauth_router.router)
app.include_router(tasks_router.router)
app.include_router(transcriptions_router.router)
app.include_router(tags_router.router)
app.include_router(audio_router.router)
app.include_router(summaries_router.router)
app.include_router(admin_router.router)


# ========== é€²ç¨‹æ¸…ç†å·¥å…·å‡½æ•¸ ==========

def cleanup_worker_processes():
    """æ¸…ç†æ‰€æœ‰ ProcessPoolExecutor worker é€²ç¨‹"""
    try:
        result = subprocess.run(
            ["pgrep", "-f", "multiprocessing.spawn"],
            capture_output=True,
            text=True
        )
        if result.stdout.strip():
            pids = result.stdout.strip().split('\n')
            print(f"ğŸ§¹ æ¸…ç† {len(pids)} å€‹ worker é€²ç¨‹...")
            subprocess.run(["pkill", "-9", "-f", "multiprocessing.spawn"], check=False)
            subprocess.run(["pkill", "-9", "-f", "multiprocessing.resource_tracker"], check=False)
            return len(pids)
        return 0
    except Exception as e:
        print(f"âš ï¸  æ¸…ç† worker é€²ç¨‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 0


def signal_handler(signum, frame):
    """è™•ç†çµ‚æ­¢ä¿¡è™Ÿï¼Œç¢ºä¿æ¸…ç†æ‰€æœ‰è³‡æº"""
    print(f"\nâš ï¸  æ”¶åˆ°çµ‚æ­¢ä¿¡è™Ÿ ({signal.Signals(signum).name})ï¼Œæ­£åœ¨æ¸…ç†...")
    cleanup_worker_processes()
    print(f"âœ… æ¸…ç†å®Œæˆï¼Œé€€å‡ºç¨‹åº")
    exit(0)


# è¨»å†Šä¿¡è™Ÿè™•ç†å™¨
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)


# ========== å•Ÿå‹•èˆ‡é—œé–‰äº‹ä»¶ ==========

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚çš„åˆå§‹åŒ–"""
    global whisper_model, current_model_name, task_repo, tag_repo, audit_log_repo, main_loop, diarization_pipeline

    print("ğŸš€ å•Ÿå‹• Whisper è½‰éŒ„æœå‹™ v3.0.0", flush=True)
    print("=" * 50, flush=True)

    # æ¸…ç†æ®˜ç•™çš„ ProcessPoolExecutor worker é€²ç¨‹
    print("ğŸ§¹ æ¸…ç†æ®˜ç•™çš„ worker é€²ç¨‹...", flush=True)
    try:
        cleaned = cleanup_worker_processes()
        if cleaned > 0:
            print(f"   âœ… å·²æ¸…ç† {cleaned} å€‹æ®˜ç•™é€²ç¨‹", flush=True)
        else:
            print("   âœ… æ²’æœ‰ç™¼ç¾æ®˜ç•™çš„ worker é€²ç¨‹", flush=True)
    except Exception as e:
        print(f"   âš ï¸  æ¸…ç†é€²ç¨‹æ™‚å‡ºéŒ¯: {e}", flush=True)

    # ç²å–ä¸»äº‹ä»¶å¾ªç’°
    print("ğŸ“¡ ç²å–äº‹ä»¶å¾ªç’°...", flush=True)
    main_loop = asyncio.get_running_loop()
    print("âœ… äº‹ä»¶å¾ªç’°å·²å°±ç·’", flush=True)

    # 1. é€£æ¥ MongoDB
    mongodb_url = os.getenv('MONGODB_URL', 'mongodb://localhost:27017')
    mongodb_db = os.getenv('MONGODB_DB_NAME', 'whisper_transcriber')
    print(f"ğŸ”Œ æ­£åœ¨é€£æ¥ MongoDB...", flush=True)
    print(f"   URL: {mongodb_url}", flush=True)
    print(f"   Database: {mongodb_db}", flush=True)
    try:
        await asyncio.wait_for(MongoDB.connect(), timeout=10.0)
        print(f"âœ… å·²é€£æ¥åˆ° MongoDB: {mongodb_db}", flush=True)
    except asyncio.TimeoutError:
        print(f"âŒ MongoDB é€£æ¥è¶…æ™‚ï¼ˆ10ç§’ï¼‰", flush=True)
        print(f"   è«‹ç¢ºä¿ MongoDB æ­£åœ¨é‹è¡Œï¼šdocker ps | grep mongo", flush=True)
        print(f"   URL: {mongodb_url}", flush=True)
        raise
    except Exception as e:
        print(f"âŒ MongoDB é€£æ¥å¤±æ•—: {e}", flush=True)
        print(f"   è«‹ç¢ºä¿ MongoDB æ­£åœ¨é‹è¡Œä¸¦æª¢æŸ¥ .env é…ç½®", flush=True)
        print(f"   URL: {mongodb_url}", flush=True)
        raise

    # 2. åˆå§‹åŒ– Repositories
    print(f"ğŸ“‚ æ­£åœ¨åˆå§‹åŒ– Repositories...")
    db = MongoDB.get_db()
    task_repo = TaskRepository(db)
    tag_repo = TagRepository(db)
    audit_log_repo = AuditLogRepository(db)

    # å»ºç«‹ç´¢å¼•
    try:
        await task_repo.create_indexes()
        await audit_log_repo.create_indexes()
        # å»ºç«‹ Summaries ç´¢å¼•
        from src.database.repositories.summary_repo import SummaryRepository
        summary_repo = SummaryRepository(db)
        await summary_repo.create_indexes()
        # å»ºç«‹ RateLimit ç´¢å¼•ï¼ˆç”¨æ–¼å¿˜è¨˜å¯†ç¢¼ç­‰åŠŸèƒ½çš„é€Ÿç‡é™åˆ¶ï¼‰
        from src.database.repositories.rate_limit_repo import RateLimitRepository
        rate_limit_repo = RateLimitRepository(db)
        await rate_limit_repo.ensure_indexes()
        print(f"âœ… è³‡æ–™åº«ç´¢å¼•å»ºç«‹å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  ç´¢å¼•å»ºç«‹å¤±æ•—: {e}")

    # çµ±è¨ˆä»»å‹™æ•¸é‡
    task_count = await db.tasks.count_documents({})
    print(f"âœ… è³‡æ–™åº«å·²å°±ç·’ï¼ˆå…± {task_count} å€‹ä»»å‹™ï¼‰")

    # åˆå§‹åŒ– AuditLogger
    print(f"ğŸ“ æ­£åœ¨åˆå§‹åŒ– AuditLogger...")
    init_audit_logger(audit_log_repo)
    print(f"âœ… AuditLogger åˆå§‹åŒ–å®Œæˆ")

    # 3. åˆå§‹åŒ– TaskServiceï¼ˆä½¿ç”¨å…±äº«çš„å…¨åŸŸå­—å…¸ï¼‰
    print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TaskService...")
    task_service = tasks_router.init_task_service(
        db,
        memory_tasks=transcription_tasks,
        cancelled_tasks=task_cancelled,
        temp_dirs=task_temp_dirs,
        diarization_processes=task_diarization_processes,
        lock=tasks_lock
    )
    print(f"âœ… TaskService åˆå§‹åŒ–å®Œæˆ")

    # 4. æ¸…ç†ç•°å¸¸ä¸­æ–·çš„ä»»å‹™
    print(f"ğŸ§¹ æ¸…ç†ç•°å¸¸ä¸­æ–·çš„ä»»å‹™...")
    await task_service.cleanup_orphaned_tasks()

    # 5. å•Ÿå‹•å®šæœŸè¨˜æ†¶é«”æ¸…ç†
    asyncio.create_task(task_service.periodic_memory_cleanup())

    # 5.1. å•Ÿå‹•å®šæœŸå­¤ç«‹é€²ç¨‹æ¸…ç†
    asyncio.create_task(task_service.periodic_orphaned_process_cleanup())

    # 5.5. å•Ÿå‹•ä»»å‹™éšŠåˆ—è™•ç†å™¨ï¼ˆåœ¨ TranscriptionService åˆå§‹åŒ–å¾Œï¼‰
    # æ³¨æ„ï¼šé€™è£¡æš«æ™‚å…ˆå‰µå»ºä»»å‹™ï¼Œç¨å¾Œåœ¨ TranscriptionService åˆå§‹åŒ–å¾Œæœƒå¯¦éš›å•Ÿå‹•
    queue_processor_task = None

    # 6. è¼‰å…¥ Whisper æ¨¡å‹
    print(f"ğŸ™ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ï¼š{DEFAULT_MODEL}...")
    print(f"ğŸ”§ é…ç½®ï¼šdevice=auto, compute_type=int8")
    current_model_name = DEFAULT_MODEL
    whisper_model = WhisperModel(
        current_model_name,
        device="auto",
        compute_type="int8",
        cpu_threads=2,  # å„ªåŒ–ï¼šé…åˆ ProcessPoolExecutorï¼Œé™ä½å–®é€²ç¨‹ä¸¦è¡Œåº¦
        num_workers=1   # å„ªåŒ–ï¼šé¿å…é€²ç¨‹å…§éåº¦ä¸¦è¡Œï¼ˆå¤–éƒ¨å·²æœ‰ ProcessPoolExecutorï¼‰
    )
    print(f"âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆï¼")

    # 8. è¼‰å…¥ Diarization æ¨¡å‹ï¼ˆå¯é¸ï¼‰
    if DIARIZATION_AVAILABLE:
        hf_token = os.getenv("HF_TOKEN")
        if hf_token:
            diarization_pipeline = DiarizationProcessor.load_pipeline(hf_token)
        else:
            print("â„¹ï¸  æœªè¨­å®š HF_TOKENï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")

    # 9. åˆå§‹åŒ– TranscriptionService
    print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TranscriptionService...")
    transcription_service = transcriptions_router.init_transcription_service(
        whisper_model=whisper_model,
        task_service=task_service,
        model_name=current_model_name,  # å‚³éæ¨¡å‹åç¨±ä¾› ProcessPoolExecutor ä½¿ç”¨
        diarization_pipeline=diarization_pipeline,
        executor=executor
    )
    print(f"âœ… TranscriptionService åˆå§‹åŒ–å®Œæˆ")

    # 10. å•Ÿå‹•ä»»å‹™éšŠåˆ—è™•ç†å™¨
    print(f"ğŸš€ æ­£åœ¨å•Ÿå‹•ä»»å‹™éšŠåˆ—è™•ç†å™¨...")
    asyncio.create_task(task_service.process_pending_queue(transcription_service, max_concurrent=2))
    print(f"âœ… ä»»å‹™éšŠåˆ—è™•ç†å™¨å·²å•Ÿå‹•")

    print("=" * 50)
    print(f"âœ¨ æœå‹™å·²å°±ç·’ï¼")
    print(f"ğŸ“š API æ–‡æª”ï¼šhttp://localhost:8000/docs")
    print(f"ğŸ”— å¥åº·æª¢æŸ¥ï¼šhttp://localhost:8000/health")
    print(f"ğŸ“‹ ä»»å‹™éšŠåˆ—ï¼šæœ€å¤š 2 å€‹ä¸¦ç™¼ä»»å‹™")
    print("=" * 50)


@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ™‚çš„æ¸…ç†"""
    print(f"ğŸ‘‹ æ­£åœ¨é—œé–‰æœå‹™...")

    # é—œé–‰ç·šç¨‹æ± 
    if executor:
        executor.shutdown(wait=True)
        print(f"âœ… ç·šç¨‹æ± å·²é—œé–‰")

    # æ¸…ç†æ‰€æœ‰ ProcessPoolExecutor worker é€²ç¨‹
    cleaned = cleanup_worker_processes()
    if cleaned > 0:
        print(f"âœ… å·²æ¸…ç† {cleaned} å€‹ worker é€²ç¨‹")

    # æ–·é–‹ MongoDB
    await MongoDB.close()
    print(f"âœ… MongoDB é€£æ¥å·²é—œé–‰")

    print(f"ğŸ‘‹ æœå‹™å·²é—œé–‰")


# ========== åŸºæœ¬ç«¯é» ==========

@app.get("/")
async def root():
    """æ ¹ç«¯é»"""
    return {
        "service": "Whisper è½‰éŒ„æœå‹™",
        "version": "3.0.0",
        "architecture": "ä¸‰å±¤æ¶æ§‹",
        "status": "running",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {
        "status": "healthy",
        "whisper_model": current_model_name,
        "diarization_available": diarization_pipeline is not None,
        "database": "connected" if MongoDB.get_db() is not None else "disconnected"
    }


# ========== ä¸»ç¨‹åºå…¥å£ ==========

if __name__ == "__main__":
    import uvicorn

    # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    reload = os.getenv("RELOAD", "false").lower() == "true"

    uvicorn.run(
        "src.main:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )
