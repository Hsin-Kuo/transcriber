"""
Whisper è½‰éŒ„æœå‹™ - æ–°æ‡‰ç”¨å…¥å£
æ¡ç”¨æ¸…æ™°çš„ä¸‰å±¤æ¶æ§‹è¨­è¨ˆ
"""

import os
import asyncio
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timezone, timedelta

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from faster_whisper import WhisperModel
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è³‡æ–™åº«å’Œ Repositories
from src.database.mongodb import MongoDB
from src.database.repositories.task_repo import TaskRepository
from src.database.repositories.tag_repo import TagRepository
from src.database.repositories.audit_log_repo import AuditLogRepository

# Routers
from src.routers import auth as auth_router
from src.routers import tasks as tasks_router
from src.routers import transcriptions as transcriptions_router
from src.routers import tags as tags_router
from src.routers import audio as audio_router

# Services
from src.services.utils.diarization_processor import DiarizationProcessor

# Utils
from src.utils.audit_logger import init_audit_logger

# å…±äº«ç‹€æ…‹
from src.utils.shared_state import (
    transcription_tasks,
    task_cancelled,
    task_temp_dirs,
    task_diarization_processes,
    tasks_lock
)

# è¨­å®š
DEFAULT_MODEL = "medium"
OUTPUT_DIR = Path(__file__).parent.parent / "output"
OUTPUT_DIR.mkdir(exist_ok=True)

# æ™‚å€è¨­å®š (UTC+8 å°åŒ—æ™‚é–“)
TZ_UTC8 = timezone(timedelta(hours=8))

# å…¨åŸŸæœå‹™å¯¦ä¾‹
whisper_model = None
current_model_name = None
diarization_pipeline = None
task_repo = None
tag_repo = None
audit_log_repo = None
main_loop = None
executor = ThreadPoolExecutor(max_workers=3)

# æª¢æŸ¥ Diarization æ˜¯å¦å¯ç”¨
try:
    from pyannote.audio import Pipeline
    DIARIZATION_AVAILABLE = True
except ImportError:
    DIARIZATION_AVAILABLE = False
    print("âš ï¸  pyannote.audio æœªå®‰è£ï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")


# ========== å‰µå»º FastAPI æ‡‰ç”¨ ==========

app = FastAPI(
    title="Whisper è½‰éŒ„æœå‹™",
    description="åŸºæ–¼ä¸‰å±¤æ¶æ§‹çš„éŸ³æª”è½‰éŒ„æœå‹™",
    version="3.0.0"
)

# CORS ä¸­é–“ä»¶
cors_origins_str = os.getenv("CORS_ORIGINS", "*")
cors_origins = [origin.strip() for origin in cors_origins_str.split(",")] if cors_origins_str != "*" else ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# ========== è¨»å†Šæ‰€æœ‰è·¯ç”± ==========

app.include_router(auth_router.router)
app.include_router(tasks_router.router)
app.include_router(transcriptions_router.router)
app.include_router(tags_router.router)
app.include_router(audio_router.router)


# ========== å•Ÿå‹•èˆ‡é—œé–‰äº‹ä»¶ ==========

@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚çš„åˆå§‹åŒ–"""
    global whisper_model, current_model_name, task_repo, tag_repo, audit_log_repo, main_loop, diarization_pipeline

    print("ğŸš€ å•Ÿå‹• Whisper è½‰éŒ„æœå‹™ v3.0.0")
    print("=" * 50)

    # ç²å–ä¸»äº‹ä»¶å¾ªç’°
    main_loop = asyncio.get_running_loop()

    # 1. é€£æ¥ MongoDB
    print(f"ğŸ”Œ æ­£åœ¨é€£æ¥ MongoDB...")
    try:
        await MongoDB.connect()
        print(f"âœ… å·²é€£æ¥åˆ° MongoDB: {os.getenv('MONGODB_DB_NAME', 'whisper_transcriber')}")
    except Exception as e:
        print(f"âŒ MongoDB é€£æ¥å¤±æ•—: {e}")
        print(f"   è«‹ç¢ºä¿ MongoDB æ­£åœ¨é‹è¡Œä¸¦æª¢æŸ¥ .env é…ç½®")
        raise

    # 2. åˆå§‹åŒ– Repositories
    print(f"ğŸ“‚ æ­£åœ¨åˆå§‹åŒ– Repositories...")
    db = MongoDB.get_db()
    task_repo = TaskRepository(db)
    tag_repo = TagRepository(db)
    audit_log_repo = AuditLogRepository(db)

    # å»ºç«‹ç´¢å¼•
    try:
        await task_repo.create_indexes()
        await audit_log_repo.create_indexes()
        print(f"âœ… è³‡æ–™åº«ç´¢å¼•å»ºç«‹å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  ç´¢å¼•å»ºç«‹å¤±æ•—: {e}")

    # çµ±è¨ˆä»»å‹™æ•¸é‡
    task_count = await db.tasks.count_documents({})
    print(f"âœ… è³‡æ–™åº«å·²å°±ç·’ï¼ˆå…± {task_count} å€‹ä»»å‹™ï¼‰")

    # åˆå§‹åŒ– AuditLogger
    print(f"ğŸ“ æ­£åœ¨åˆå§‹åŒ– AuditLogger...")
    init_audit_logger(audit_log_repo)
    print(f"âœ… AuditLogger åˆå§‹åŒ–å®Œæˆ")

    # 3. åˆå§‹åŒ– TaskServiceï¼ˆä½¿ç”¨å…±äº«çš„å…¨åŸŸå­—å…¸ï¼‰
    print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TaskService...")
    task_service = tasks_router.init_task_service(
        db,
        memory_tasks=transcription_tasks,
        cancelled_tasks=task_cancelled,
        temp_dirs=task_temp_dirs,
        diarization_processes=task_diarization_processes,
        lock=tasks_lock
    )
    print(f"âœ… TaskService åˆå§‹åŒ–å®Œæˆ")

    # 4. æ¸…ç†ç•°å¸¸ä¸­æ–·çš„ä»»å‹™
    print(f"ğŸ§¹ æ¸…ç†ç•°å¸¸ä¸­æ–·çš„ä»»å‹™...")
    await task_service.cleanup_orphaned_tasks()

    # 5. å•Ÿå‹•å®šæœŸè¨˜æ†¶é«”æ¸…ç†
    asyncio.create_task(task_service.periodic_memory_cleanup())

    # 6. è¼‰å…¥ Whisper æ¨¡å‹
    print(f"ğŸ™ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ï¼š{DEFAULT_MODEL}...")
    print(f"ğŸ”§ é…ç½®ï¼šdevice=auto, compute_type=int8")
    current_model_name = DEFAULT_MODEL
    whisper_model = WhisperModel(
        current_model_name,
        device="auto",
        compute_type="int8",
        cpu_threads=1,
        num_workers=4
    )
    print(f"âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆï¼")

    # 8. è¼‰å…¥ Diarization æ¨¡å‹ï¼ˆå¯é¸ï¼‰
    if DIARIZATION_AVAILABLE:
        hf_token = os.getenv("HF_TOKEN")
        if hf_token:
            diarization_pipeline = DiarizationProcessor.load_pipeline(hf_token)
        else:
            print("â„¹ï¸  æœªè¨­å®š HF_TOKENï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")

    # 9. åˆå§‹åŒ– TranscriptionService
    print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TranscriptionService...")
    transcriptions_router.init_transcription_service(
        whisper_model=whisper_model,
        task_service=task_service,
        diarization_pipeline=diarization_pipeline,
        executor=executor,
        output_dir=OUTPUT_DIR
    )
    print(f"âœ… TranscriptionService åˆå§‹åŒ–å®Œæˆ")

    print("=" * 50)
    print(f"âœ¨ æœå‹™å·²å°±ç·’ï¼")
    print(f"ğŸ“š API æ–‡æª”ï¼šhttp://localhost:8000/docs")
    print(f"ğŸ”— å¥åº·æª¢æŸ¥ï¼šhttp://localhost:8000/health")
    print("=" * 50)


@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ™‚çš„æ¸…ç†"""
    print(f"ğŸ‘‹ æ­£åœ¨é—œé–‰æœå‹™...")

    # é—œé–‰ç·šç¨‹æ± 
    if executor:
        executor.shutdown(wait=True)
        print(f"âœ… ç·šç¨‹æ± å·²é—œé–‰")

    # æ–·é–‹ MongoDB
    await MongoDB.close()
    print(f"âœ… MongoDB é€£æ¥å·²é—œé–‰")

    print(f"ğŸ‘‹ æœå‹™å·²é—œé–‰")


# ========== åŸºæœ¬ç«¯é» ==========

@app.get("/")
async def root():
    """æ ¹ç«¯é»"""
    return {
        "service": "Whisper è½‰éŒ„æœå‹™",
        "version": "3.0.0",
        "architecture": "ä¸‰å±¤æ¶æ§‹",
        "status": "running",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {
        "status": "healthy",
        "whisper_model": current_model_name,
        "diarization_available": diarization_pipeline is not None,
        "database": "connected" if MongoDB.get_db() is not None else "disconnected"
    }


@app.get("/api/admin/statistics")
async def get_admin_statistics():
    """ç²å–å¾Œå°çµ±è¨ˆè³‡æ–™ï¼ˆæš«æ™‚ç„¡éœ€èªè­‰ï¼‰"""
    try:
        db = MongoDB.get_db()

        # 1. ç¸½é«”çµ±è¨ˆ
        total_tasks = await db.tasks.count_documents({})
        completed_tasks = await db.tasks.count_documents({"status": "completed"})
        processing_tasks = await db.tasks.count_documents({"status": "processing"})
        failed_tasks = await db.tasks.count_documents({"status": "failed"})

        # 2. Token ä½¿ç”¨çµ±è¨ˆ
        token_pipeline = [
            {
                "$match": {
                    "stats.token_usage.total": {"$exists": True, "$ne": None}
                }
            },
            {
                "$group": {
                    "_id": None,
                    "total_tokens": {"$sum": "$stats.token_usage.total"},
                    "total_prompt_tokens": {"$sum": "$stats.token_usage.prompt"},
                    "total_completion_tokens": {"$sum": "$stats.token_usage.completion"},
                    "tasks_with_tokens": {"$sum": 1}
                }
            }
        ]
        token_stats_cursor = db.tasks.aggregate(token_pipeline)
        token_stats_list = await token_stats_cursor.to_list(length=1)
        token_stats = token_stats_list[0] if token_stats_list else {
            "total_tokens": 0,
            "total_prompt_tokens": 0,
            "total_completion_tokens": 0,
            "tasks_with_tokens": 0
        }

        # 3. æ¨¡å‹ä½¿ç”¨çµ±è¨ˆ
        model_pipeline = [
            {
                "$match": {
                    "stats.token_usage.model": {"$exists": True, "$ne": None}
                }
            },
            {
                "$group": {
                    "_id": "$stats.token_usage.model",
                    "count": {"$sum": 1},
                    "total_tokens": {"$sum": "$stats.token_usage.total"}
                }
            },
            {
                "$sort": {"count": -1}
            }
        ]
        model_stats_cursor = db.tasks.aggregate(model_pipeline)
        model_stats = await model_stats_cursor.to_list(length=None)

        # 4. æ¯æ—¥çµ±è¨ˆï¼ˆæœ€è¿‘ 30 å¤©ï¼‰
        thirty_days_ago = (datetime.now(TZ_UTC8) - timedelta(days=30)).strftime("%Y-%m-%d")

        daily_pipeline = [
            {
                "$match": {
                    "timestamps.created_at": {"$gte": thirty_days_ago}
                }
            },
            {
                "$group": {
                    "_id": {"$substr": ["$timestamps.created_at", 0, 10]},
                    "tasks_count": {"$sum": 1},
                    "tokens_used": {"$sum": {"$ifNull": ["$stats.token_usage.total", 0]}}
                }
            },
            {
                "$sort": {"_id": 1}
            }
        ]
        daily_stats_cursor = db.tasks.aggregate(daily_pipeline)
        daily_stats = await daily_stats_cursor.to_list(length=None)

        # 5. ä½¿ç”¨è€…çµ±è¨ˆ
        user_stats_pipeline = [
            {
                "$group": {
                    "_id": "$user.user_id",
                    "tasks_count": {"$sum": 1},
                    "tokens_used": {"$sum": {"$ifNull": ["$stats.token_usage.total", 0]}}
                }
            },
            {
                "$sort": {"tasks_count": -1}
            },
            {
                "$limit": 10
            }
        ]
        user_stats_cursor = db.tasks.aggregate(user_stats_pipeline)
        top_users = await user_stats_cursor.to_list(length=None)

        # 6. å¹³å‡è™•ç†æ™‚é–“
        avg_duration_pipeline = [
            {
                "$match": {
                    "status": "completed",
                    "stats.duration_seconds": {"$exists": True, "$ne": None}
                }
            },
            {
                "$group": {
                    "_id": None,
                    "avg_duration": {"$avg": "$stats.duration_seconds"},
                    "min_duration": {"$min": "$stats.duration_seconds"},
                    "max_duration": {"$max": "$stats.duration_seconds"}
                }
            }
        ]
        duration_stats_cursor = db.tasks.aggregate(avg_duration_pipeline)
        duration_stats_list = await duration_stats_cursor.to_list(length=1)
        duration_stats = duration_stats_list[0] if duration_stats_list else {
            "avg_duration": 0,
            "min_duration": 0,
            "max_duration": 0
        }

        # 7. æ¨™é»ç¬¦è™Ÿæœå‹™ä½¿ç”¨çµ±è¨ˆ
        punct_pipeline = [
            {
                "$group": {
                    "_id": "$config.punct_provider",
                    "count": {"$sum": 1}
                }
            },
            {
                "$sort": {"count": -1}
            }
        ]
        punct_stats_cursor = db.tasks.aggregate(punct_pipeline)
        punct_stats = await punct_stats_cursor.to_list(length=None)

        return {
            "overview": {
                "total_tasks": total_tasks,
                "completed_tasks": completed_tasks,
                "processing_tasks": processing_tasks,
                "failed_tasks": failed_tasks,
                "success_rate": round(completed_tasks / total_tasks * 100, 2) if total_tasks > 0 else 0
            },
            "token_usage": {
                "total_tokens": token_stats.get("total_tokens", 0),
                "prompt_tokens": token_stats.get("total_prompt_tokens", 0),
                "completion_tokens": token_stats.get("total_completion_tokens", 0),
                "tasks_with_tokens": token_stats.get("tasks_with_tokens", 0),
                "avg_tokens_per_task": round(token_stats.get("total_tokens", 0) / token_stats.get("tasks_with_tokens", 1), 2) if token_stats.get("tasks_with_tokens", 0) > 0 else 0
            },
            "model_usage": [
                {
                    "model": stat["_id"] or "æœªçŸ¥",
                    "count": stat["count"],
                    "total_tokens": stat.get("total_tokens", 0)
                }
                for stat in model_stats
            ],
            "daily_stats": [
                {
                    "date": stat["_id"],
                    "tasks_count": stat["tasks_count"],
                    "tokens_used": stat["tokens_used"]
                }
                for stat in daily_stats
            ],
            "top_users": [
                {
                    "user_id": stat["_id"],
                    "tasks_count": stat["tasks_count"],
                    "tokens_used": stat["tokens_used"]
                }
                for stat in top_users
            ],
            "performance": {
                "avg_duration_seconds": round(duration_stats.get("avg_duration", 0), 2),
                "min_duration_seconds": round(duration_stats.get("min_duration", 0), 2),
                "max_duration_seconds": round(duration_stats.get("max_duration", 0), 2)
            },
            "punct_provider_usage": [
                {
                    "provider": stat["_id"] or "none",
                    "count": stat["count"]
                }
                for stat in punct_stats
            ]
        }

    except Exception as e:
        print(f"âŒ ç²å–çµ±è¨ˆè³‡æ–™å¤±æ•—ï¼š{e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç²å–çµ±è¨ˆè³‡æ–™å¤±æ•—ï¼š{str(e)}"
        )


@app.get("/api/admin/audit-logs")
async def get_audit_logs(
    limit: int = 100,
    skip: int = 0,
    log_type: str = None,
    user_id: str = None
):
    """ç²å–æ“ä½œè¨˜éŒ„ï¼ˆç®¡ç†å“¡ï¼‰

    Args:
        limit: é™åˆ¶æ•¸é‡ï¼ˆé è¨­ 100ï¼‰
        skip: è·³éæ•¸é‡ï¼ˆé è¨­ 0ï¼‰
        log_type: éæ¿¾æ—¥èªŒé¡å‹ï¼ˆå¯é¸ï¼‰
        user_id: éæ¿¾ç”¨æˆ¶ IDï¼ˆå¯é¸ï¼‰

    Returns:
        æ“ä½œè¨˜éŒ„åˆ—è¡¨
    """
    try:
        if user_id:
            logs = await audit_log_repo.get_by_user(user_id, limit=limit, skip=skip, log_type=log_type)
        else:
            logs = await audit_log_repo.get_recent(limit=limit, skip=skip, log_type=log_type)

        # è½‰æ› ObjectId ç‚ºå­—ä¸²
        for log in logs:
            if "_id" in log:
                log["_id"] = str(log["_id"])

        return {
            "logs": logs,
            "total": len(logs),
            "limit": limit,
            "skip": skip
        }
    except Exception as e:
        print(f"âŒ ç²å–æ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç²å–æ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{str(e)}"
        )


@app.get("/api/admin/audit-logs/failed")
async def get_failed_audit_logs(
    days: int = 7,
    limit: int = 100
):
    """ç²å–å¤±æ•—çš„æ“ä½œè¨˜éŒ„ï¼ˆç®¡ç†å“¡ï¼‰

    Args:
        days: æœ€è¿‘å¹¾å¤©ï¼ˆé è¨­ 7ï¼‰
        limit: é™åˆ¶æ•¸é‡ï¼ˆé è¨­ 100ï¼‰

    Returns:
        å¤±æ•—æ“ä½œè¨˜éŒ„åˆ—è¡¨
    """
    try:
        logs = await audit_log_repo.get_failed_operations(days=days, limit=limit)

        return {
            "failed_logs": logs,
            "total": len(logs),
            "days": days
        }
    except Exception as e:
        print(f"âŒ ç²å–å¤±æ•—æ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç²å–å¤±æ•—æ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{str(e)}"
        )


@app.get("/api/admin/audit-logs/statistics")
async def get_audit_statistics(
    days: int = 30
):
    """ç²å–æ“ä½œè¨˜éŒ„çµ±è¨ˆï¼ˆç®¡ç†å“¡ï¼‰

    Args:
        days: æœ€è¿‘å¹¾å¤©ï¼ˆé è¨­ 30ï¼‰

    Returns:
        æ“ä½œçµ±è¨ˆ
    """
    try:
        stats = await audit_log_repo.get_statistics(days=days)

        return {
            "statistics": stats,
            "days": days
        }
    except Exception as e:
        print(f"âŒ ç²å–æ“ä½œçµ±è¨ˆå¤±æ•—ï¼š{e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç²å–æ“ä½œçµ±è¨ˆå¤±æ•—ï¼š{str(e)}"
        )


@app.get("/api/admin/audit-logs/resource/{resource_id}")
async def get_resource_audit_logs(
    resource_id: str,
    limit: int = 50
):
    """ç²å–ç‰¹å®šè³‡æºçš„æ“ä½œè¨˜éŒ„ï¼ˆç®¡ç†å“¡ï¼‰

    Args:
        resource_id: è³‡æº IDï¼ˆå¦‚ task_idï¼‰
        limit: é™åˆ¶æ•¸é‡ï¼ˆé è¨­ 50ï¼‰

    Returns:
        è³‡æºæ“ä½œè¨˜éŒ„åˆ—è¡¨
    """
    try:
        logs = await audit_log_repo.get_by_resource(resource_id, limit=limit)

        return {
            "resource_id": resource_id,
            "logs": logs,
            "total": len(logs)
        }
    except Exception as e:
        print(f"âŒ ç²å–è³‡æºæ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç²å–è³‡æºæ“ä½œè¨˜éŒ„å¤±æ•—ï¼š{str(e)}"
        )


# ========== ä¸»ç¨‹åºå…¥å£ ==========

if __name__ == "__main__":
    import uvicorn

    # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    reload = os.getenv("RELOAD", "false").lower() == "true"

    uvicorn.run(
        "src.main:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )
