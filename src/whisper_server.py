#!/usr/bin/env python3
"""
Whisper è½‰éŒ„æœå‹™ - FastAPI ç‰ˆæœ¬
æ¨¡å‹åªéœ€è¼‰å…¥ä¸€æ¬¡ï¼Œå¯é‡è¤‡ä½¿ç”¨æå‡æ•ˆç‡
"""

import os
import sys
import tempfile
import shutil
import asyncio
import uuid
import json
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from threading import Lock
import multiprocessing
from faster_whisper import WhisperModel
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from dotenv import load_dotenv
load_dotenv()

# èªè­‰ç³»çµ±æ¨¡çµ„
from src.database.mongodb import MongoDB
from src.routers import auth as auth_router

# Speaker Diarization
try:
    from pyannote.audio import Pipeline
    DIARIZATION_AVAILABLE = True
except ImportError:
    DIARIZATION_AVAILABLE = False
    print("âš ï¸  pyannote.audio æœªå®‰è£ï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")

# â€”â€” è¨­å®š â€”â€” #
DEFAULT_MODEL = "medium"
CHUNK_DURATION_MS = 10 * 60 * 1000
OPENAI_MODEL = "gpt-4o-mini"
GEMINI_MODEL = "gemini-2.0-flash"
# å¤šå±¤å‚™æ´æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
GEMINI_FALLBACK_MODELS = [
    "gemini-2.0-flash-lite",      # ç¬¬ä¸€å‚™æ´ï¼š2.0-flash-liteï¼ˆè¼•é‡ç‰ˆï¼Œé…é¡è¼ƒå¯¬é¬†ï¼‰
    "gemini-flash-lite-latest",   # ç¬¬äºŒå‚™æ´ï¼šflash-lite-latestï¼ˆæœ€è¼•é‡ï¼Œé€šå¸¸æœ‰é…é¡ï¼‰
    "gemini-2.5-flash",           # ç¬¬ä¸‰å‚™æ´ï¼š2.5-flashï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
    "gemini-flash-latest",        # ç¬¬å››å‚™æ´ï¼šflash-latestï¼ˆé€šç”¨ç‰ˆæœ¬ï¼‰
    "gemini-2.5-pro",             # ç¬¬äº”å‚™æ´ï¼š2.5-proï¼ˆæ›´å¼·å¤§ä½†è¼ƒæ…¢ï¼‰
]
GEMINI_FALLBACK_MODEL = "gemini-2.0-flash-lite"  # å‘å¾Œå…¼å®¹ï¼ˆå·²æ£„ç”¨ï¼‰

# é€²åº¦éšæ®µæ¬Šé‡ï¼ˆå›ºå®šåˆ†é…ï¼Œç¸½å’Œ 100%ï¼‰
PROGRESS_WEIGHTS = {
    "audio_conversion": 5.0,      # éŸ³è¨Šè½‰æª”ï¼š5%
    "audio_chunking": 5.0,        # éŸ³è¨Šåˆ‡åˆ†ï¼š5%ï¼ˆåƒ…åˆ†æ®µæ¨¡å¼ï¼‰
    "transcription": 77.0,        # è½‰éŒ„ï¼š77%ï¼ˆåˆ†æ®µæ¨¡å¼ï¼‰æˆ– 82%ï¼ˆéåˆ†æ®µæ¨¡å¼ï¼‰
    "punctuation": 13.0,          # åŠ æ¨™é»ï¼š13%
}

# æ™‚å€è¨­å®š (UTC+8 å°åŒ—æ™‚é–“)
TZ_UTC8 = timezone(timedelta(hours=8))

def get_current_time():
    """å–å¾— UTC+8 ç•¶å‰æ™‚é–“"""
    return datetime.now(TZ_UTC8).strftime("%Y-%m-%d %H:%M:%S")

def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æ™‚é•·ç‚ºå‹å¥½çš„æ–‡å­—"""
    if seconds < 60:
        return f"{int(seconds)} ç§’"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes} åˆ† {secs} ç§’"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours} å°æ™‚ {minutes} åˆ†"

def calculate_progress_percentage(task_data: Dict[str, Any]) -> float:
    """æ ¹æ“šä»»å‹™ç‹€æ…‹å‹•æ…‹è¨ˆç®—é€²åº¦ç™¾åˆ†æ¯”

    - å®Œæˆæ™‚å¼·åˆ¶è¿”å› 100%
    - éç¨‹ä¸­æ ¹æ“šå¯¦éš› chunks æ•¸é‡å‹•æ…‹åˆ†é…æ¬Šé‡
    """
    # å¦‚æœä»»å‹™å·²å®Œæˆï¼Œç›´æ¥è¿”å› 100%
    if task_data.get("status") == "completed":
        return 100.0

    progress = 0.0
    chunks = task_data.get("chunks", [])
    is_chunked = len(chunks) > 0  # æ˜¯å¦ä½¿ç”¨åˆ†æ®µæ¨¡å¼

    # 1. éŸ³è¨Šè½‰æª”å®Œæˆï¼š5%
    if task_data.get("audio_converted", False):
        progress += PROGRESS_WEIGHTS["audio_conversion"]

    # 2. è½‰éŒ„éšæ®µ
    if is_chunked:
        # åˆ†æ®µæ¨¡å¼ï¼šaudio_chunking(5%) + transcription(77%)
        if task_data.get("chunks_created", False):
            progress += PROGRESS_WEIGHTS["audio_chunking"]

        # æ ¹æ“šå¯¦éš› chunks æ•¸é‡åˆ†é…è½‰éŒ„é€²åº¦
        num_chunks = len(chunks)
        if num_chunks > 0:
            completed_chunks = sum(1 for c in chunks if c.get("status") == "completed")
            processing_chunks = sum(1 for c in chunks if c.get("status") == "processing")

            # æ¯å€‹ chunk å®Œæˆè²¢ç»ï¼š77% / num_chunks
            # æ¯å€‹ chunk é€²è¡Œä¸­è²¢ç»ï¼š50% çš„å®Œæˆæ¬Šé‡
            chunk_weight = PROGRESS_WEIGHTS["transcription"] / num_chunks
            progress += completed_chunks * chunk_weight
            progress += processing_chunks * (chunk_weight * 0.5)
    else:
        # éåˆ†æ®µæ¨¡å¼ï¼štranscription(82%) = audio_chunking(5%) + transcription(77%)
        # ç°¡å–®åˆ¤æ–·ï¼šå¦‚æœå·²ç¶“é–‹å§‹æ¨™é»ï¼Œèªªæ˜è½‰éŒ„å®Œæˆ
        if task_data.get("punctuation_started", False) or task_data.get("punctuation_completed", False):
            progress += PROGRESS_WEIGHTS["audio_chunking"] + PROGRESS_WEIGHTS["transcription"]
        elif task_data.get("audio_converted", False):
            # è½‰éŒ„ä¸­ï¼Œçµ¦äºˆ 50% çš„è½‰éŒ„é€²åº¦
            progress += (PROGRESS_WEIGHTS["audio_chunking"] + PROGRESS_WEIGHTS["transcription"]) * 0.5

    # 3. æ¨™é»è™•ç†ï¼š13%
    if task_data.get("punctuation_completed", False):
        progress += PROGRESS_WEIGHTS["punctuation"]
    elif task_data.get("punctuation_started", False):
        # æ¨™é»è™•ç†ä¸­ï¼Œæ ¹æ“šæ®µæ•¸è¨ˆç®—é€²åº¦
        punct_current = task_data.get("punctuation_current_chunk", 0)
        punct_total = task_data.get("punctuation_total_chunks", 1)
        punct_progress = (punct_current / punct_total) * PROGRESS_WEIGHTS["punctuation"]
        progress += punct_progress

    return min(progress, 100.0)

# è¼¸å‡ºç›®éŒ„è¨­å®š
OUTPUT_DIR = Path(__file__).parent.parent / "output"
OUTPUT_DIR.mkdir(exist_ok=True)

# ä»»å‹™ç‹€æ…‹æŒä¹…åŒ–æª”æ¡ˆ
TASKS_DB_FILE = OUTPUT_DIR / "tasks.json"
TAG_COLORS_FILE = OUTPUT_DIR / "tag_colors.json"
TAG_ORDER_FILE = OUTPUT_DIR / "tag_order.json"

# â€”â€” Google API Keys ç®¡ç† â€”â€” #
def load_google_api_keys():
    """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥æ‰€æœ‰ Google API Keys"""
    keys = []
    i = 1
    while True:
        key = os.getenv(f"GOOGLE_API_KEY_{i}")
        if not key:
            break
        keys.append(key)
        i += 1

    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç·¨è™Ÿçš„ keysï¼Œå˜—è©¦ä½¿ç”¨å–®ä¸€çš„ GOOGLE_API_KEY
    if not keys:
        single_key = os.getenv("GOOGLE_API_KEY")
        if single_key:
            keys.append(single_key)

    return keys

GOOGLE_API_KEYS = load_google_api_keys()
current_google_key_index = 0
google_keys_lock = Lock()

def get_next_google_api_key():
    """ç²å–ä¸‹ä¸€å€‹ Google API Keyï¼ˆè¼ªè©¢ï¼‰"""
    global current_google_key_index

    if not GOOGLE_API_KEYS:
        raise ValueError("æœªè¨­å®šä»»ä½• GOOGLE_API_KEY")

    with google_keys_lock:
        key = GOOGLE_API_KEYS[current_google_key_index]
        current_google_key_index = (current_google_key_index + 1) % len(GOOGLE_API_KEYS)
        print(f"ğŸ”‘ ä½¿ç”¨ Google API Key #{current_google_key_index + 1}/{len(GOOGLE_API_KEYS)}")
        return key

# â€”â€” å…¨åŸŸæ¨¡å‹ (å•Ÿå‹•æ™‚è¼‰å…¥ï¼ŒæŒä¹…åŒ–åœ¨è¨˜æ†¶é«”ä¸­) â€”â€” #
whisper_model = None
current_model_name = None

# â€”â€” ä»»å‹™ç‹€æ…‹ç®¡ç† â€”â€” #
transcription_tasks: Dict[str, Dict[str, Any]] = {}  # å„²å­˜ä»»å‹™ç‹€æ…‹
task_temp_dirs: Dict[str, Path] = {}  # å„²å­˜ä»»å‹™çš„æš«å­˜ç›®éŒ„è·¯å¾‘
task_cancelled: Dict[str, bool] = {}  # æ¨™è¨˜å·²å–æ¶ˆçš„ä»»å‹™
task_diarization_processes: Dict[str, Any] = {}  # å„²å­˜ä»»å‹™çš„ diarization é€²ç¨‹
tag_colors: Dict[str, str] = {}  # å„²å­˜æ¨™ç±¤é¡è‰² (æ¨™ç±¤åç¨± -> é¡è‰²ç¢¼)
tag_order: list[str] = []  # å„²å­˜æ¨™ç±¤é †åº
tasks_lock = Lock()  # ç·šç¨‹å®‰å…¨é–
executor = ThreadPoolExecutor(max_workers=1)  # ç·šç¨‹æ± ï¼Œæœ€å¤š 1 å€‹ä¸¦ç™¼è½‰éŒ„

def save_tasks_to_disk():
    """å°‡ä»»å‹™ç‹€æ…‹ä¿å­˜åˆ°ç£ç¢Ÿ"""
    try:
        with tasks_lock:
            with open(TASKS_DB_FILE, 'w', encoding='utf-8') as f:
                json.dump(transcription_tasks, f, ensure_ascii=False, indent=2)
            # ä¹Ÿå„²å­˜æ¨™ç±¤é¡è‰²
            with open(TAG_COLORS_FILE, 'w', encoding='utf-8') as f:
                json.dump(tag_colors, f, ensure_ascii=False, indent=2)
            # å„²å­˜æ¨™ç±¤é †åº
            with open(TAG_ORDER_FILE, 'w', encoding='utf-8') as f:
                json.dump(tag_order, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ ä¿å­˜ä»»å‹™ç‹€æ…‹å¤±æ•—ï¼š{e}")

def load_tasks_from_disk():
    """å¾ç£ç¢Ÿè¼‰å…¥ä»»å‹™ç‹€æ…‹"""
    global transcription_tasks, tag_colors, tag_order
    try:
        if TASKS_DB_FILE.exists():
            with open(TASKS_DB_FILE, 'r', encoding='utf-8') as f:
                loaded_tasks = json.load(f)

            # éæ¿¾æ‰é€²è¡Œä¸­çš„ä»»å‹™ï¼ˆå› ç‚ºé‡å•Ÿå¾Œç„¡æ³•ç¹¼çºŒï¼‰
            # åªä¿ç•™å·²å®Œæˆã€å¤±æ•—ã€å–æ¶ˆçš„ä»»å‹™
            with tasks_lock:
                for task_id, task in loaded_tasks.items():
                    if task["status"] in ["completed", "failed", "cancelled"]:
                        transcription_tasks[task_id] = task
                    else:
                        # å°‡é€²è¡Œä¸­çš„ä»»å‹™æ¨™è¨˜ç‚ºå¤±æ•—
                        task["status"] = "failed"
                        task["error"] = "æœå‹™é‡å•Ÿï¼Œä»»å‹™å·²ä¸­æ–·"
                        task["progress"] = "æœå‹™é‡å•Ÿï¼Œä»»å‹™å·²ä¸­æ–·"
                        transcription_tasks[task_id] = task

            print(f"âœ… å·²å¾ç£ç¢Ÿè¼‰å…¥ {len(transcription_tasks)} å€‹ä»»å‹™è¨˜éŒ„")

        # è¼‰å…¥æ¨™ç±¤é¡è‰²
        if TAG_COLORS_FILE.exists():
            with open(TAG_COLORS_FILE, 'r', encoding='utf-8') as f:
                tag_colors = json.load(f)
            print(f"âœ… å·²è¼‰å…¥ {len(tag_colors)} å€‹æ¨™ç±¤é¡è‰²è¨­å®š")

        # è¼‰å…¥æ¨™ç±¤é †åº
        if TAG_ORDER_FILE.exists():
            with open(TAG_ORDER_FILE, 'r', encoding='utf-8') as f:
                tag_order = json.load(f)
            print(f"âœ… å·²è¼‰å…¥æ¨™ç±¤é †åºï¼ˆ{len(tag_order)} å€‹æ¨™ç±¤ï¼‰")
    except Exception as e:
        print(f"âŒ è¼‰å…¥ä»»å‹™ç‹€æ…‹å¤±æ•—ï¼š{e}")
        print(f"   å°‡å¾ç©ºç™½ç‹€æ…‹é–‹å§‹")

# Pydantic models
class TranscriptContentUpdate(BaseModel):
    content: str

class TaskMetadataUpdate(BaseModel):
    custom_name: str = None

class TaskTagsUpdate(BaseModel):
    tags: list[str] = []

class TagColorUpdate(BaseModel):
    color: str

class TagOrderUpdate(BaseModel):
    order: list[str] = []

class KeepAudioUpdate(BaseModel):
    keep_audio: bool

class BatchDeleteRequest(BaseModel):
    task_ids: List[str]

class BatchTagsRequest(BaseModel):
    task_ids: List[str]
    tags: List[str]

app = FastAPI(
    title="Whisper è½‰éŒ„æœå‹™",
    description="ä¸Šå‚³éŸ³æª”é€²è¡Œè½‰éŒ„ï¼Œæ”¯æ´è‡ªå‹•åˆ†æ®µèˆ‡æ¨™é»",
    version="2.0.0"
)

# æ·»åŠ  CORS ä¸­é–“ä»¶
# å¾ç’°å¢ƒè®Šæ•¸è®€å–å…è¨±çš„ä¾†æº
cors_origins_str = os.getenv("CORS_ORIGINS", "*")
cors_origins = [origin.strip() for origin in cors_origins_str.split(",")] if cors_origins_str != "*" else ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],  # å…è¨±å‰ç«¯è¨ªå•æ‰€æœ‰éŸ¿æ‡‰é ­
    max_age=3600,  # preflight è«‹æ±‚å¿«å–æ™‚é–“ï¼ˆç§’ï¼‰
)

# è¨»å†Šèªè­‰è·¯ç”±
app.include_router(auth_router.router)


# ---------- å·¥å…·å‡½å¼ ----------

def cleanup_temp_dir(temp_dir: Path):
    """æ¸…ç†è‡¨æ™‚ç›®éŒ„"""
    try:
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
            print(f"ğŸ—‘ï¸ å·²æ¸…ç†è‡¨æ™‚ç›®éŒ„ï¼š{temp_dir.name}")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†è‡¨æ™‚ç›®éŒ„å¤±æ•—ï¼š{e}")


def update_task_status(task_id: str, updates: Dict[str, Any]):
    """æ›´æ–°ä»»å‹™ç‹€æ…‹ï¼ˆç·šç¨‹å®‰å…¨ï¼‰"""
    with tasks_lock:
        if task_id in transcription_tasks:
            transcription_tasks[task_id].update(updates)
            transcription_tasks[task_id]["updated_at"] = get_current_time()

            # è‡ªå‹•è¨ˆç®—ä¸¦æ›´æ–°é€²åº¦ç™¾åˆ†æ¯”
            progress_pct = calculate_progress_percentage(transcription_tasks[task_id])
            transcription_tasks[task_id]["progress_percentage"] = round(progress_pct, 1)

    # ç•¶ä»»å‹™ç‹€æ…‹è®Šæ›´ç‚ºçµ‚æ­¢ç‹€æ…‹æ™‚ï¼Œä¿å­˜åˆ°ç£ç¢Ÿ
    if updates.get("status") in ["completed", "failed", "cancelled"]:
        save_tasks_to_disk()


# ---------- è½‰éŒ„å‡½å¼ (å¾åŸå§‹ transcribe.py ç§»æ¤) ----------

def transcribe_single_chunk(
    model,
    chunk_path: Path,
    language: Optional[str] = None,
    task_id: str = None,
    chunk_idx: int = None,
    time_offset: float = 0.0,
    return_segments: bool = True
) -> tuple:
    """è½‰éŒ„å–®ä¸€éŸ³æª”ç‰‡æ®µï¼ˆç”¨æ–¼ä¸¦è¡Œè™•ç†ï¼‰

    Args:
        model: Whisper æ¨¡å‹
        chunk_path: éŸ³æª”è·¯å¾‘
        language: èªè¨€ä»£ç¢¼ï¼ˆNone è¡¨ç¤ºè‡ªå‹•åµæ¸¬ï¼Œé è¨­å€¼ï¼‰
        task_id: ä»»å‹™ ID
        chunk_idx: Chunk ç´¢å¼•
        time_offset: æ™‚é–“åç§»ï¼ˆç§’ï¼‰ï¼Œç”¨æ–¼è¨ˆç®—ç›¸å°æ–¼å®Œæ•´éŸ³æª”çš„æ™‚é–“æˆ³
        return_segments: æ˜¯å¦è¿”å›å¸¶æ™‚é–“æˆ³çš„ segmentsï¼ˆé è¨­ Trueï¼‰

    Returns:
        è¿”å› (text, segments, detected_language) å…ƒçµ„
    """
    # æ¨™è¨˜æ­¤ chunk é–‹å§‹è™•ç†ï¼ˆå¯¦éš›é–‹å§‹åŸ·è¡Œæ™‚æ‰æ¨™è¨˜ï¼‰
    if task_id and chunk_idx:
        with tasks_lock:
            if task_id in transcription_tasks:
                chunks = transcription_tasks[task_id].get("chunks", [])
                if chunk_idx - 1 < len(chunks) and chunks[chunk_idx - 1]["status"] == "pending":
                    chunks[chunk_idx - 1]["status"] = "processing"
                    chunks[chunk_idx - 1]["started_at"] = get_current_time()
        update_task_status(task_id, {})  # è§¸ç™¼é€²åº¦è¨ˆç®—

    segments, info = model.transcribe(str(chunk_path), language=language, beam_size=5)

    # ç²å– Whisper åµæ¸¬åˆ°çš„èªè¨€
    detected_language = info.language if hasattr(info, 'language') else None

    # å§‹çµ‚æ”¶é›† segments
    segments_list = []
    text_parts = []

    for segment in segments:
        text_parts.append(segment.text)
        segments_list.append({
            "start": segment.start + time_offset,  # åŠ ä¸Šæ™‚é–“åç§»
            "end": segment.end + time_offset,
            "text": segment.text
        })

    text = "".join(text_parts).strip()

    return text, segments_list, detected_language


def transcribe_with_timestamps(model, audio_path: Path, language: Optional[str] = None) -> tuple:
    """
    è½‰éŒ„éŸ³æª”ä¸¦è¿”å›å¸¶æ™‚é–“æˆ³çš„ segments

    Args:
        model: Whisper æ¨¡å‹
        audio_path: éŸ³æª”è·¯å¾‘
        language: èªè¨€ä»£ç¢¼ï¼ˆNone è¡¨ç¤ºè‡ªå‹•åµæ¸¬ï¼Œé è¨­å€¼ï¼‰

    Returns:
        è¿”å› (segments_list, detected_language) å…ƒçµ„
        segments_list: List of segments with format [{"start": 0.0, "end": 5.2, "text": "hello"}, ...]
        detected_language: Whisper åµæ¸¬åˆ°çš„èªè¨€ä»£ç¢¼
    """
    segments_list = []
    segments, info = model.transcribe(str(audio_path), language=language, beam_size=5)

    # ç²å– Whisper åµæ¸¬åˆ°çš„èªè¨€
    detected_language = info.language if hasattr(info, 'language') else None

    for segment in segments:
        segments_list.append({
            "start": segment.start,
            "end": segment.end,
            "text": segment.text
        })

    return segments_list, detected_language


def perform_diarization_in_process(audio_path_str: str, max_speakers: Optional[int], hf_token: str) -> Optional[List[Dict]]:
    """åœ¨ç¨ç«‹é€²ç¨‹ä¸­åŸ·è¡Œ speaker diarizationï¼ˆå¯è¢«å¼·åˆ¶çµ‚æ­¢ï¼‰

    æ­¤å‡½æ•¸è¨­è¨ˆç‚ºåœ¨å–®ç¨çš„é€²ç¨‹ä¸­é‹è¡Œï¼Œå› æ­¤ä¸ä¾è³´å…¨å±€è®Šé‡

    Args:
        audio_path_str: éŸ³æª”è·¯å¾‘ï¼ˆå­—ä¸²æ ¼å¼ï¼‰
        max_speakers: æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼‰
        hf_token: Hugging Face Token

    Returns:
        List of diarization segments with format:
        [{"start": 0.0, "end": 5.2, "speaker": "SPEAKER_00"}, ...]
    """
    try:
        # åœ¨é€²ç¨‹ä¸­é‡æ–°è¼‰å…¥ pipelineï¼ˆå› ç‚ºç„¡æ³•è·¨é€²ç¨‹å‚³éï¼‰
        from pyannote.audio import Pipeline
        from huggingface_hub import login

        if hf_token:
            login(token=hf_token, add_to_git_credential=False)

        print(f"ğŸ”Š [é€²ç¨‹] æ­£åœ¨è¼‰å…¥ diarization pipeline...")
        import torch
        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")

        # M1 Mac MPS åŠ é€Ÿ
        if torch.backends.mps.is_available():
            pipeline.to(torch.device("mps"))
            print(f"ğŸ”Š [é€²ç¨‹] ä½¿ç”¨ MPS åŠ é€Ÿ")

        print(f"ğŸ”Š [é€²ç¨‹] æ­£åœ¨åˆ†æèªªè©±è€…...")

        # æº–å‚™ diarization åƒæ•¸
        diarization_kwargs = {}
        if max_speakers is not None and 2 <= max_speakers <= 10:
            diarization_kwargs["min_speakers"] = 1
            diarization_kwargs["max_speakers"] = max_speakers
            print(f"   [é€²ç¨‹] è¨­å®šè¬›è€…äººæ•¸ç¯„åœï¼š1-{max_speakers} äºº")

        print(f"   [é€²ç¨‹] Diarization åƒæ•¸ï¼š{diarization_kwargs}")
        diarization = pipeline(audio_path_str, **diarization_kwargs)

        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                "start": turn.start,
                "end": turn.end,
                "speaker": speaker
            })

        print(f"âœ… [é€²ç¨‹] èªªè©±è€…åˆ†æå®Œæˆï¼Œè­˜åˆ¥åˆ° {len(set(s['speaker'] for s in segments))} ä½èªªè©±è€…")
        return segments

    except Exception as e:
        print(f"âš ï¸  [é€²ç¨‹] Speaker diarization å¤±æ•—ï¼š{e}")
        return None


def perform_diarization(audio_path: Path, max_speakers: Optional[int] = None) -> Optional[List[Dict]]:
    """åŸ·è¡Œ speaker diarizationï¼ˆç·šç¨‹ç‰ˆæœ¬ï¼Œç”¨æ–¼éåˆ†æ®µæ¨¡å¼ï¼‰

    Args:
        audio_path: éŸ³æª”è·¯å¾‘
        max_speakers: æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼‰

    Returns:
        List of diarization segments with format:
        [{"start": 0.0, "end": 5.2, "speaker": "SPEAKER_00"}, ...]
    """
    if not diarization_pipeline:
        return None

    try:
        print(f"ğŸ”Š æ­£åœ¨åˆ†æèªªè©±è€…...")

        # æº–å‚™ diarization åƒæ•¸
        diarization_kwargs = {}
        if max_speakers is not None and 2 <= max_speakers <= 10:
            # pyannote.audio éœ€è¦åŒæ™‚è¨­å®š min_speakers å’Œ max_speakers
            diarization_kwargs["min_speakers"] = 1
            diarization_kwargs["max_speakers"] = max_speakers
            print(f"   è¨­å®šè¬›è€…äººæ•¸ç¯„åœï¼š1-{max_speakers} äºº")

        print(f"   Diarization åƒæ•¸ï¼š{diarization_kwargs}")
        diarization = diarization_pipeline(str(audio_path), **diarization_kwargs)

        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                "start": turn.start,
                "end": turn.end,
                "speaker": speaker
            })

        print(f"âœ… èªªè©±è€…åˆ†æå®Œæˆï¼Œè­˜åˆ¥åˆ° {len(set(s['speaker'] for s in segments))} ä½èªªè©±è€…")
        return segments

    except Exception as e:
        print(f"âš ï¸  Speaker diarization å¤±æ•—ï¼š{e}")
        return None


def merge_transcription_with_diarization(
    transcription_segments: List[Dict],
    diarization_segments: List[Dict]
) -> str:
    """åˆä½µè½‰éŒ„æ–‡å­—å’Œèªªè©±è€…æ¨™è¨˜

    Args:
        transcription_segments: Whisper è½‰éŒ„çµæœ (å¸¶æ™‚é–“æˆ³)
        diarization_segments: Speaker diarization çµæœ

    Returns:
        åˆä½µå¾Œçš„æ–‡å­—ï¼Œæ ¼å¼ï¼š[Speaker A] æ–‡å­—å…§å®¹
    """
    if not diarization_segments:
        # æ²’æœ‰ diarization çµæœï¼Œç›´æ¥è¿”å›ç´”æ–‡å­—
        return " ".join(seg.get("text", "") for seg in transcription_segments)

    # ç‚ºæ¯å€‹è½‰éŒ„ç‰‡æ®µåˆ†é…èªªè©±è€…
    result_lines = []
    current_speaker = None
    current_text = []

    for trans_seg in transcription_segments:
        trans_start = trans_seg.get("start", 0)
        trans_end = trans_seg.get("end", 0)
        trans_text = trans_seg.get("text", "")

        if not trans_text.strip():
            continue

        # æ‰¾åˆ°èˆ‡æ­¤è½‰éŒ„ç‰‡æ®µé‡ç–Šæœ€å¤šçš„èªªè©±è€…
        best_speaker = None
        max_overlap = 0

        for dia_seg in diarization_segments:
            dia_start = dia_seg["start"]
            dia_end = dia_seg["end"]

            # è¨ˆç®—é‡ç–Šæ™‚é–“
            overlap_start = max(trans_start, dia_start)
            overlap_end = min(trans_end, dia_end)
            overlap = max(0, overlap_end - overlap_start)

            if overlap > max_overlap:
                max_overlap = overlap
                best_speaker = dia_seg["speaker"]

        # å¦‚æœèªªè©±è€…æ”¹è®Šï¼Œè¼¸å‡ºä¹‹å‰çš„å…§å®¹
        if best_speaker != current_speaker and current_text:
            speaker_label = f"[{current_speaker}]" if current_speaker else ""
            result_lines.append(f"{speaker_label} {''.join(current_text)}")
            current_text = []

        current_speaker = best_speaker
        current_text.append(trans_text)

    # è¼¸å‡ºæœ€å¾Œä¸€æ®µ
    if current_text:
        speaker_label = f"[{current_speaker}]" if current_speaker else ""
        result_lines.append(f"{speaker_label} {''.join(current_text)}")

    return "\n\n".join(result_lines)


def transcribe_audio_in_chunks(
    audio_path: Path,
    model,
    chunk_duration_ms: int = CHUNK_DURATION_MS,
    task_id: str = None,
    diarize: bool = False,
    max_speakers: Optional[int] = None,
    language: Optional[str] = None
) -> str:
    """å°‡éŸ³æª”åˆ†æ®µå¾Œä¸¦è¡Œè½‰éŒ„ï¼Œæé«˜é€Ÿåº¦å’Œæº–ç¢ºåº¦

    Args:
        audio_path: éŸ³æª”è·¯å¾‘
        model: Whisper æ¨¡å‹
        chunk_duration_ms: æ¯æ®µé•·åº¦ï¼ˆæ¯«ç§’ï¼‰
        task_id: ä»»å‹™ ID
        diarize: æ˜¯å¦å•Ÿç”¨èªªè©±è€…è¾¨è­˜ï¼ˆæœƒå…ˆå°å®Œæ•´éŸ³æª”åš diarizationï¼Œå†åˆ‡åˆ†è½‰éŒ„ï¼‰
        max_speakers: æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼‰
    """
    print(f"ğŸ”Š è¼‰å…¥éŸ³æª”ï¼š{audio_path.name}")
    audio = AudioSegment.from_file(audio_path)
    total_duration_ms = len(audio)
    total_minutes = total_duration_ms / 1000 / 60

    print(f"ğŸ“Š éŸ³æª”ç¸½é•·åº¦ï¼š{total_minutes:.1f} åˆ†é˜")

    # å¦‚æœéŸ³æª”ä¸é•·ï¼Œç›´æ¥è½‰éŒ„
    if total_duration_ms <= chunk_duration_ms:
        print(f"ğŸ“ éŸ³æª”é•·åº¦åœ¨ {chunk_duration_ms/1000/60:.0f} åˆ†é˜å…§ï¼Œç›´æ¥è½‰éŒ„...")
        text, segments, detected_language = transcribe_single_chunk(model, audio_path, language=language)
        return text, segments, detected_language

    # æ­¥é©Ÿ 1ï¼šå¦‚æœå•Ÿç”¨ diarizationï¼Œåœ¨èƒŒæ™¯ä¸¦è¡ŒåŸ·è¡Œèªªè©±è€…è¾¨è­˜
    diarization_future = None
    diarization_start_time = None
    diarization_executor = None

    if diarize and diarization_pipeline:
        diarization_start_time = datetime.now(TZ_UTC8)
        print(f"ğŸ”Š åœ¨èƒŒæ™¯å•Ÿå‹•èªªè©±è€…è¾¨è­˜ï¼ˆèˆ‡è½‰éŒ„ä¸¦è¡ŒåŸ·è¡Œï¼‰...")
        if task_id:
            update_task_status(task_id, {
                "progress": "æ­£åœ¨åˆ†æèªªè©±è€…ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼‰...",
                "diarization_status": "running"
            })

        # ä½¿ç”¨é€²ç¨‹æ± åŸ·è¡Œ diarizationï¼Œå¯ä»¥è¢«å¼·åˆ¶çµ‚æ­¢
        diarization_executor = ProcessPoolExecutor(max_workers=1)
        hf_token = os.getenv("HF_TOKEN", "")
        diarization_future = diarization_executor.submit(
            perform_diarization_in_process,
            str(audio_path),
            max_speakers,
            hf_token
        )

        # è¨˜éŒ„ diarization é€²ç¨‹ä¾›å–æ¶ˆæ™‚ä½¿ç”¨
        if task_id:
            with tasks_lock:
                task_diarization_processes[task_id] = diarization_executor

    # é•·éŸ³æª”ï¼šåˆ†æ®µè™•ç†
    num_chunks = (total_duration_ms + chunk_duration_ms - 1) // chunk_duration_ms
    print(f"ğŸ”„ éŸ³æª”è¼ƒé•·ï¼Œå°‡åˆ†ç‚º {num_chunks} æ®µè™•ç†ï¼ˆæ¯æ®µç´„ {chunk_duration_ms/1000/60:.0f} åˆ†é˜ï¼‰...")

    # åˆå§‹åŒ– chunks ç‹€æ…‹è¿½è¹¤
    if task_id:
        chunks_state = [
            {
                "chunk_id": i,
                "status": "pending",
                "started_at": None,
                "completed_at": None,
                "duration_seconds": None
            }
            for i in range(1, num_chunks + 1)
        ]

        update_task_status(task_id, {
            "total_chunks": num_chunks,
            "completed_chunks": 0,
            "chunks": chunks_state,
            "chunks_created": False  # åˆ‡åˆ†å°šæœªå®Œæˆ
            # ä¸è¨­ç½® estimated_completion_timeï¼Œå‰ç«¯æœƒé¡¯ç¤ºã€Œè¨ˆç®—ä¸­......ã€
        })

    # ç¬¬ä¸€æ­¥ï¼šæº–å‚™æ‰€æœ‰ chunksï¼ˆåˆ‡åˆ†éŸ³æª”ï¼‰
    print(f"ğŸ“¦ æº–å‚™åˆ‡åˆ†éŸ³æª”...")
    chunk_info_list = []  # å„²å­˜ (chunk_idx, start_ms, end_ms, temp_path)
    start_ms = 0
    chunk_idx = 1

    while start_ms < total_duration_ms:
        end_ms = min(start_ms + chunk_duration_ms, total_duration_ms)

        # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€æ®µï¼Œå˜—è©¦åœ¨éœéŸ³è™•åˆ‡åˆ†
        if end_ms < total_duration_ms:
            search_start = max(end_ms - 30000, start_ms)
            search_end = min(end_ms + 30000, total_duration_ms)
            search_segment = audio[search_start:search_end]

            nonsilent_ranges = detect_nonsilent(
                search_segment,
                min_silence_len=500,
                silence_thresh=-40
            )

            if nonsilent_ranges:
                target_pos = end_ms - search_start
                best_split = end_ms
                min_diff = float('inf')

                for i in range(len(nonsilent_ranges) - 1):
                    gap_start = nonsilent_ranges[i][1]
                    gap_end = nonsilent_ranges[i + 1][0]
                    gap_mid = (gap_start + gap_end) // 2

                    diff = abs(gap_mid - target_pos)
                    if diff < min_diff:
                        min_diff = diff
                        best_split = search_start + gap_mid

                if abs(best_split - end_ms) < 60000:
                    end_ms = best_split

        print(f"   æº–å‚™ç¬¬ {chunk_idx}/{num_chunks} æ®µ ({start_ms/1000/60:.1f}-{end_ms/1000/60:.1f} åˆ†é˜)...")

        # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if task_id and task_cancelled.get(task_id, False):
            raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

        # å°å‡º chunk åˆ°è‡¨æ™‚æª”æ¡ˆ
        chunk_audio = audio[start_ms:end_ms]
        temp_path = audio_path.parent / f"_temp_{audio_path.stem}_chunk_{chunk_idx}.wav"
        chunk_audio.export(temp_path, format="wav")

        chunk_info_list.append((chunk_idx, start_ms, end_ms, temp_path))

        start_ms = end_ms
        chunk_idx += 1

    print(f"âœ… å·²æº–å‚™ {len(chunk_info_list)} å€‹éŸ³æª”ç‰‡æ®µ")

    # æ¨™è¨˜åˆ‡åˆ†å®Œæˆä¸¦è¨ˆç®—é ä¼°å®Œæˆæ™‚é–“
    if task_id:
        # æ ¹æ“šéŸ³æª”æ™‚é•·è¨ˆç®—é ä¼°è™•ç†æ™‚é–“ï¼šéŸ³æª”æ™‚é•·çš„ 3/5
        estimated_minutes = total_minutes * 3 / 5

        # å–å¾—ä»»å‹™é–‹å§‹æ™‚é–“ä¸¦è¨ˆç®—é ä¼°å®Œæˆæ™‚é–“
        with tasks_lock:
            if task_id in transcription_tasks:
                started_at_str = transcription_tasks[task_id].get("started_at")
                if started_at_str:
                    started_at = datetime.strptime(started_at_str, "%Y-%m-%d %H:%M:%S").replace(tzinfo=TZ_UTC8)
                    estimated_completion = started_at + timedelta(minutes=estimated_minutes)
                    estimated_completion_str = estimated_completion.strftime("%Y-%m-%d %H:%M:%S")
                else:
                    estimated_completion_str = None

        update_task_status(task_id, {
            "chunks_created": True,
            "progress": f"å·²åˆ‡åˆ†ç‚º {num_chunks} å€‹ç‰‡æ®µï¼Œé–‹å§‹è½‰éŒ„...",
            "estimated_completion_time": estimated_completion_str
        })

    # ç¬¬äºŒæ­¥ï¼šä¸¦è¡Œè½‰éŒ„æ‰€æœ‰ chunksï¼ˆèˆ‡ diarization åŒæ™‚é€²è¡Œï¼‰
    # å¦‚æœåŒæ™‚åŸ·è¡Œ diarizationï¼Œé™ä½è½‰éŒ„ä¸¦è¡Œåº¦ä»¥æ¸›å°‘è³‡æºç«¶çˆ­
    transcribe_workers = 2 if diarization_future else 4
    print(f"ğŸš€ é–‹å§‹ä¸¦è¡Œè½‰éŒ„ï¼ˆä¸¦è¡Œæ•¸ï¼š{transcribe_workers}ï¼‰{'ï¼ŒåŒæ™‚é€²è¡Œèªªè©±è€…è¾¨è­˜' if diarization_future else ''}...")
    chunks_text = [None] * num_chunks  # é å…ˆåˆ†é…é™£åˆ—ä¿æŒé †åº
    all_segments = []  # å§‹çµ‚æ”¶é›†æ‰€æœ‰ segments

    try:
        with ThreadPoolExecutor(max_workers=transcribe_workers) as executor:
            # æäº¤æ‰€æœ‰è½‰éŒ„ä»»å‹™åˆ°ç·šç¨‹æ± 
            future_to_chunk = {}
            for chunk_idx, start_ms, end_ms, temp_path in chunk_info_list:
                # è¨ˆç®—é€™å€‹ chunk çš„æ™‚é–“åç§»ï¼ˆç›¸å°æ–¼å®Œæ•´éŸ³æª”çš„ç§’æ•¸ï¼‰
                time_offset_seconds = start_ms / 1000.0

                # å§‹çµ‚è¿”å›å¸¶æ™‚é–“æˆ³çš„ segments
                future = executor.submit(
                    transcribe_single_chunk,
                    model,
                    temp_path,
                    language,  # ä½¿ç”¨æŒ‡å®šçš„èªè¨€
                    task_id,
                    chunk_idx,
                    time_offset_seconds,
                    True  # return_segments å§‹çµ‚ç‚º True
                )
                future_to_chunk[future] = (chunk_idx, temp_path, time_offset_seconds)

            # ç­‰å¾…å®Œæˆä¸¦æ›´æ–°é€²åº¦
            detected_language = None  # ç”¨æ–¼è¨˜éŒ„ç¬¬ä¸€å€‹ chunk åµæ¸¬åˆ°çš„èªè¨€
            for future in as_completed(future_to_chunk):
                chunk_idx, temp_path, time_offset = future_to_chunk[future]

                # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                if task_id and task_cancelled.get(task_id, False):
                    executor.shutdown(wait=False, cancel_futures=True)
                    # å¼·åˆ¶çµ‚æ­¢ diarization é€²ç¨‹
                    if diarization_future and diarization_executor:
                        print(f"ğŸ›‘ æ­£åœ¨å¼·åˆ¶çµ‚æ­¢èªªè©±è€…è¾¨è­˜é€²ç¨‹...")
                        diarization_executor.shutdown(wait=False, cancel_futures=True)
                    raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

                try:
                    chunk_start_time = None
                    if task_id:
                        with tasks_lock:
                            if task_id in transcription_tasks:
                                chunks = transcription_tasks[task_id].get("chunks", [])
                                if chunk_idx - 1 < len(chunks):
                                    start_str = chunks[chunk_idx - 1].get("started_at")
                                    if start_str:
                                        chunk_start_time = datetime.strptime(start_str, "%Y-%m-%d %H:%M:%S")

                    result = future.result()

                    # è™•ç†è¿”å›çµæœï¼ˆç¾åœ¨æ˜¯ (æ–‡å­—, segments, detected_language) å…ƒçµ„ï¼‰
                    chunk_text, chunk_segments, chunk_detected_language = result
                    all_segments.extend(chunk_segments)  # æ”¶é›†æ‰€æœ‰ segments

                    # è¨˜éŒ„ç¬¬ä¸€å€‹ chunk åµæ¸¬åˆ°çš„èªè¨€
                    if detected_language is None and chunk_detected_language:
                        detected_language = chunk_detected_language

                    chunks_text[chunk_idx - 1] = chunk_text
                    print(f"   âœ… å®Œæˆç¬¬ {chunk_idx}/{num_chunks} æ®µ")

                    # è¨ˆç®— chunk è™•ç†æ™‚é–“
                    chunk_duration = None
                    if chunk_start_time:
                        chunk_end_time = datetime.now(TZ_UTC8)
                        chunk_duration = (chunk_end_time - chunk_start_time.replace(tzinfo=TZ_UTC8)).total_seconds()

                    # æ›´æ–° chunk ç‹€æ…‹ç‚º completed
                    completed = sum(1 for t in chunks_text if t is not None)
                    if task_id:
                        with tasks_lock:
                            if task_id in transcription_tasks:
                                chunks = transcription_tasks[task_id].get("chunks", [])
                                if chunk_idx - 1 < len(chunks):
                                    chunks[chunk_idx - 1]["status"] = "completed"
                                    chunks[chunk_idx - 1]["completed_at"] = get_current_time()
                                    if chunk_duration:
                                        chunks[chunk_idx - 1]["duration_seconds"] = round(chunk_duration, 1)
                        update_task_status(task_id, {
                            "progress": f"æ­£åœ¨è½‰éŒ„éŸ³è¨Š... ({completed}/{num_chunks} æ®µå®Œæˆ)",
                            "completed_chunks": completed
                        })

                except Exception as e:
                    print(f"   âŒ ç¬¬ {chunk_idx} æ®µè½‰éŒ„å¤±æ•—ï¼š{e}")
                    raise

    finally:
        # æ¸…ç†æ‰€æœ‰è‡¨æ™‚æª”æ¡ˆ
        for _, _, _, temp_path in chunk_info_list:
            try:
                if temp_path.exists():
                    temp_path.unlink()
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—ï¼š{e}")

        # ç¢ºä¿ diarization executor è¢«æ­£ç¢ºé—œé–‰
        if diarization_executor:
            try:
                diarization_executor.shutdown(wait=False, cancel_futures=True)
                print(f"âœ… Diarization é€²ç¨‹å·²é—œé–‰")
            except Exception as e:
                print(f"âš ï¸ é—œé–‰ diarization executor å¤±æ•—ï¼š{e}")

        # æ¸…ç† diarization é€²ç¨‹è¨˜éŒ„
        if task_id:
            with tasks_lock:
                task_diarization_processes.pop(task_id, None)

    print("âœ… æ‰€æœ‰éŸ³æª”ç‰‡æ®µè½‰éŒ„å®Œæˆ")

    # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœå•Ÿç”¨äº† diarizationï¼Œç­‰å¾…èªªè©±è€…è¾¨è­˜å®Œæˆä¸¦åˆä½µè³‡è¨Š
    if diarization_future:
        print(f"â³ ç­‰å¾…èªªè©±è€…è¾¨è­˜å®Œæˆ...")
        if task_id:
            update_task_status(task_id, {"progress": "ç­‰å¾…èªªè©±è€…è¾¨è­˜å®Œæˆ..."})

        try:
            # ç­‰å¾… diarization å®Œæˆä¸¦å–å¾—çµæœ
            diarization_segments = diarization_future.result()
            if diarization_executor:
                diarization_executor.shutdown(wait=True)

            # è¨ˆç®— diarization å¯¦éš›è€—æ™‚
            if diarization_start_time:
                diarization_duration = (datetime.now(TZ_UTC8) - diarization_start_time).total_seconds()
            else:
                diarization_duration = 0

            if diarization_segments:
                num_speakers = len(set(s['speaker'] for s in diarization_segments))
                print(f"âœ… èªªè©±è€…è¾¨è­˜å®Œæˆï¼Œè­˜åˆ¥åˆ° {num_speakers} ä½èªªè©±è€… (è€—æ™‚ {format_duration(diarization_duration)})")
                if task_id:
                    update_task_status(task_id, {
                        "progress": f"èªªè©±è€…è¾¨è­˜å®Œæˆ ({num_speakers} ä½èªªè©±è€…ï¼Œè€—æ™‚ {format_duration(diarization_duration)})",
                        "diarization_status": "completed",
                        "diarization_num_speakers": num_speakers,
                        "diarization_duration_seconds": round(diarization_duration, 1)
                    })

                # åˆä½µèªªè©±è€…è³‡è¨Šèˆ‡è½‰éŒ„æ–‡å­—
                print(f"ğŸ”— æ­£åœ¨åˆä½µèªªè©±è€…è³‡è¨Šèˆ‡è½‰éŒ„æ–‡å­—...")
                if task_id:
                    update_task_status(task_id, {"progress": "æ­£åœ¨åˆä½µèªªè©±è€…è³‡è¨Š..."})

                # æŒ‰æ™‚é–“æ’åº segmentsï¼ˆç¢ºä¿é †åºæ­£ç¢ºï¼‰
                all_segments.sort(key=lambda s: s["start"])

                final_text = merge_transcription_with_diarization(all_segments, diarization_segments)
                print(f"âœ… èªªè©±è€…è³‡è¨Šåˆä½µå®Œæˆ")
                return final_text, all_segments, detected_language
            else:
                print(f"âš ï¸  èªªè©±è€…è¾¨è­˜å¤±æ•—ï¼Œè¿”å›ç´”æ–‡å­—è½‰éŒ„")
                if task_id:
                    update_task_status(task_id, {
                        "diarization_status": "failed"
                    })
                return " ".join(chunks_text), all_segments, detected_language

        except Exception as e:
            print(f"âš ï¸  ç­‰å¾…èªªè©±è€…è¾¨è­˜æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            print(f"   å°‡è¿”å›ç´”æ–‡å­—è½‰éŒ„")
            if task_id:
                update_task_status(task_id, {
                    "diarization_status": "failed"
                })
            return " ".join(chunks_text), all_segments, detected_language
    else:
        # æ²’æœ‰ diarizationï¼Œè¿”å›ç´”æ–‡å­—å’Œ segments
        return " ".join(chunks_text), all_segments, detected_language


def detect_language_with_llm(text: str, provider: str = "gemini") -> str:
    """ä½¿ç”¨ LLM è‡ªå‹•è¾¨è­˜æ–‡å­—èªè¨€

    Args:
        text: è¦è¾¨è­˜çš„æ–‡å­—ï¼ˆå»ºè­°ä½¿ç”¨å‰å¹¾ç™¾å­—å³å¯ï¼‰
        provider: ä½¿ç”¨çš„ LLM æä¾›è€… (gemini/openai)

    Returns:
        èªè¨€ä»£ç¢¼ (zh/en/ja/ko ç­‰)
    """
    # åªå–å‰ 100 å­—é€²è¡Œè¾¨è­˜ä»¥ç¯€çœæˆæœ¬
    sample_text = text[:100]

    prompt = f"""Please identify the primary language of the following text and respond with ONLY the language code (zh/en/ja/ko/es/fr/de/etc.).

Text:
{sample_text}

Language code:"""

    try:
        if provider == "gemini":
            result = call_gemini_with_retry(prompt).strip().lower()
        else:  # openai
            from openai import OpenAI
            client = OpenAI()
            resp = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "You are a language detection assistant. Respond only with language codes."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
            )
            result = resp.choices[0].message.content.strip().lower()

        # é©—è­‰çµæœæ˜¯å¦ç‚ºæœ‰æ•ˆçš„èªè¨€ä»£ç¢¼
        valid_codes = ["zh", "en", "ja", "ko", "es", "fr", "de", "it", "pt", "ru", "ar", "hi", "th", "vi"]
        if result in valid_codes:
            return result

        # å¦‚æœä¸æ˜¯æ¨™æº–ä»£ç¢¼ï¼Œå˜—è©¦æ˜ å°„å¸¸è¦‹å›æ‡‰
        if "chinese" in result or "ä¸­æ–‡" in result:
            return "zh"
        elif "english" in result:
            return "en"
        elif "japanese" in result or "æ—¥æœ¬" in result:
            return "ja"
        elif "korean" in result or "éŸ“" in result:
            return "ko"

        # é è¨­è¿”å›ä¸­æ–‡
        print(f"âš ï¸ èªè¨€è¾¨è­˜çµæœä¸æ˜ç¢º: {result}ï¼Œé è¨­ä½¿ç”¨ä¸­æ–‡")
        return "zh"

    except Exception as e:
        print(f"âš ï¸ èªè¨€è¾¨è­˜å¤±æ•—: {e}ï¼Œé è¨­ä½¿ç”¨ä¸­æ–‡")
        return "zh"


def get_punctuation_prompt(language: str, text: str) -> tuple[str, str]:
    """æ ¹æ“šèªè¨€ç”Ÿæˆé©ç•¶çš„æ¨™é»æç¤ºèª

    Args:
        language: èªè¨€ä»£ç¢¼ (zh/en/ja/ko/ç­‰)ï¼Œç”± Whisper è‡ªå‹•åµæ¸¬æˆ–ç”¨æˆ¶æŒ‡å®š
        text: è¦è™•ç†çš„æ–‡å­—

    Returns:
        (system_message, user_message) å…ƒçµ„
    """
    if language == "zh":
        system_msg = "ä½ æ˜¯åš´è¬¹çš„é€å­—ç¨¿æ½¤é£¾åŠ©æ‰‹ï¼Œåªåšæ¨™é»èˆ‡åˆ†æ®µã€‚"
        user_msg = (
            "è«‹å°‡ä»¥ä¸‹ã€ä¸­æ–‡é€å­—ç¨¿ã€åŠ ä¸Šé©ç•¶æ¨™é»ç¬¦è™Ÿä¸¦åˆç†åˆ†æ®µã€‚"
            "ä¸è¦çœç•¥æˆ–æ·»åŠ å…§å®¹ï¼Œä¸è¦æ„è­¯ï¼Œä¿ç•™å›ºæœ‰åè©èˆ‡æ•¸å­—ã€‚"
            f"è¼¸å‡ºç´”æ–‡å­—å³å¯ï¼š\n\n{text}"
        )
    elif language == "en":
        system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing."
        user_msg = (
            "Please add appropriate punctuation and paragraphing to the following English transcript. "
            "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers. "
            f"Output plain text only:\n\n{text}"
        )
    elif language == "ja":
        system_msg = "ã‚ãªãŸã¯æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—ç·¨é›†è€…ã§ã™ã€‚å¥èª­ç‚¹ã¨æ®µè½åˆ†ã‘ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚"
        user_msg = (
            "ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«é©åˆ‡ãªå¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
            "å†…å®¹ã®çœç•¥ã‚„è¿½åŠ ã¯ã›ãšã€æ„è¨³ã›ãšã€å›ºæœ‰åè©ã¨æ•°å­—ã¯ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚"
            f"ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n{text}"
        )
    elif language == "ko":
        system_msg = "ë‹¹ì‹ ì€ ì •í™•í•œ ì „ì‚¬ í¸ì§‘ìì…ë‹ˆë‹¤. êµ¬ë‘ì ê³¼ ë‹¨ë½ ë‚˜ëˆ„ê¸°ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤."
        user_msg = (
            "ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— ì ì ˆí•œ êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”. "
            "ë‚´ìš©ì„ ìƒëµí•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜ì—­í•˜ì§€ ë§ê³ , ê³ ìœ ëª…ì‚¬ì™€ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”. "
            f"ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\n\n{text}"
        )
    else:
        # å…¶ä»–èªè¨€ä½¿ç”¨è‹±æ–‡æç¤º
        system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing."
        user_msg = (
            f"Please add appropriate punctuation and paragraphing to the following transcript. "
            "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers. "
            f"Output plain text only:\n\n{text}"
        )

    return system_msg, user_msg


def punctuate_with_openai(text: str, language: str = "zh") -> str:
    """ç”¨ OpenAI å¹«é€å­—ç¨¿åŠ æ¨™é»èˆ‡åˆ†æ®µï¼ˆæ”¯æ´å¤šèªè¨€ï¼‰

    Args:
        text: è¦åŠ æ¨™é»çš„æ–‡å­—
        language: èªè¨€ä»£ç¢¼ (zh/en/ja/ko/auto)ï¼Œauto æœƒè‡ªå‹•è¾¨è­˜
    """
    from openai import OpenAI
    client = OpenAI()

    # ç²å–å°æ‡‰èªè¨€çš„æç¤ºèª
    system_msg, user_msg = get_punctuation_prompt(language, text)

    resp = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg},
        ],
        temperature=0.2,
    )
    return resp.choices[0].message.content.strip()


def call_gemini_with_retry(prompt: str, max_retries: int = None) -> str:
    """èª¿ç”¨ Gemini APIï¼Œæ”¯æ´è‡ªå‹•é‡è©¦å’Œ Key åˆ‡æ›ï¼Œé…é¡è€—ç›¡æ™‚è‡ªå‹•åˆ‡æ›åˆ°å¤šå±¤å‚™æ´æ¨¡å‹"""
    import google.generativeai as genai

    if max_retries is None:
        max_retries = len(GOOGLE_API_KEYS)

    last_error = None
    quota_exceeded_count = 0
    current_model = GEMINI_MODEL
    fallback_index = -1  # è¿½è¹¤ç•¶å‰ä½¿ç”¨çš„å‚™æ´æ¨¡å‹ç´¢å¼•
    tried_models = [GEMINI_MODEL]  # è¿½è¹¤å·²å˜—è©¦çš„æ¨¡å‹

    for attempt in range(max_retries * (len(GEMINI_FALLBACK_MODELS) + 1)):  # æ“´å¤§é‡è©¦æ¬¡æ•¸ä»¥æ”¯æ´å¤šå±¤å‚™æ´
        try:
            # ç²å–ä¸‹ä¸€å€‹ API Key
            api_key = get_next_google_api_key()
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(current_model)

            # èª¿ç”¨ API
            resp = model.generate_content(
                [{"role": "user", "parts": [prompt]}],
                generation_config={"temperature": 0.2}
            )

            result = (resp.text or "").strip()
            if fallback_index >= 0:
                print(f"âœ… ä½¿ç”¨å‚™æ´æ¨¡å‹ {current_model} æˆåŠŸ")
            return result

        except Exception as e:
            last_error = e
            error_msg = str(e)

            # æª¢æŸ¥æ˜¯å¦ç‚º 429 é…é¡éŒ¯èª¤
            is_quota_error = "429" in error_msg or "quota" in error_msg.lower() or "Quota exceeded" in error_msg

            if is_quota_error:
                quota_exceeded_count += 1
                print(f"âš ï¸ Google API Key é…é¡å·²ç”¨å®Œ (å˜—è©¦ {attempt + 1}ï¼Œæ¨¡å‹: {current_model})")

                # å¦‚æœæ‰€æœ‰ keys éƒ½é…é¡è€—ç›¡ï¼Œå˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å‚™æ´æ¨¡å‹
                if quota_exceeded_count >= len(GOOGLE_API_KEYS):
                    fallback_index += 1

                    if fallback_index < len(GEMINI_FALLBACK_MODELS):
                        current_model = GEMINI_FALLBACK_MODELS[fallback_index]
                        print(f"ğŸ’¡ æ‰€æœ‰ API Keys åœ¨ {tried_models[-1]} çš„é…é¡å·²ç”¨å®Œï¼Œåˆ‡æ›åˆ°å‚™ç”¨æ¨¡å‹ {current_model}")
                        tried_models.append(current_model)
                        quota_exceeded_count = 0  # é‡ç½®è¨ˆæ•¸ï¼Œç”¨æ–°å‚™æ´æ¨¡å‹å†è©¦ä¸€è¼ª
                        continue
                    else:
                        # æ‰€æœ‰å‚™æ´æ¨¡å‹éƒ½ç”¨å®Œäº†
                        print(f"âŒ æ‰€æœ‰æ¨¡å‹ï¼ˆ{', '.join(tried_models)}ï¼‰çš„é…é¡éƒ½å·²ç”¨å®Œ")
                        raise RuntimeError(f"æ‰€æœ‰ Google API Keys éƒ½èª¿ç”¨å¤±æ•—ã€‚å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}ã€‚æœ€å¾ŒéŒ¯èª¤: {error_msg}") from last_error
            else:
                print(f"âš ï¸ Google API Key èª¿ç”¨å¤±æ•— (å˜—è©¦ {attempt + 1}): {error_msg}")

            # å¦‚æœé‚„æœ‰ key å¯ç”¨ï¼Œç¹¼çºŒå˜—è©¦
            if attempt < max_retries * (len(GEMINI_FALLBACK_MODELS) + 1) - 1:
                print(f"ğŸ”„ åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ API Key...")
                continue
            else:
                print(f"âŒ æ‰€æœ‰ API Keys éƒ½å·²å˜—è©¦ï¼Œå¤±æ•—")
                raise RuntimeError(f"æ‰€æœ‰ Google API Keys éƒ½èª¿ç”¨å¤±æ•—ã€‚å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}ã€‚æœ€å¾ŒéŒ¯èª¤: {error_msg}") from last_error

    raise RuntimeError(f"ç„¡æ³•èª¿ç”¨ Gemini APIã€‚å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}") from last_error


def get_chunked_punctuation_prompt(language: str, chunk_text: str, chunk_idx: int, total_chunks: int) -> tuple[str, str]:
    """ç‚ºé•·æ–‡æœ¬åˆ†æ®µç”Ÿæˆæç¤ºèª

    Args:
        language: èªè¨€ä»£ç¢¼
        chunk_text: ç•¶å‰åˆ†æ®µæ–‡å­—
        chunk_idx: ç•¶å‰åˆ†æ®µç´¢å¼•ï¼ˆå¾1é–‹å§‹ï¼‰
        total_chunks: ç¸½åˆ†æ®µæ•¸

    Returns:
        (system_message, user_message) å…ƒçµ„
    """
    if language == "zh":
        system_msg = "ä½ æ˜¯åš´è¬¹çš„é€å­—ç¨¿æ½¤é£¾åŠ©æ‰‹ã€‚åªåšã€ä¸­æ–‡æ¨™é»è£œå…¨èˆ‡åˆç†åˆ†æ®µã€ï¼Œä¸è¦çœç•¥æˆ–æ·»åŠ å…§å®¹ï¼Œä¸è¦æ„è­¯ï¼Œéå¿…è¦ä¸è¦ç”¨åˆªç¯€è™Ÿï¼Œä¿ç•™å›ºæœ‰åè©èˆ‡æ•¸å­—ã€‚"
        if chunk_idx == 1:
            user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯ç¬¬ 1 æ®µï¼‰ï¼š\n\n{chunk_text}"
        elif chunk_idx == total_chunks:
            user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯æœ€å¾Œä¸€æ®µï¼Œæ¥çºŒå‰æ–‡ï¼‰ï¼š\n\n{chunk_text}"
        else:
            user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯ç¬¬ {chunk_idx} æ®µï¼Œæ¥çºŒå‰æ–‡ï¼‰ï¼š\n\n{chunk_text}"
    elif language == "en":
        system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing. Do not omit or add content, do not paraphrase, preserve proper nouns and numbers."
        if chunk_idx == 1:
            user_msg = f"Add punctuation and paragraphing to this English transcript (part 1):\n\n{chunk_text}"
        elif chunk_idx == total_chunks:
            user_msg = f"Add punctuation and paragraphing to this English transcript (final part, continuing from previous):\n\n{chunk_text}"
        else:
            user_msg = f"Add punctuation and paragraphing to this English transcript (part {chunk_idx}, continuing from previous):\n\n{chunk_text}"
    elif language == "ja":
        system_msg = "ã‚ãªãŸã¯æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—ç·¨é›†è€…ã§ã™ã€‚å¥èª­ç‚¹ã¨æ®µè½åˆ†ã‘ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚å†…å®¹ã®çœç•¥ã‚„è¿½åŠ ã¯ã›ãšã€æ„è¨³ã›ãšã€å›ºæœ‰åè©ã¨æ•°å­—ã¯ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚"
        if chunk_idx == 1:
            user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆç¬¬1éƒ¨åˆ†ï¼‰ï¼š\n\n{chunk_text}"
        elif chunk_idx == total_chunks:
            user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆæœ€å¾Œã®éƒ¨åˆ†ã€å‰ã®ç¶šãï¼‰ï¼š\n\n{chunk_text}"
        else:
            user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆç¬¬{chunk_idx}éƒ¨åˆ†ã€å‰ã®ç¶šãï¼‰ï¼š\n\n{chunk_text}"
    elif language == "ko":
        system_msg = "ë‹¹ì‹ ì€ ì •í™•í•œ ì „ì‚¬ í¸ì§‘ìì…ë‹ˆë‹¤. êµ¬ë‘ì ê³¼ ë‹¨ë½ ë‚˜ëˆ„ê¸°ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë‚´ìš©ì„ ìƒëµí•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜ì—­í•˜ì§€ ë§ê³ , ê³ ìœ ëª…ì‚¬ì™€ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”."
        if chunk_idx == 1:
            user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” (1ë¶€):\n\n{chunk_text}"
        elif chunk_idx == total_chunks:
            user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” (ë§ˆì§€ë§‰ ë¶€ë¶„, ì´ì „ ê³„ì†):\n\n{chunk_text}"
        else:
            user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” ({chunk_idx}ë¶€, ì´ì „ ê³„ì†):\n\n{chunk_text}"
    else:
        # å…¶ä»–èªè¨€ä½¿ç”¨è‹±æ–‡æç¤º
        system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing. Do not omit or add content, do not paraphrase, preserve proper nouns and numbers."
        if chunk_idx == 1:
            user_msg = f"Add punctuation and paragraphing to this transcript (part 1):\n\n{chunk_text}"
        elif chunk_idx == total_chunks:
            user_msg = f"Add punctuation and paragraphing to this transcript (final part, continuing from previous):\n\n{chunk_text}"
        else:
            user_msg = f"Add punctuation and paragraphing to this transcript (part {chunk_idx}, continuing from previous):\n\n{chunk_text}"

    return system_msg, user_msg


def punctuate_with_gemini(text: str, chunk_size: int = None, task_id: str = None, language: str = "zh") -> str:
    """ç”¨ Google Gemini å¹«é€å­—ç¨¿åŠ æ¨™é»èˆ‡åˆ†æ®µï¼ˆæ”¯æ´é•·æ–‡æœ¬åˆ†æ®µè™•ç†ã€å¤šèªè¨€ï¼‰

    Args:
        text: è¦åŠ æ¨™é»çš„æ–‡å­—
        chunk_size: åˆ†æ®µå¤§å°ï¼ˆå­—å…ƒæ•¸ï¼‰ï¼ŒNone å‰‡æ ¹æ“šèªè¨€è‡ªå‹•æ±ºå®š
        task_id: ä»»å‹™ IDï¼ˆç”¨æ–¼æ›´æ–°é€²åº¦ï¼‰
        language: èªè¨€ä»£ç¢¼ (zh/en/ja/ko/ç­‰)ï¼Œç”± Whisper è‡ªå‹•åµæ¸¬æˆ–ç”¨æˆ¶æŒ‡å®š
    """
    if not GOOGLE_API_KEYS:
        raise RuntimeError("æœªè¨­å®šä»»ä½• GOOGLE_API_KEY")

    # æ ¹æ“šèªè¨€æ±ºå®šåˆé©çš„åˆ†æ®µå¤§å°
    if chunk_size is None:
        if language in ['en', 'es', 'fr', 'de', 'it', 'pt']:
            # è‹±æ–‡ç­‰å­—æ¯èªè¨€ï¼šä½¿ç”¨è¼ƒå¤§çš„å­—å…ƒæ•¸ï¼ˆå› ç‚ºå–®è©åŒ…å«ç©ºæ ¼ï¼Œå­—å…ƒæ•¸è¼ƒå¤šï¼‰
            chunk_size = 8000  # ç´„ 1300-1600 å€‹è‹±æ–‡å–®è©
        else:
            # ä¸­æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ç­‰ï¼šä½¿ç”¨æ¨™æº–å­—å…ƒæ•¸
            chunk_size = 3000  # ç´„ 3000 å€‹å­—ç¬¦
        print(f"ğŸ“ æ ¹æ“šèªè¨€ '{language}' è¨­å®šåˆ†æ®µå¤§å°ï¼š{chunk_size} å­—å…ƒ")

    # å¦‚æœæ–‡æœ¬ä¸é•·ï¼Œç›´æ¥è™•ç†
    if len(text) <= chunk_size:
        system_msg, user_msg = get_punctuation_prompt(language, text)
        prompt = system_msg + "\n\n" + user_msg
        return call_gemini_with_retry(prompt)

    # é•·æ–‡æœ¬ï¼šåˆ†æ®µè™•ç†
    print(f"ğŸ“Š æ–‡æœ¬é•·åº¦ {len(text)} å­—ï¼Œå°‡åˆ†æ®µè™•ç†ï¼ˆæ¯æ®µç´„ {chunk_size} å­—ï¼‰...")
    chunks = []
    start = 0

    # æ ¹æ“šèªè¨€é¸æ“‡åˆ†æ®µæ¨™è¨˜
    split_markers = 'ã€‚ï¼Ÿï¼\n' if language in ['zh', 'ja'] else '.?!\n'

    while start < len(text):
        end = start + chunk_size
        if end < len(text):
            for i in range(end, max(start + chunk_size // 2, end - 200), -1):
                if text[i] in split_markers:
                    end = i + 1
                    break
        chunks.append(text[start:end])
        start = end

    print(f"ğŸ”„ å…±åˆ†ç‚º {len(chunks)} æ®µè™•ç†...")

    # è¨˜éŒ„æ¨™é»åˆ†æ®µç¸½æ•¸
    if task_id:
        update_task_status(task_id, {
            "punctuation_total_chunks": len(chunks),
            "punctuation_current_chunk": 0
        })

    results = []

    for idx, chunk in enumerate(chunks, 1):
        print(f"   è™•ç†ç¬¬ {idx}/{len(chunks)} æ®µ...")

        # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if task_id and task_cancelled.get(task_id, False):
            raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

        # æ›´æ–°ä»»å‹™é€²åº¦ï¼ˆé¡¯ç¤ºç•¶å‰æ¨™é»è™•ç†æ®µæ•¸ï¼‰
        if task_id:
            update_task_status(task_id, {
                "punctuation_current_chunk": idx,
                "progress": f"æ­£åœ¨æ·»åŠ æ¨™é»ç¬¦è™Ÿ... (ç¬¬ {idx}/{len(chunks)} æ®µ)"
            })

        # ä½¿ç”¨èªè¨€æ„ŸçŸ¥çš„æç¤ºèª
        system_msg, user_msg = get_chunked_punctuation_prompt(language, chunk, idx, len(chunks))

        prompt = system_msg + "\n\n" + user_msg
        result = call_gemini_with_retry(prompt)
        results.append(result)

    print("âœ… æ‰€æœ‰æ®µè½è™•ç†å®Œæˆï¼Œæ­£åœ¨åˆä½µ...")
    return "\n\n".join(results)


def cleanup_old_audio_files(current_task_id: str):
    """æ¸…ç†èˆŠçš„éŸ³æª”ï¼Œä¿ç•™è¦å‰‡ï¼š
    1. æœ€æ–°çš„ä»»å‹™ï¼ˆcurrent_task_idï¼‰å§‹çµ‚ä¿ç•™
    2. ç”¨æˆ¶å‹¾é¸çš„ä»»å‹™ï¼ˆkeep_audio=Trueï¼‰æ°¸é ä¿ç•™ï¼ˆæœ€å¤š 3 å€‹ï¼‰
    3. ç³»çµ±æœ€å¤šä¿ç•™ 4 å€‹éŸ³æª”
    4. è¶…é 4 å€‹æ™‚ï¼Œå¾æ²’æœ‰å‹¾é¸çš„ä»»å‹™ä¸­ï¼ŒæŒ‰å®Œæˆæ™‚é–“å¾æœ€èˆŠçš„é–‹å§‹åˆªé™¤

    Args:
        current_task_id: ç•¶å‰æœ€æ–°ä»»å‹™çš„ ID

    Note:
        å¿…é ˆåœ¨ä»»å‹™ç‹€æ…‹æ›´æ–°ï¼ˆè¨­å®š audio_fileï¼‰ä¹‹å¾Œèª¿ç”¨
    """
    try:
        print(f"ğŸ§¹ é–‹å§‹æ¸…ç†èˆŠéŸ³æª”...")

        # æ”¶é›†æ‰€æœ‰å·²å®Œæˆä¸”æœ‰éŸ³æª”çš„ä»»å‹™
        tasks_with_audio = []

        with tasks_lock:
            for tid, task in transcription_tasks.items():
                if task.get("status") == "completed" and task.get("audio_file"):
                    audio_path = Path(task.get("audio_file"))
                    completed_at = task.get("completed_at", "")
                    keep_audio = task.get("keep_audio", False)

                    tasks_with_audio.append({
                        "task_id": tid,
                        "audio_file": audio_path,
                        "completed_at": completed_at,
                        "keep_audio": keep_audio,
                        "is_current": tid == current_task_id
                    })

        # æ±ºå®šå“ªäº›éŸ³æª”è¦ä¿ç•™
        files_to_keep = set()

        # 1. æœ€æ–°çš„ä»»å‹™å§‹çµ‚ä¿ç•™
        if current_task_id:
            files_to_keep.add(current_task_id)
            print(f"   âœ“ ä¿ç•™æœ€æ–°ä»»å‹™éŸ³æª”ï¼š{current_task_id[:8]}...")

        # 2. ç”¨æˆ¶å‹¾é¸ä¿ç•™çš„ä»»å‹™ï¼ˆkeep_audio=Trueï¼‰æ°¸é ä¿ç•™
        keep_audio_tasks = [t for t in tasks_with_audio if t["keep_audio"]]
        for idx, task in enumerate(keep_audio_tasks):
            files_to_keep.add(task["task_id"])
            print(f"   âœ“ ä¿ç•™ç”¨æˆ¶å‹¾é¸éŸ³æª” #{idx+1}ï¼š{task['audio_file'].name}")

        # 3. å¦‚æœä¿ç•™çš„æª”æ¡ˆè¶…é 4 å€‹ï¼Œéœ€è¦å¾æ²’æœ‰å‹¾é¸çš„ä»»å‹™ä¸­åˆªé™¤æœ€èˆŠçš„
        # ç³»çµ±æœ€å¤šä¿ç•™ 4 å€‹éŸ³æª”
        MAX_AUDIO_FILES = 4

        if len(files_to_keep) >= MAX_AUDIO_FILES:
            # å·²ç¶“é”åˆ°æˆ–è¶…éä¸Šé™ï¼Œä¸éœ€è¦é¡å¤–ä¿ç•™
            print(f"   ç•¶å‰å·²ä¿ç•™ {len(files_to_keep)} å€‹éŸ³æª”ï¼ˆé”åˆ°ä¸Šé™ï¼‰")
        else:
            # é‚„æœ‰ç©ºé–“ï¼Œå¯ä»¥ä¿ç•™ä¸€äº›æœªå‹¾é¸çš„ä»»å‹™
            # å¾æœªå‹¾é¸çš„ä»»å‹™ä¸­ï¼ŒæŒ‰å®Œæˆæ™‚é–“æ’åºï¼Œä¿ç•™æœ€æ–°çš„
            uncheckd_tasks = [t for t in tasks_with_audio if not t["keep_audio"] and t["task_id"] not in files_to_keep]
            uncheckd_tasks.sort(key=lambda x: x["completed_at"], reverse=True)

            slots_remaining = MAX_AUDIO_FILES - len(files_to_keep)
            for idx, task in enumerate(uncheckd_tasks[:slots_remaining]):
                files_to_keep.add(task["task_id"])
                print(f"   âœ“ ä¿ç•™æœªå‹¾é¸ä»»å‹™ #{idx+1}ï¼š{task['audio_file'].name}")

        # 4. æ¨™è¨˜è¦åˆªé™¤çš„éŸ³æª”ï¼ˆæ‰€æœ‰ä¸åœ¨ä¿ç•™æ¸…å–®ä¸­çš„ï¼‰
        files_to_delete = []
        tasks_to_update = []

        for item in tasks_with_audio:
            if item["task_id"] not in files_to_keep:
                files_to_delete.append(item["audio_file"])
                tasks_to_update.append(item["task_id"])

        if not files_to_delete:
            print(f"   ç„¡éœ€æ¸…ç†ï¼Œç•¶å‰ä¿ç•™ {len(files_to_keep)} å€‹éŸ³æª”")
            return

        # 4. åˆªé™¤èˆŠéŸ³æª”
        deleted_count = 0
        for audio_file in files_to_delete:
            try:
                if audio_file.exists():
                    audio_file.unlink()
                    print(f"   ğŸ—‘ï¸ å·²åˆªé™¤èˆŠéŸ³æª”ï¼š{audio_file.name}")
                    deleted_count += 1
            except Exception as e:
                print(f"   âš ï¸ åˆªé™¤éŸ³æª”å¤±æ•— {audio_file.name}ï¼š{e}")

        # 5. æ›´æ–°ä»»å‹™è¨˜éŒ„ï¼Œæ¸…é™¤å·²åˆªé™¤éŸ³æª”çš„å¼•ç”¨
        if tasks_to_update:
            with tasks_lock:
                for tid in tasks_to_update:
                    if tid in transcription_tasks:
                        transcription_tasks[tid]["audio_file"] = None
                        transcription_tasks[tid]["audio_filename"] = None
                        transcription_tasks[tid]["keep_audio"] = False  # æ¸…é™¤ä¿ç•™æ¨™è¨˜
                        transcription_tasks[tid]["updated_at"] = get_current_time()

            # ä¿å­˜æ›´æ–°åˆ°ç£ç¢Ÿ
            save_tasks_to_disk()

        print(f"âœ… æ¸…ç†å®Œæˆï¼šåˆªé™¤äº† {deleted_count} å€‹èˆŠéŸ³æª”ï¼Œä¿ç•™ {len(files_to_keep)} å€‹")

    except Exception as e:
        print(f"âš ï¸ æ¸…ç†èˆŠéŸ³æª”å¤±æ•—ï¼š{e}")
        # æ¸…ç†å¤±æ•—ä¸æ‡‰è©²å½±éŸ¿ä¸»æµç¨‹ï¼Œæ‰€ä»¥ä¸æ‹‹å‡ºç•°å¸¸


def process_transcription_task(
    task_id: str,
    temp_audio_path: Path,
    filename: str,
    punct_provider: str,
    chunk_audio: bool,
    chunk_minutes: int,
    diarize: bool = False,
    max_speakers: Optional[int] = None,
    language: str = "zh"
):
    """
    åœ¨èƒŒæ™¯ç·šç¨‹ä¸­åŸ·è¡Œè½‰éŒ„ä»»å‹™
    é€™å€‹å‡½æ•¸æœƒæ›´æ–°ä»»å‹™ç‹€æ…‹ï¼Œä¸¦è™•ç†æ‰€æœ‰è½‰éŒ„é‚è¼¯

    æ³¨æ„ï¼šdiarization åƒ…åœ¨éåˆ†æ®µæ¨¡å¼ä¸‹å¯ç”¨ï¼Œåˆ†æ®µæ¨¡å¼æœƒå¿½ç•¥æ­¤åƒæ•¸
    max_speakers: æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼‰
    """
    # å°‡ 'auto' è½‰æ›ç‚º Noneï¼Œè®“ Whisper è‡ªå‹•åµæ¸¬èªè¨€
    whisper_language = None if language == "auto" else language

    temp_dir = temp_audio_path.parent

    # ä¿å­˜éŸ³æª”åˆ° output ç›®éŒ„ï¼ˆä¿ç•™è½‰æ›å¾Œçš„ WAV æ ¼å¼ä»¥ç¢ºä¿ç€è¦½å™¨ç›¸å®¹æ€§ï¼‰
    audio_filename = f"{Path(filename).stem}_{task_id}.wav"
    permanent_audio_path = OUTPUT_DIR / audio_filename

    try:
        # è¨˜éŒ„æš«å­˜ç›®éŒ„
        with tasks_lock:
            task_temp_dirs[task_id] = temp_dir

        # è¨˜éŒ„é–‹å§‹è™•ç†æ™‚é–“
        start_time = datetime.now(TZ_UTC8)

        # æ›´æ–°ç‹€æ…‹ï¼šè™•ç†ä¸­
        update_task_status(task_id, {
            "status": "processing",
            "progress": "æ­£åœ¨è½‰æ›éŸ³è¨Šæ ¼å¼...",
            "started_at": start_time.strftime("%Y-%m-%d %H:%M:%S")
        })

        # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if task_cancelled.get(task_id, False):
            raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

        # è½‰æ›ç‚º WAV
        wav_path = temp_dir / "input.wav"
        print(f"ğŸ”„ [{task_id}] è½‰æª”ç‚º WAV...")
        try:
            # æ˜ç¢ºæŒ‡å®šä½¿ç”¨ ffmpeg ä½œç‚ºè½‰æª”å·¥å…·
            audio = AudioSegment.from_file(str(temp_audio_path))
            audio.export(str(wav_path), format="wav")
        except Exception as e:
            import traceback
            print(f"âŒ [{task_id}] éŸ³è¨Šè½‰æª”å¤±æ•—ï¼š{e}")
            print(f"è©³ç´°éŒ¯èª¤ï¼š\n{traceback.format_exc()}")
            raise

        # æ¨™è¨˜éŸ³è¨Šè½‰æª”å®Œæˆ
        update_task_status(task_id, {
            "audio_converted": True,
            "progress": "éŸ³è¨Šè½‰æª”å®Œæˆï¼Œæº–å‚™è½‰éŒ„..."
        })

        # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if task_cancelled.get(task_id, False):
            raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

        # åŸ·è¡Œè½‰éŒ„
        update_task_status(task_id, {"progress": "æ­£åœ¨è½‰éŒ„éŸ³è¨Š..."})

        all_segments = []  # ç”¨æ–¼å„²å­˜æ‰€æœ‰ segments
        detected_language = None  # ç”¨æ–¼å„²å­˜ Whisper åµæ¸¬åˆ°çš„èªè¨€

        if chunk_audio:
            # åˆ†æ®µæ¨¡å¼ï¼šç¾åœ¨æ”¯æ´ diarizationï¼ˆå…ˆå°å®Œæ•´éŸ³æª”åšèªªè©±è€…è¾¨è­˜ï¼Œå†åˆ†æ®µè½‰éŒ„ï¼‰
            chunk_duration_ms = chunk_minutes * 60 * 1000
            raw_text, all_segments, detected_language = transcribe_audio_in_chunks(
                wav_path,
                whisper_model,
                chunk_duration_ms,
                task_id=task_id,
                diarize=diarize,
                max_speakers=max_speakers,
                language=whisper_language
            )
        else:
            # éåˆ†æ®µæ¨¡å¼ï¼šå¯ä»¥ä½¿ç”¨ diarization
            if diarize and diarization_pipeline:
                print(f"ğŸ”Š [{task_id}] å•Ÿç”¨ speaker diarization...")

                # åŸ·è¡Œ speaker diarization
                diarization_start = datetime.now(TZ_UTC8)
                update_task_status(task_id, {
                    "progress": "æ­£åœ¨åˆ†æèªªè©±è€…...",
                    "diarization_status": "running"
                })
                diarization_segments = perform_diarization(wav_path, max_speakers=max_speakers)
                diarization_duration = (datetime.now(TZ_UTC8) - diarization_start).total_seconds()

                # åŸ·è¡Œè½‰éŒ„ï¼ˆå¸¶æ™‚é–“æˆ³ï¼‰
                update_task_status(task_id, {"progress": "æ­£åœ¨è½‰éŒ„éŸ³è¨Šï¼ˆå¸¶æ™‚é–“æˆ³ï¼‰..."})
                transcription_segments, detected_language = transcribe_with_timestamps(whisper_model, wav_path, language=whisper_language)
                all_segments = transcription_segments  # ä¿å­˜ segments

                # åˆä½µçµæœ
                if diarization_segments:
                    num_speakers = len(set(s['speaker'] for s in diarization_segments))
                    update_task_status(task_id, {
                        "progress": "æ­£åœ¨åˆä½µèªªè©±è€…è³‡è¨Š...",
                        "diarization_status": "completed",
                        "diarization_num_speakers": num_speakers,
                        "diarization_duration_seconds": round(diarization_duration, 1)
                    })
                    raw_text = merge_transcription_with_diarization(
                        transcription_segments,
                        diarization_segments
                    )
                else:
                    # diarization å¤±æ•—ï¼Œå›é€€åˆ°ç´”æ–‡å­—
                    update_task_status(task_id, {
                        "diarization_status": "failed"
                    })
                    raw_text = " ".join(seg["text"] for seg in transcription_segments)
            else:
                print(f"ğŸ“ [{task_id}] é–‹å§‹è½‰é€å­—ç¨¿...")
                raw_text, all_segments, detected_language = transcribe_single_chunk(whisper_model, wav_path, language=whisper_language)

        # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if task_cancelled.get(task_id, False):
            raise RuntimeError("ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")

        print(f"âœ… [{task_id}] è½‰éŒ„å®Œæˆï¼ˆ{len(raw_text)} å­—ï¼‰")

        # æ±ºå®šä½¿ç”¨å“ªå€‹èªè¨€é€²è¡Œæ¨™é»è™•ç†
        # å¦‚æœç”¨æˆ¶é¸æ“‡ autoï¼Œä½¿ç”¨ Whisper åµæ¸¬çš„èªè¨€ï¼›å¦å‰‡ä½¿ç”¨ç”¨æˆ¶æŒ‡å®šçš„èªè¨€
        punct_language = detected_language if language == "auto" and detected_language else language
        if detected_language and language == "auto":
            print(f"ğŸ” [{task_id}] Whisper åµæ¸¬åˆ°çš„èªè¨€ï¼š{detected_language}")

        # åŠ æ¨™é»
        final_text = raw_text
        if punct_provider == "gemini":
            try:
                update_task_status(task_id, {
                    "punctuation_started": True,
                    "progress": "æ­£åœ¨æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼ˆGeminiï¼‰..."
                })
                print(f"âœ¨ [{task_id}] ä½¿ç”¨ Gemini åŠ æ¨™é»èˆ‡åˆ†æ®µï¼ˆèªè¨€ï¼š{punct_language}ï¼‰...")
                final_text = punctuate_with_gemini(raw_text, task_id=task_id, language=punct_language)
                update_task_status(task_id, {"punctuation_completed": True})
            except Exception as e:
                print(f"âš ï¸ [{task_id}] Gemini åŠ æ¨™é»å¤±æ•—ï¼š{e}")
                print(f"ğŸ“ [{task_id}] å°‡ä½¿ç”¨ Whisper åŸå§‹è½‰éŒ„çµæœ")
                update_task_status(task_id, {
                    "punctuation_completed": False,
                    "punctuation_error": str(e),
                    "progress": "æ¨™é»ç¬¦è™Ÿæ·»åŠ å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è½‰éŒ„çµæœ"
                })
        elif punct_provider == "openai":
            try:
                update_task_status(task_id, {
                    "punctuation_started": True,
                    "progress": "æ­£åœ¨æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼ˆOpenAIï¼‰..."
                })
                if not os.getenv("OPENAI_API_KEY"):
                    raise ValueError("æœªè¨­å®š OPENAI_API_KEY")
                print(f"âœ¨ [{task_id}] ä½¿ç”¨ OpenAI åŠ æ¨™é»èˆ‡åˆ†æ®µï¼ˆèªè¨€ï¼š{punct_language}ï¼‰...")
                final_text = punctuate_with_openai(raw_text, language=punct_language)
                update_task_status(task_id, {"punctuation_completed": True})
            except Exception as e:
                print(f"âš ï¸ [{task_id}] OpenAI åŠ æ¨™é»å¤±æ•—ï¼š{e}")
                print(f"ğŸ“ [{task_id}] å°‡ä½¿ç”¨ Whisper åŸå§‹è½‰éŒ„çµæœ")
                update_task_status(task_id, {
                    "punctuation_completed": False,
                    "punctuation_error": str(e),
                    "progress": "æ¨™é»ç¬¦è™Ÿæ·»åŠ å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è½‰éŒ„çµæœ"
                })

        print(f"ğŸ‰ [{task_id}] è™•ç†å®Œæˆï¼")

        # ä¿å­˜æ–‡å­—æª”åˆ° output/ ç›®éŒ„
        update_task_status(task_id, {"progress": "æ­£åœ¨ä¿å­˜çµæœ..."})
        timestamp = datetime.now(TZ_UTC8).strftime("%Y%m%d_%H%M%S")
        safe_filename = Path(filename).stem.replace(" ", "_")
        output_filename = f"{safe_filename}_{timestamp}_transcript.txt"
        permanent_output = OUTPUT_DIR / output_filename
        permanent_output.write_text(final_text, encoding="utf-8")
        print(f"ğŸ’¾ [{task_id}] æ–‡å­—æª”å·²ä¿å­˜ï¼š{permanent_output.relative_to(OUTPUT_DIR.parent)}")

        # ä¿å­˜ segments åˆ° JSON æª”æ¡ˆ
        segments_filename = f"{safe_filename}_{timestamp}_segments.json"
        segments_output = OUTPUT_DIR / segments_filename
        segments_output.write_text(json.dumps(all_segments, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"ğŸ“Š [{task_id}] Segments å·²ä¿å­˜ï¼š{segments_output.relative_to(OUTPUT_DIR.parent)}")

        # è¤‡è£½ WAV éŸ³æª”åˆ° output ç›®éŒ„ï¼ˆä¿ç•™ä»¥ä¾›æ’­æ”¾ï¼ŒWAV æ ¼å¼åœ¨ç€è¦½å™¨ä¸­æœ‰æœ€ä½³ç›¸å®¹æ€§ï¼‰
        import shutil
        shutil.copy2(wav_path, permanent_audio_path)
        print(f"ğŸµ [{task_id}] éŸ³æª”å·²ä¿å­˜ï¼ˆWAV æ ¼å¼ï¼‰ï¼š{permanent_audio_path.relative_to(OUTPUT_DIR.parent)}")

        # è¨ˆç®—ç¸½è™•ç†æ™‚é–“
        end_time = datetime.now(TZ_UTC8)
        duration_seconds = (end_time - start_time).total_seconds()

        # æ›´æ–°ç‹€æ…‹ï¼šå®Œæˆ
        update_task_status(task_id, {
            "status": "completed",
            "progress": "è½‰éŒ„å®Œæˆ",
            "result_file": str(permanent_output),
            "result_filename": output_filename,
            "segments_file": str(segments_output),
            "segments_filename": segments_filename,
            "audio_file": str(permanent_audio_path),
            "audio_filename": audio_filename,
            "text_length": len(final_text),
            "completed_at": get_current_time(),
            "duration_seconds": round(duration_seconds, 1)
        })

        # æ¸…ç†èˆŠçš„éŸ³æª”ï¼ˆåªä¿ç•™æœ€æ–°çš„ 3 å€‹ï¼‰
        # å¿…é ˆåœ¨ update_task_status ä¹‹å¾Œï¼Œé€™æ¨£ç•¶å‰ä»»å‹™çš„éŸ³æª”æ‰æœƒè¢«è¨ˆå…¥
        cleanup_old_audio_files(task_id)

        print(f"â±ï¸ [{task_id}] ç¸½è™•ç†æ™‚é–“ï¼š{format_duration(duration_seconds)}")

    except Exception as e:
        # æª¢æŸ¥æ˜¯å¦ç‚ºå–æ¶ˆæ“ä½œ
        is_cancelled = "å–æ¶ˆ" in str(e)

        if is_cancelled:
            print(f"ğŸ›‘ [{task_id}] ä»»å‹™å·²è¢«ä½¿ç”¨è€…å–æ¶ˆ")
            update_task_status(task_id, {
                "status": "cancelled",
                "progress": "ä»»å‹™å·²å–æ¶ˆ",
                "error": "ä½¿ç”¨è€…å–æ¶ˆäº†ä»»å‹™"
            })
        else:
            # æ›´æ–°ç‹€æ…‹ï¼šå¤±æ•—
            print(f"âŒ [{task_id}] éŒ¯èª¤ï¼š{e}")
            update_task_status(task_id, {
                "status": "failed",
                "progress": f"éŒ¯èª¤ï¼š{str(e)}",
                "error": str(e)
            })

    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        cleanup_temp_dir(temp_dir)

        # æ¸…ç†ä»»å‹™ç›¸é—œè¨˜éŒ„
        with tasks_lock:
            task_temp_dirs.pop(task_id, None)
            task_cancelled.pop(task_id, None)
            task_diarization_processes.pop(task_id, None)


# ---------- API Endpoints ----------

@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚è¼‰å…¥ Whisper æ¨¡å‹å’Œä»»å‹™è¨˜éŒ„"""
    global whisper_model, current_model_name

    # é€£æ¥ MongoDB
    print(f"ğŸ”Œ æ­£åœ¨é€£æ¥ MongoDB...")
    try:
        await MongoDB.connect()
    except Exception as e:
        print(f"âš ï¸  MongoDB é€£æ¥å¤±æ•—ï¼ˆå°‡ç¹¼çºŒä½¿ç”¨ JSON æª”æ¡ˆï¼‰: {e}")

    # è¼‰å…¥ä»»å‹™è¨˜éŒ„
    print(f"ğŸ“‚ æ­£åœ¨è¼‰å…¥ä»»å‹™è¨˜éŒ„...")
    load_tasks_from_disk()

    # è¼‰å…¥ Faster-Whisper æ¨¡å‹
    current_model_name = DEFAULT_MODEL
    print(f"ğŸ™ æ­£åœ¨è¼‰å…¥ Faster-Whisper æ¨¡å‹ï¼š{current_model_name}...")
    print(f"ğŸ”§ é…ç½®ï¼šdevice=auto, compute_type=int8ï¼ˆé‡å° M1 å„ªåŒ–ï¼‰")
    whisper_model = WhisperModel(
        current_model_name,
        device="auto",  # è‡ªå‹•é¸æ“‡ CPU
        compute_type="int8",  # ä½¿ç”¨ INT8 é‡åŒ–ï¼Œç¯€çœè¨˜æ†¶é«”ä¸¦æå‡é€Ÿåº¦
        cpu_threads=1,  # æ¯å€‹æ¨ç†ä»»å‹™ç”¨ 1 ç·šç¨‹ï¼ˆé¿å…èˆ‡ diarization ç«¶çˆ­ï¼‰
        num_workers=4  # å…è¨± 4 å€‹ä»»å‹™åŒæ™‚æ¨ç†
    )
    print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œæœå‹™å·²å°±ç·’ï¼")

    # è¼‰å…¥ Speaker Diarization æ¨¡å‹ï¼ˆå¯é¸ï¼‰
    global diarization_pipeline
    diarization_pipeline = None

    if DIARIZATION_AVAILABLE:
        hf_token = os.getenv("HF_TOKEN")
        if hf_token:
            try:
                # ä½¿ç”¨ huggingface_hub ç™»å…¥
                from huggingface_hub import login
                login(token=hf_token, add_to_git_credential=False)

                print("ğŸ”Š æ­£åœ¨è¼‰å…¥ Speaker Diarization æ¨¡å‹...")
                import torch
                diarization_pipeline = Pipeline.from_pretrained(
                    "pyannote/speaker-diarization-3.1"
                )

                # M1 Mac MPS åŠ é€Ÿ
                if torch.backends.mps.is_available():
                    diarization_pipeline.to(torch.device("mps"))
                    print("âœ… Speaker Diarization æ¨¡å‹è¼‰å…¥å®Œæˆï¼ˆä½¿ç”¨ MPS åŠ é€Ÿï¼‰ï¼")
                else:
                    print("âœ… Speaker Diarization æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
            except Exception as e:
                print(f"âš ï¸  Speaker Diarization æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e}")
                print("   è«‹ç¢ºèªå·²åœ¨ Hugging Face åŒæ„ä½¿ç”¨æ¢æ¬¾ï¼šhttps://huggingface.co/pyannote/speaker-diarization-3.1")
        else:
            print("â„¹ï¸  æœªè¨­å®š HF_TOKENï¼Œspeaker diarization åŠŸèƒ½ä¸å¯ç”¨")
            print("   å¦‚éœ€ä½¿ç”¨ï¼Œè«‹ï¼š")
            print("   1. è¨ªå• https://huggingface.co/settings/tokens")
            print("   2. å‰µå»º access token")
            print("   3. åœ¨ .env æ·»åŠ ï¼šHF_TOKEN=your_token_here")


@app.on_event("shutdown")
async def shutdown_event():
    """é—œé–‰æ™‚æ–·é–‹ MongoDB é€£æ¥"""
    print(f"ğŸ”Œ æ­£åœ¨é—œé–‰ MongoDB é€£æ¥...")
    await MongoDB.close()


@app.get("/")
async def root():
    """æœå‹™ç‹€æ…‹"""
    with tasks_lock:
        active_count = sum(1 for t in transcription_tasks.values() if t["status"] in ["pending", "processing"])

    return {
        "service": "Whisper è½‰éŒ„æœå‹™",
        "version": "2.0.0",
        "status": "running",
        "model": current_model_name,
        "output_dir": str(OUTPUT_DIR.relative_to(OUTPUT_DIR.parent)),
        "concurrent_limit": executor._max_workers,
        "active_transcriptions": active_count,
        "endpoints": {
            "POST /transcribe": "ä¸Šå‚³éŸ³æª”é€²è¡Œè½‰éŒ„ï¼ˆç•°æ­¥ï¼Œç«‹å³è¿”å› task_idï¼‰",
            "GET /transcribe/{task_id}": "æŸ¥è©¢ä»»å‹™ç‹€æ…‹",
            "GET /transcribe/{task_id}/download": "ä¸‹è¼‰è½‰éŒ„çµæœ",
            "GET /transcribe/active/list": "åˆ—å‡ºæ‰€æœ‰ä»»å‹™ï¼ˆå«é€²è¡Œä¸­ï¼‰",
            "GET /transcripts": "åˆ—å‡ºå·²ä¿å­˜çš„æ–‡å­—æª”",
            "GET /health": "å¥åº·æª¢æŸ¥",
            "GET /docs": "Swagger API æ–‡æª”"
        }
    }


@app.post("/transcribe")
async def transcribe(
    file: UploadFile = File(..., description="éŸ³æª” (æ”¯æ´ mp3/m4a/wav/mp4 ç­‰æ ¼å¼)"),
    punct_provider: str = Form("gemini", description="æ¨™é»æä¾›è€… (openai/gemini/none)"),
    chunk_audio: bool = Form(True, description="æ˜¯å¦ä½¿ç”¨åˆ†æ®µæ¨¡å¼"),
    chunk_minutes: int = Form(10, description="åˆ†æ®µé•·åº¦ï¼ˆåˆ†é˜ï¼‰"),
    diarize: bool = Form(False, description="æ˜¯å¦å•Ÿç”¨èªªè©±è€…è¾¨è­˜"),
    max_speakers: Optional[int] = Form(None, description="æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼‰"),
    language: str = Form("zh", description="è½‰éŒ„èªè¨€ (zh/en/ja/ko/auto)"),
    tags: Optional[str] = Form(None, description="æ¨™ç±¤ï¼ˆJSON é™£åˆ—å­—ä¸²ï¼Œå¦‚ '[\"ç’°å®‡å°ˆæ¡ˆ\",\"2025\"]'ï¼‰")
):
    """
    ä¸Šå‚³éŸ³æª”é€²è¡Œè½‰éŒ„ï¼ˆç•°æ­¥æ¨¡å¼ï¼‰

    ç«‹å³è¿”å›ä»»å‹™ IDï¼Œè½‰éŒ„åœ¨èƒŒæ™¯åŸ·è¡Œ
    ä½¿ç”¨ GET /transcribe/{task_id} æŸ¥è©¢ç‹€æ…‹
    ä½¿ç”¨ GET /transcribe/{task_id}/download ä¸‹è¼‰çµæœ

    - **file**: éŸ³æª”æª”æ¡ˆ
    - **punct_provider**: æ¨™é»æä¾›è€… (openai/gemini/none)
    - **chunk_audio**: æ˜¯å¦ä½¿ç”¨åˆ†æ®µæ¨¡å¼ï¼ˆé•·éŸ³æª”å»ºè­°é–‹å•Ÿï¼‰
    - **chunk_minutes**: åˆ†æ®µé•·åº¦ï¼ˆåˆ†é˜ï¼‰
    - **diarize**: æ˜¯å¦å•Ÿç”¨èªªè©±è€…è¾¨è­˜ï¼ˆspeaker diarizationï¼‰
    - **max_speakers**: æœ€å¤§è¬›è€…äººæ•¸ï¼ˆå¯é¸ï¼Œ2-10ï¼Œç•™ç©ºå‰‡è‡ªå‹•åµæ¸¬ï¼‰
    """
    global whisper_model

    if not whisper_model:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªè¼‰å…¥å®Œæˆ")

    # ç”Ÿæˆä»»å‹™ ID
    task_id = str(uuid.uuid4())

    # å»ºç«‹è‡¨æ™‚ç›®éŒ„ä¸¦ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
    temp_dir = Path(tempfile.mkdtemp())
    file_suffix = Path(file.filename).suffix
    temp_audio = temp_dir / f"input{file_suffix}"

    try:
        with temp_audio.open("wb") as f:
            content = await file.read()
            f.write(content)

        print(f"ğŸ“ æ”¶åˆ°æª”æ¡ˆï¼š{file.filename} ({len(content) / 1024 / 1024:.2f} MB)")

        # æª¢æŸ¥ diarization å¯ç”¨æ€§
        if diarize and not diarization_pipeline:
            raise HTTPException(
                status_code=400,
                detail="Speaker diarization åŠŸèƒ½æœªå•Ÿç”¨ã€‚è«‹è¨­å®š HF_TOKEN ç’°å¢ƒè®Šæ•¸ä¸¦é‡å•Ÿæœå‹™ã€‚"
            )

        # è§£ææ¨™ç±¤ï¼ˆå¦‚æœæœ‰æä¾›ï¼‰
        task_tags = []
        if tags:
            try:
                import json
                task_tags = json.loads(tags)
            except:
                task_tags = []

        # å‰µå»ºä»»å‹™è¨˜éŒ„
        with tasks_lock:
            transcription_tasks[task_id] = {
                "task_id": task_id,
                "status": "pending",
                "filename": file.filename,
                "file_size_mb": round(len(content) / 1024 / 1024, 2),
                "progress": "ç­‰å¾…è™•ç†...",
                "punct_provider": punct_provider,
                "chunk_audio": chunk_audio,
                "chunk_minutes": chunk_minutes,
                "diarize": diarize,
                "max_speakers": max_speakers,
                "language": language,
                "diarization_status": None,  # "running" | "completed" | "failed" | None
                "diarization_num_speakers": None,  # è­˜åˆ¥åˆ°çš„è¬›è€…äººæ•¸
                "tags": task_tags,  # æ¨™ç±¤é™£åˆ—
                "keep_audio": False,  # æ˜¯å¦ä¿ç•™éŸ³æª”ï¼ˆç”¨æˆ¶å‹¾é¸ï¼‰
                "created_at": get_current_time(),
                "updated_at": get_current_time()
            }

        # ç«‹å³ä¿å­˜æ–°ä»»å‹™
        save_tasks_to_disk()

        # åœ¨èƒŒæ™¯ç·šç¨‹ä¸­åŸ·è¡Œè½‰éŒ„
        loop = asyncio.get_event_loop()
        loop.run_in_executor(
            executor,
            process_transcription_task,
            task_id,
            temp_audio,
            file.filename,
            punct_provider,
            chunk_audio,
            chunk_minutes,
            diarize,
            max_speakers,
            language
        )

        # ç«‹å³è¿”å›ä»»å‹™è³‡è¨Š
        return JSONResponse({
            "task_id": task_id,
            "status": "pending",
            "message": "è½‰éŒ„ä»»å‹™å·²æäº¤ï¼Œè«‹ä½¿ç”¨ task_id æŸ¥è©¢ç‹€æ…‹",
            "filename": file.filename,
            "created_at": transcription_tasks[task_id]["created_at"],
            "status_url": f"/transcribe/{task_id}",
            "download_url": f"/transcribe/{task_id}/download"
        })

    except Exception as e:
        # ç™¼ç”ŸéŒ¯èª¤æ™‚æ¸…ç†
        cleanup_temp_dir(temp_dir)
        print(f"âŒ æäº¤ä»»å‹™å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æäº¤ä»»å‹™å¤±æ•—ï¼š{str(e)}")


@app.get("/transcribe/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è©¢è½‰éŒ„ä»»å‹™ç‹€æ…‹"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    # ä½¿ç”¨çµ±ä¸€çš„å‡½æ•¸æ·»åŠ è¨ˆç®—æ¬„ä½
    return JSONResponse(enrich_task_data(task))


@app.get("/transcribe/{task_id}/download")
async def download_task_result(task_id: str):
    """ä¸‹è¼‰è½‰éŒ„çµæœ"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    if task["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"ä»»å‹™å°šæœªå®Œæˆï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰"
        )

    result_file = Path(task["result_file"])
    if not result_file.exists():
        raise HTTPException(status_code=404, detail="çµæœæª”æ¡ˆä¸å­˜åœ¨")

    # ä½¿ç”¨è‡ªè¨‚åç¨±ä½œç‚ºä¸‹è¼‰æª”åï¼ˆå¦‚æœæœ‰è¨­å®šï¼‰ï¼Œå¦å‰‡ä½¿ç”¨åŸå§‹æª”å
    if task.get("custom_name"):
        download_filename = task["custom_name"]
        # ç§»é™¤å¸¸è¦‹çš„éŸ³è¨Šå‰¯æª”å
        import os
        name_without_ext = download_filename
        for ext in ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac', '.wma']:
            if download_filename.lower().endswith(ext):
                name_without_ext = download_filename[:-len(ext)]
                break
        # ç¢ºä¿æª”åæœ‰ .txt å‰¯æª”å
        if not name_without_ext.endswith('.txt'):
            download_filename = name_without_ext + '.txt'
        else:
            download_filename = name_without_ext
    else:
        download_filename = task["result_filename"]

    return FileResponse(
        result_file,
        media_type="text/plain",
        filename=download_filename,
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )


@app.get("/transcribe/{task_id}/audio")
async def get_task_audio(task_id: str):
    """ç²å–ä»»å‹™çš„éŸ³æª”"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    if task["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"ä»»å‹™å°šæœªå®Œæˆï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰"
        )

    # æª¢æŸ¥æ˜¯å¦æœ‰éŸ³æª”
    audio_file_path = task.get("audio_file")
    if not audio_file_path:
        raise HTTPException(status_code=404, detail="æ­¤ä»»å‹™æ²’æœ‰ä¿å­˜éŸ³æª”ï¼ˆå¯èƒ½æ˜¯è¼ƒèˆŠçš„ä»»å‹™ï¼‰")

    audio_file = Path(audio_file_path)
    if not audio_file.exists():
        raise HTTPException(status_code=404, detail="éŸ³æª”ä¸å­˜åœ¨")

    # æ ¹æ“šæª”æ¡ˆå‰¯æª”åæ±ºå®š media type
    suffix = audio_file.suffix.lower()
    media_types = {
        ".mp3": "audio/mpeg",
        ".m4a": "audio/mp4",
        ".wav": "audio/wav",
        ".ogg": "audio/ogg",
        ".flac": "audio/flac"
    }
    media_type = media_types.get(suffix, "audio/mpeg")

    return FileResponse(
        audio_file,
        media_type=media_type,
        filename=task.get("audio_filename", "audio" + suffix)
    )


@app.get("/transcribe/{task_id}/segments")
async def get_task_segments(task_id: str):
    """ç²å–ä»»å‹™çš„ segments timing æ•¸æ“š"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    if task["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"ä»»å‹™å°šæœªå®Œæˆï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰"
        )

    # æª¢æŸ¥æ˜¯å¦æœ‰ segments æª”æ¡ˆ
    segments_file_path = task.get("segments_file")
    if not segments_file_path:
        raise HTTPException(status_code=404, detail="æ­¤ä»»å‹™æ²’æœ‰ segments æ•¸æ“šï¼ˆå¯èƒ½æ˜¯è¼ƒèˆŠçš„ä»»å‹™ï¼‰")

    segments_file = Path(segments_file_path)
    if not segments_file.exists():
        raise HTTPException(status_code=404, detail="Segments æª”æ¡ˆä¸å­˜åœ¨")

    try:
        segments_data = json.loads(segments_file.read_text(encoding="utf-8"))
        return JSONResponse({"segments": segments_data})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è®€å– segments å¤±æ•—ï¼š{str(e)}")


@app.put("/transcribe/{task_id}/content")
async def update_transcript_content(task_id: str, update_data: TranscriptContentUpdate):
    """æ›´æ–°é€å­—ç¨¿å…§å®¹"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    if task["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"ä»»å‹™å°šæœªå®Œæˆï¼Œç„¡æ³•ç·¨è¼¯ï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰"
        )

    result_file = Path(task["result_file"])
    if not result_file.exists():
        raise HTTPException(status_code=404, detail="çµæœæª”æ¡ˆä¸å­˜åœ¨")

    # ç²å–æ–°å…§å®¹
    new_content = update_data.content
    if not new_content:
        raise HTTPException(status_code=400, detail="å…§å®¹ä¸èƒ½ç‚ºç©º")

    try:
        # é™¤éŒ¯ï¼šé¡¯ç¤ºæª”æ¡ˆè·¯å¾‘å’Œå…§å®¹å‰100å­—
        print(f"ğŸ“ [{task_id}] æº–å‚™æ›´æ–°æª”æ¡ˆï¼š{result_file}")
        print(f"   æ–°å…§å®¹å‰100å­—ï¼š{new_content[:100]}")

        # ä¿å­˜æ–°å…§å®¹åˆ°æª”æ¡ˆ
        result_file.write_text(new_content, encoding="utf-8")

        # é™¤éŒ¯ï¼šé©—è­‰æª”æ¡ˆæ˜¯å¦çœŸçš„è¢«æ›´æ–°
        saved_content = result_file.read_text(encoding="utf-8")
        print(f"   æª”æ¡ˆå·²æ›´æ–°ï¼Œé©—è­‰å‰100å­—ï¼š{saved_content[:100]}")

        # æ›´æ–°ä»»å‹™è¨˜éŒ„ä¸­çš„å­—æ•¸
        with tasks_lock:
            if task_id in transcription_tasks:
                transcription_tasks[task_id]["text_length"] = len(new_content)
                transcription_tasks[task_id]["updated_at"] = get_current_time()

        # ä¿å­˜ä»»å‹™ç‹€æ…‹åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        print(f"âœ… [{task_id}] é€å­—ç¨¿å·²æ›´æ–°ï¼ˆæ–°é•·åº¦ï¼š{len(new_content)} å­—ï¼‰")

        return {
            "message": "é€å­—ç¨¿å·²æˆåŠŸæ›´æ–°",
            "task_id": task_id,
            "text_length": len(new_content)
        }

    except Exception as e:
        print(f"âŒ [{task_id}] æ›´æ–°é€å­—ç¨¿å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.put("/transcribe/{task_id}/metadata")
async def update_task_metadata(task_id: str, metadata: TaskMetadataUpdate):
    """æ›´æ–°ä»»å‹™çš„è‡ªè¨‚åç¨±ï¼ˆç”¨æ–¼é¡¯ç¤ºå’Œä¸‹è¼‰ï¼‰"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    try:
        with tasks_lock:
            if task_id in transcription_tasks:
                if metadata.custom_name is not None:
                    # é©—è­‰æª”åï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
                    import re
                    safe_name = re.sub(r'[<>:"/\\|?*]', '_', metadata.custom_name)
                    transcription_tasks[task_id]["custom_name"] = safe_name
                    print(f"ğŸ“ [{task_id}] æ›´æ–°è‡ªè¨‚åç¨±ï¼š{safe_name}")

                transcription_tasks[task_id]["updated_at"] = get_current_time()

        # ä¿å­˜ä»»å‹™ç‹€æ…‹åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        return {
            "message": "ä»»å‹™åç¨±å·²æ›´æ–°",
            "task_id": task_id,
            "custom_name": transcription_tasks[task_id].get("custom_name")
        }

    except Exception as e:
        print(f"âŒ [{task_id}] æ›´æ–°ä»»å‹™åç¨±å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.put("/transcribe/{task_id}/tags")
async def update_task_tags(task_id: str, tag_update: TaskTagsUpdate):
    """æ›´æ–°ä»»å‹™çš„æ¨™ç±¤"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    try:
        with tasks_lock:
            if task_id in transcription_tasks:
                transcription_tasks[task_id]["tags"] = tag_update.tags
                transcription_tasks[task_id]["updated_at"] = get_current_time()
                print(f"ğŸ·ï¸  [{task_id}] æ›´æ–°æ¨™ç±¤ï¼š{tag_update.tags}")

        # ä¿å­˜ä»»å‹™ç‹€æ…‹åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        return {
            "message": "æ¨™ç±¤å·²æ›´æ–°",
            "task_id": task_id,
            "tags": tag_update.tags
        }

    except Exception as e:
        print(f"âŒ [{task_id}] æ›´æ–°æ¨™ç±¤å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.put("/transcribe/{task_id}/keep-audio")
async def update_keep_audio(task_id: str, keep_audio_update: KeepAudioUpdate):
    """æ›´æ–°ä»»å‹™çš„éŸ³æª”ä¿ç•™ç‹€æ…‹"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    # æª¢æŸ¥ä»»å‹™æ˜¯å¦æœ‰éŸ³æª”
    if task.get("status") != "completed" or not task.get("audio_file"):
        raise HTTPException(status_code=400, detail="æ­¤ä»»å‹™æ²’æœ‰éŸ³æª”å¯ä»¥ä¿ç•™")

    try:
        # å¦‚æœè¦è¨­ç½®ç‚º Trueï¼Œæª¢æŸ¥å·²å‹¾é¸çš„æ•¸é‡
        if keep_audio_update.keep_audio:
            with tasks_lock:
                # è¨ˆç®—ç•¶å‰æœ‰å¤šå°‘å€‹ä»»å‹™è¢«æ¨™è¨˜ç‚ºä¿ç•™éŸ³æª”ï¼ˆä¸åŒ…æ‹¬ç•¶å‰ä»»å‹™ï¼‰
                keep_count = sum(
                    1 for tid, t in transcription_tasks.items()
                    if tid != task_id and t.get("keep_audio", False) and t.get("status") == "completed" and t.get("audio_file")
                )

                if keep_count >= 3:
                    raise HTTPException(status_code=400, detail="æœ€å¤šåªèƒ½å‹¾é¸ 3 å€‹éŸ³æª”ä¿ç•™")

        with tasks_lock:
            if task_id in transcription_tasks:
                transcription_tasks[task_id]["keep_audio"] = keep_audio_update.keep_audio
                transcription_tasks[task_id]["updated_at"] = get_current_time()
                print(f"ğŸ“Œ [{task_id}] æ›´æ–°éŸ³æª”ä¿ç•™ç‹€æ…‹ï¼š{keep_audio_update.keep_audio}")

        # ä¿å­˜ä»»å‹™ç‹€æ…‹åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        return {
            "message": "éŸ³æª”ä¿ç•™ç‹€æ…‹å·²æ›´æ–°",
            "task_id": task_id,
            "keep_audio": keep_audio_update.keep_audio
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [{task_id}] æ›´æ–°éŸ³æª”ä¿ç•™ç‹€æ…‹å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.get("/tags")
async def get_all_tags():
    """ç²å–æ‰€æœ‰å·²ä½¿ç”¨çš„æ¨™ç±¤åŠå…¶é¡è‰²"""
    with tasks_lock:
        # æ”¶é›†æ‰€æœ‰ä»»å‹™ä¸­çš„æ¨™ç±¤
        all_tags = set()
        for task in transcription_tasks.values():
            if "tags" in task and task["tags"]:
                all_tags.update(task["tags"])

    # è¿”å›æ¨™ç±¤åŠå…¶é¡è‰²
    tags_with_colors = []
    for tag in sorted(all_tags):
        tags_with_colors.append({
            "name": tag,
            "color": tag_colors.get(tag, None)  # å¦‚æœæ²’æœ‰è¨­å®šé¡è‰²å‰‡ç‚º None
        })

    return {
        "tags": tags_with_colors,
        "count": len(tags_with_colors)
    }


@app.put("/tags/{tag_name}/color")
async def update_tag_color(tag_name: str, color_update: TagColorUpdate):
    """æ›´æ–°æ¨™ç±¤çš„é¡è‰²"""
    try:
        tag_colors[tag_name] = color_update.color
        print(f"ğŸ¨ æ›´æ–°æ¨™ç±¤é¡è‰²ï¼š{tag_name} -> {color_update.color}")

        # ä¿å­˜åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        return {
            "message": "æ¨™ç±¤é¡è‰²å·²æ›´æ–°",
            "tag": tag_name,
            "color": color_update.color
        }

    except Exception as e:
        print(f"âŒ æ›´æ–°æ¨™ç±¤é¡è‰²å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.get("/tags/order")
async def get_tag_order():
    """ç²å–æ¨™ç±¤é †åº"""
    return {
        "order": tag_order,
        "count": len(tag_order)
    }


@app.put("/tags/order")
async def update_tag_order(order_update: TagOrderUpdate):
    """æ›´æ–°æ¨™ç±¤é †åº"""
    try:
        global tag_order
        tag_order = order_update.order
        print(f"ğŸ“‹ æ›´æ–°æ¨™ç±¤é †åºï¼š{len(tag_order)} å€‹æ¨™ç±¤")

        # ä¿å­˜åˆ°ç£ç¢Ÿ
        save_tasks_to_disk()

        return {
            "message": "æ¨™ç±¤é †åºå·²æ›´æ–°",
            "order": tag_order,
            "count": len(tag_order)
        }

    except Exception as e:
        print(f"âŒ æ›´æ–°æ¨™ç±¤é †åºå¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—ï¼š{str(e)}")


@app.post("/transcribe/{task_id}/cancel")
async def cancel_task(task_id: str):
    """å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„ä»»å‹™"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

        if not task:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

        # åªèƒ½å–æ¶ˆé€²è¡Œä¸­æˆ–ç­‰å¾…ä¸­çš„ä»»å‹™
        if task["status"] not in ["pending", "processing"]:
            raise HTTPException(
                status_code=400,
                detail=f"ç„¡æ³•å–æ¶ˆå·²çµæŸçš„ä»»å‹™ï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰"
            )

        # æ¨™è¨˜ä»»å‹™ç‚ºå·²å–æ¶ˆ
        task_cancelled[task_id] = True

        # ç«‹å³çµ‚æ­¢ diarization é€²ç¨‹ï¼ˆå¦‚æœæ­£åœ¨é‹è¡Œï¼‰
        diarization_executor = task_diarization_processes.get(task_id)
        if diarization_executor:
            print(f"ğŸ›‘ æ­£åœ¨å¼·åˆ¶çµ‚æ­¢èªªè©±è€…è¾¨è­˜é€²ç¨‹...")
            try:
                diarization_executor.shutdown(wait=False, cancel_futures=True)
                print(f"âœ… èªªè©±è€…è¾¨è­˜é€²ç¨‹å·²çµ‚æ­¢")
            except Exception as e:
                print(f"âš ï¸ çµ‚æ­¢ diarization é€²ç¨‹å¤±æ•—ï¼š{e}")
            task_diarization_processes.pop(task_id, None)

        # ç«‹å³æ¸…ç†æš«å­˜ç›®éŒ„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        temp_dir = task_temp_dirs.get(task_id)
        if temp_dir:
            cleanup_temp_dir(temp_dir)
            task_temp_dirs.pop(task_id, None)

    print(f"ğŸ›‘ ä»»å‹™ {task_id} å·²è¢«æ¨™è¨˜ç‚ºå–æ¶ˆ")

    return {
        "message": "ä»»å‹™å–æ¶ˆæŒ‡ä»¤å·²ç™¼é€",
        "task_id": task_id,
        "note": "ä»»å‹™å°‡åœ¨ç•¶å‰æ­¥é©Ÿå®Œæˆå¾Œåœæ­¢"
    }


@app.delete("/transcribe/{task_id}")
async def delete_task(task_id: str):
    """åˆªé™¤ä»»å‹™åŠå…¶ç›¸é—œæª”æ¡ˆ"""
    with tasks_lock:
        task = transcription_tasks.get(task_id)

        if not task:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

        # ä¸å…è¨±åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™
        if task["status"] in ["pending", "processing"]:
            raise HTTPException(
                status_code=400,
                detail=f"ç„¡æ³•åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™ï¼ˆç•¶å‰ç‹€æ…‹ï¼š{task['status']}ï¼‰ï¼Œè«‹å…ˆå–æ¶ˆä»»å‹™"
            )

        deleted_files = []

        # åˆªé™¤çµæœæª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task["status"] == "completed" and task.get("result_file"):
            result_file = Path(task["result_file"])
            try:
                if result_file.exists():
                    result_file.unlink()
                    deleted_files.append(result_file.name)
                    print(f"ğŸ—‘ï¸ å·²åˆªé™¤è½‰éŒ„æª”æ¡ˆï¼š{result_file.name}")
            except Exception as e:
                print(f"âš ï¸ åˆªé™¤è½‰éŒ„æª”æ¡ˆå¤±æ•—ï¼š{e}")

        # åˆªé™¤ segments æª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task["status"] == "completed" and task.get("segments_file"):
            segments_file = Path(task["segments_file"])
            try:
                if segments_file.exists():
                    segments_file.unlink()
                    deleted_files.append(segments_file.name)
                    print(f"ğŸ—‘ï¸ å·²åˆªé™¤ segments æª”æ¡ˆï¼š{segments_file.name}")
            except Exception as e:
                print(f"âš ï¸ åˆªé™¤ segments æª”æ¡ˆå¤±æ•—ï¼š{e}")

        # åˆªé™¤éŸ³æª”ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if task["status"] == "completed" and task.get("audio_file"):
            audio_file = Path(task["audio_file"])
            try:
                if audio_file.exists():
                    audio_file.unlink()
                    deleted_files.append(audio_file.name)
                    print(f"ğŸ—‘ï¸ å·²åˆªé™¤éŸ³æª”ï¼š{audio_file.name}")
            except Exception as e:
                print(f"âš ï¸ åˆªé™¤éŸ³æª”å¤±æ•—ï¼š{e}")

        # å¾ä»»å‹™åˆ—è¡¨ä¸­ç§»é™¤
        del transcription_tasks[task_id]

    # ä¿å­˜åˆ°ç£ç¢Ÿ
    save_tasks_to_disk()

    return {
        "message": "ä»»å‹™å·²åˆªé™¤",
        "task_id": task_id,
        "deleted_files": deleted_files
    }


@app.post("/transcribe/batch/delete")
async def batch_delete_tasks(request: BatchDeleteRequest):
    """æ‰¹æ¬¡åˆªé™¤ä»»å‹™"""
    deleted_tasks = []
    failed_tasks = []

    for task_id in request.task_ids:
        try:
            with tasks_lock:
                task = transcription_tasks.get(task_id)

                if not task:
                    failed_tasks.append({"task_id": task_id, "reason": "ä»»å‹™ä¸å­˜åœ¨"})
                    continue

                # ä¸å…è¨±åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™
                if task["status"] in ["pending", "processing"]:
                    failed_tasks.append({"task_id": task_id, "reason": "ç„¡æ³•åˆªé™¤é€²è¡Œä¸­çš„ä»»å‹™"})
                    continue

                # åˆªé™¤ç›¸é—œæª”æ¡ˆ
                deleted_files = []

                # åˆªé™¤çµæœæª”æ¡ˆ
                if task["status"] == "completed" and task.get("result_file"):
                    result_file = Path(task["result_file"])
                    try:
                        if result_file.exists():
                            result_file.unlink()
                            deleted_files.append(result_file.name)
                    except Exception as e:
                        print(f"âš ï¸ åˆªé™¤è½‰éŒ„æª”æ¡ˆå¤±æ•—ï¼š{e}")

                # åˆªé™¤ segments æª”æ¡ˆ
                if task["status"] == "completed" and task.get("segments_file"):
                    segments_file = Path(task["segments_file"])
                    try:
                        if segments_file.exists():
                            segments_file.unlink()
                            deleted_files.append(segments_file.name)
                    except Exception as e:
                        print(f"âš ï¸ åˆªé™¤ segments æª”æ¡ˆå¤±æ•—ï¼š{e}")

                # åˆªé™¤éŸ³æª”
                if task["status"] == "completed" and task.get("audio_file"):
                    audio_file = Path(task["audio_file"])
                    try:
                        if audio_file.exists():
                            audio_file.unlink()
                            deleted_files.append(audio_file.name)
                    except Exception as e:
                        print(f"âš ï¸ åˆªé™¤éŸ³æª”å¤±æ•—ï¼š{e}")

                # å¾ä»»å‹™åˆ—è¡¨ä¸­ç§»é™¤
                del transcription_tasks[task_id]
                deleted_tasks.append({"task_id": task_id, "deleted_files": deleted_files})

        except Exception as e:
            failed_tasks.append({"task_id": task_id, "reason": str(e)})

    # ä¿å­˜åˆ°ç£ç¢Ÿ
    save_tasks_to_disk()

    return {
        "message": f"æˆåŠŸåˆªé™¤ {len(deleted_tasks)} å€‹ä»»å‹™",
        "deleted_count": len(deleted_tasks),
        "failed_count": len(failed_tasks),
        "deleted_tasks": deleted_tasks,
        "failed_tasks": failed_tasks
    }


@app.post("/transcribe/batch/tags/add")
async def batch_add_tags(request: BatchTagsRequest):
    """æ‰¹æ¬¡åŠ å…¥æ¨™ç±¤"""
    updated_tasks = []
    failed_tasks = []

    for task_id in request.task_ids:
        try:
            with tasks_lock:
                task = transcription_tasks.get(task_id)

                if not task:
                    failed_tasks.append({"task_id": task_id, "reason": "ä»»å‹™ä¸å­˜åœ¨"})
                    continue

                # ç²å–ç¾æœ‰æ¨™ç±¤
                existing_tags = set(task.get("tags", []))

                # åŠ å…¥æ–°æ¨™ç±¤ï¼ˆé¿å…é‡è¤‡ï¼‰
                for tag in request.tags:
                    existing_tags.add(tag)

                # æ›´æ–°ä»»å‹™çš„æ¨™ç±¤
                transcription_tasks[task_id]["tags"] = list(existing_tags)
                transcription_tasks[task_id]["updated_at"] = get_current_time()

                updated_tasks.append({
                    "task_id": task_id,
                    "tags": list(existing_tags)
                })

        except Exception as e:
            failed_tasks.append({"task_id": task_id, "reason": str(e)})

    # ä¿å­˜åˆ°ç£ç¢Ÿ
    save_tasks_to_disk()

    return {
        "message": f"æˆåŠŸç‚º {len(updated_tasks)} å€‹ä»»å‹™åŠ å…¥æ¨™ç±¤",
        "updated_count": len(updated_tasks),
        "failed_count": len(failed_tasks),
        "updated_tasks": updated_tasks,
        "failed_tasks": failed_tasks
    }


@app.post("/transcribe/batch/tags/remove")
async def batch_remove_tags(request: BatchTagsRequest):
    """æ‰¹æ¬¡ç§»é™¤æ¨™ç±¤"""
    updated_tasks = []
    failed_tasks = []

    for task_id in request.task_ids:
        try:
            with tasks_lock:
                task = transcription_tasks.get(task_id)

                if not task:
                    failed_tasks.append({"task_id": task_id, "reason": "ä»»å‹™ä¸å­˜åœ¨"})
                    continue

                # ç²å–ç¾æœ‰æ¨™ç±¤
                existing_tags = set(task.get("tags", []))

                # ç§»é™¤æŒ‡å®šæ¨™ç±¤
                for tag in request.tags:
                    existing_tags.discard(tag)

                # æ›´æ–°ä»»å‹™çš„æ¨™ç±¤
                transcription_tasks[task_id]["tags"] = list(existing_tags)
                transcription_tasks[task_id]["updated_at"] = get_current_time()

                updated_tasks.append({
                    "task_id": task_id,
                    "tags": list(existing_tags)
                })

        except Exception as e:
            failed_tasks.append({"task_id": task_id, "reason": str(e)})

    # ä¿å­˜åˆ°ç£ç¢Ÿ
    save_tasks_to_disk()

    return {
        "message": f"æˆåŠŸå¾ {len(updated_tasks)} å€‹ä»»å‹™ç§»é™¤æ¨™ç±¤",
        "updated_count": len(updated_tasks),
        "failed_count": len(failed_tasks),
        "updated_tasks": updated_tasks,
        "failed_tasks": failed_tasks
    }


def enrich_task_data(task: Dict[str, Any]) -> Dict[str, Any]:
    """ç‚ºä»»å‹™è³‡æ–™æ·»åŠ è¨ˆç®—æ¬„ä½ï¼ˆé ä¼°æ™‚é–“ã€æ ¼å¼åŒ–æ™‚é•·ç­‰ï¼‰"""
    task_copy = task.copy()

    # æ·»åŠ é ä¼°å‰©é¤˜æ™‚é–“
    if task["status"] == "processing":
        # ä½¿ç”¨å›ºå®šçš„é ä¼°å®Œæˆæ™‚é–“ï¼ˆåœ¨åˆ‡åˆ†å®Œæˆæ™‚è¨ˆç®—ä¸€æ¬¡ï¼‰
        estimated_completion_time = task.get("estimated_completion_time")

        if estimated_completion_time:
            # æ ¼å¼åŒ–å®Œæˆæ™‚é–“ç‚º MM/DD HH:MM
            try:
                completion_dt = datetime.strptime(estimated_completion_time, "%Y-%m-%d %H:%M:%S")
                task_copy["estimated_completion_text"] = completion_dt.strftime("%m/%d %H:%M")
            except:
                task_copy["estimated_completion_text"] = "è¨ˆç®—ä¸­......"
        else:
            # å°šæœªåˆ‡åˆ†å®Œæˆï¼Œé¡¯ç¤ºè¨ˆç®—ä¸­
            task_copy["estimated_completion_text"] = "è¨ˆç®—ä¸­......"

    # æ·»åŠ æ ¼å¼åŒ–çš„ç¸½è™•ç†æ™‚é•·ï¼ˆå¦‚æœå·²å®Œæˆï¼‰
    if task["status"] == "completed" and "duration_seconds" in task:
        task_copy["duration_text"] = format_duration(task["duration_seconds"])

    return task_copy


@app.get("/transcribe/active/list")
async def list_active_tasks():
    """åˆ—å‡ºæ‰€æœ‰é€²è¡Œä¸­çš„è½‰éŒ„ä»»å‹™"""
    with tasks_lock:
        active = [
            task for task in transcription_tasks.values()
            if task["status"] in ["pending", "processing"]
        ]
        all_tasks = list(transcription_tasks.values())

    # ç‚ºæ‰€æœ‰ä»»å‹™æ·»åŠ è¨ˆç®—æ¬„ä½
    active_enriched = [enrich_task_data(task) for task in active]
    all_tasks_enriched = [enrich_task_data(task) for task in all_tasks]

    return {
        "active_count": len(active_enriched),
        "total_count": len(all_tasks_enriched),
        "active_tasks": sorted(active_enriched, key=lambda x: x["created_at"], reverse=True),
        "all_tasks": sorted(all_tasks_enriched, key=lambda x: x["created_at"], reverse=True)[:20]  # æœ€è¿‘ 20 å€‹
    }


@app.get("/transcripts")
async def list_transcripts():
    """åˆ—å‡ºå·²ä¿å­˜çš„è½‰éŒ„æ–‡å­—æª”"""
    try:
        transcripts = []
        for txt_file in sorted(OUTPUT_DIR.glob("*.txt"), key=lambda x: x.stat().st_mtime, reverse=True):
            stat = txt_file.stat()
            transcripts.append({
                "filename": txt_file.name,
                "size_kb": round(stat.st_size / 1024, 2),
                "created": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                "path": str(txt_file.relative_to(OUTPUT_DIR.parent))
            })

        return {
            "total": len(transcripts),
            "output_dir": str(OUTPUT_DIR.relative_to(OUTPUT_DIR.parent)),
            "transcripts": transcripts
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": whisper_model is not None,
        "model_name": current_model_name
    }


# ==================== éŸ³è¨Šç·¨è¼¯åŠŸèƒ½ ====================

# éŸ³è¨Šç‰‡æ®µå„²å­˜ç›®éŒ„
AUDIO_CLIPS_DIR = OUTPUT_DIR / "audio_clips"
AUDIO_CLIPS_DIR.mkdir(exist_ok=True)

# ç‰‡æ®µå…ƒæ•¸æ“šå„²å­˜
audio_clips: Dict[str, Dict[str, Any]] = {}
clips_lock = Lock()


def save_audio_clip(audio_segment: AudioSegment, source_filename: str, clip_id: str = None) -> Dict[str, Any]:
    """
    ä¿å­˜éŸ³è¨Šç‰‡æ®µåˆ°ç£ç¢Ÿ

    Args:
        audio_segment: pydub AudioSegment å°è±¡
        source_filename: ä¾†æºæª”æ¡ˆåç¨±
        clip_id: å¯é¸çš„ç‰‡æ®µ IDï¼ˆç”¨æ–¼åˆä½µï¼‰

    Returns:
        {
            "clip_id": str,
            "filename": str,
            "duration": float,
            "path": str
        }
    """
    if clip_id is None:
        clip_id = str(uuid.uuid4())

    timestamp = datetime.now(TZ_UTC8).strftime("%Y%m%d_%H%M%S")
    filename = f"clip_{timestamp}_{clip_id[:8]}.mp3"
    filepath = AUDIO_CLIPS_DIR / filename

    # å°å‡ºç‚º MP3
    audio_segment.export(str(filepath), format="mp3", bitrate="192k")

    clip_data = {
        "clip_id": clip_id,
        "filename": filename,
        "duration": len(audio_segment) / 1000.0,  # æ¯«ç§’è½‰ç§’
        "path": str(filepath),
        "source": source_filename,
        "created_at": get_current_time()
    }

    with clips_lock:
        audio_clips[clip_id] = clip_data

    return clip_data


@app.post("/audio/clip")
async def clip_audio(
    audio_file: UploadFile = File(...),
    regions: str = Form(..., description="å€æ®µ JSON é™£åˆ—ï¼Œæ ¼å¼ï¼š[{start, end, id}]")
):
    """
    å‰ªè¼¯éŸ³è¨Šæ–‡ä»¶ä¸­çš„æŒ‡å®šå€æ®µ

    - **audio_file**: åŸå§‹éŸ³è¨Šæ–‡ä»¶
    - **regions**: JSON å­—ä¸²ï¼ŒåŒ…å«å€æ®µé™£åˆ— [{"start": 10.5, "end": 25.3, "id": "xxx"}]

    Returns:
        {
            "clips": [
                {"clip_id": "...", "filename": "...", "duration": 14.8},
                ...
            ]
        }
    """
    temp_dir = Path(tempfile.mkdtemp())

    try:
        # ä¿å­˜ä¸Šå‚³çš„éŸ³æª”
        file_suffix = Path(audio_file.filename).suffix
        temp_audio_path = temp_dir / f"input{file_suffix}"

        with temp_audio_path.open("wb") as f:
            content = await audio_file.read()
            f.write(content)

        print(f"ğŸµ è¼‰å…¥éŸ³æª”é€²è¡Œå‰ªè¼¯ï¼š{audio_file.filename}")

        # è¼‰å…¥éŸ³æª”
        audio = AudioSegment.from_file(str(temp_audio_path))

        # è§£æå€æ®µ
        import json
        regions_data = json.loads(regions)

        if not regions_data or len(regions_data) == 0:
            raise HTTPException(status_code=400, detail="æœªæä¾›ä»»ä½•å€æ®µ")

        # å‰ªè¼¯æ¯å€‹å€æ®µ
        clips = []
        for idx, region in enumerate(regions_data):
            start_ms = int(region["start"] * 1000)
            end_ms = int(region["end"] * 1000)

            # é‚Šç•Œæª¢æŸ¥
            if end_ms > len(audio):
                end_ms = len(audio)

            if start_ms >= end_ms:
                raise HTTPException(
                    status_code=400,
                    detail=f"å€æ®µ {idx + 1} çš„èµ·å§‹æ™‚é–“å¤§æ–¼æˆ–ç­‰æ–¼çµæŸæ™‚é–“"
                )

            # æå–ç‰‡æ®µ
            clip_segment = audio[start_ms:end_ms]

            # ä¿å­˜ç‰‡æ®µ
            clip_data = save_audio_clip(clip_segment, audio_file.filename)
            clips.append({
                "clip_id": clip_data["clip_id"],
                "filename": clip_data["filename"],
                "duration": clip_data["duration"]
            })

        print(f"âœ… æˆåŠŸå‰ªè¼¯ {len(clips)} å€‹ç‰‡æ®µ")

        return JSONResponse({
            "clips": clips,
            "source_file": audio_file.filename,
            "total_clips": len(clips)
        })

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="regions æ ¼å¼éŒ¯èª¤ï¼Œéœ€ç‚ºæœ‰æ•ˆ JSON")
    except Exception as e:
        print(f"âŒ å‰ªè¼¯å¤±æ•—ï¼š{e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å‰ªè¼¯å¤±æ•—ï¼š{str(e)}")
    finally:
        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        cleanup_temp_dir(temp_dir)


@app.post("/audio/merge")
async def merge_audio(
    clip_ids: str = Form(..., description="è¦åˆä½µçš„ç‰‡æ®µ ID é™£åˆ—ï¼ˆJSON å­—ä¸²ï¼‰"),
    mode: str = Form("different-files", description="åˆä½µæ¨¡å¼")
):
    """
    åˆä½µå¤šå€‹éŸ³è¨Šç‰‡æ®µ

    - **clip_ids**: ç‰‡æ®µ ID é™£åˆ—ï¼ˆJSON å­—ä¸²ï¼‰
    - **mode**: åˆä½µæ¨¡å¼
        - "different-files": åˆä½µä¸åŒéŸ³æª”ï¼ˆä¸­é–“ç„¡é–“éš”ï¼‰
        - "same-file-clips": åˆä½µåŒä¸€éŸ³æª”çš„ç‰‡æ®µï¼ˆä¿æŒåŸå§‹æ™‚é–“é †åºï¼‰

    Returns:
        {
            "merged_id": "...",
            "filename": "...",
            "duration": 120.5
        }
    """
    try:
        # è§£æ clip_ids
        import json
        clip_ids_list = json.loads(clip_ids)

        if len(clip_ids_list) < 2:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ 2 å€‹ç‰‡æ®µ")

        # å–å¾—æ‰€æœ‰ç‰‡æ®µ
        with clips_lock:
            clips_to_merge = []
            for clip_id in clip_ids_list:
                if clip_id not in audio_clips:
                    raise HTTPException(status_code=404, detail=f"ç‰‡æ®µ {clip_id} ä¸å­˜åœ¨")
                clips_to_merge.append(audio_clips[clip_id])

        print(f"ğŸ”— åˆä½µ {len(clips_to_merge)} å€‹ç‰‡æ®µï¼ˆæ¨¡å¼ï¼š{mode}ï¼‰")

        # è¼‰å…¥æ‰€æœ‰ç‰‡æ®µ
        segments = []
        for clip_data in clips_to_merge:
            segment = AudioSegment.from_file(clip_data["path"])
            segments.append(segment)

        # åˆä½µé‚è¼¯
        merged = segments[0]
        for seg in segments[1:]:
            merged += seg

        # ä¿å­˜åˆä½µçµæœ
        merged_id = str(uuid.uuid4())
        merged_data = save_audio_clip(
            merged,
            f"merged_{len(clips_to_merge)}_clips",
            merged_id
        )

        duration_str = format_duration(merged_data['duration'])
        print(f"âœ… åˆä½µå®Œæˆï¼š{merged_data['filename']} ({duration_str})")

        return JSONResponse({
            "merged_id": merged_data["clip_id"],
            "filename": merged_data["filename"],
            "duration": merged_data["duration"]
        })

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="clip_ids æ ¼å¼éŒ¯èª¤")
    except Exception as e:
        print(f"âŒ åˆä½µå¤±æ•—ï¼š{e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆä½µå¤±æ•—ï¼š{str(e)}")


@app.get("/audio/download/{clip_id}")
async def download_clip(clip_id: str):
    """ä¸‹è¼‰éŸ³è¨Šç‰‡æ®µæˆ–åˆä½µçµæœ"""
    with clips_lock:
        if clip_id not in audio_clips:
            raise HTTPException(status_code=404, detail="ç‰‡æ®µä¸å­˜åœ¨")

        clip_data = audio_clips[clip_id]

    filepath = Path(clip_data["path"])

    if not filepath.exists():
        raise HTTPException(status_code=404, detail="æª”æ¡ˆå·²è¢«åˆªé™¤")

    return FileResponse(
        path=str(filepath),
        filename=clip_data["filename"],
        media_type="audio/mpeg"
    )


@app.post("/audio/cleanup")
async def cleanup_old_clips(max_age_hours: int = 24):
    """
    æ¸…ç†è¶…éæŒ‡å®šæ™‚é–“çš„éŸ³è¨Šç‰‡æ®µ

    - **max_age_hours**: æœ€å¤§ä¿ç•™æ™‚é–“ï¼ˆå°æ™‚ï¼‰ï¼Œé è¨­ 24 å°æ™‚
    """
    from datetime import datetime, timedelta

    cutoff_time = datetime.now(TZ_UTC8) - timedelta(hours=max_age_hours)

    deleted_count = 0
    with clips_lock:
        clips_to_delete = []

        for clip_id, clip_data in audio_clips.items():
            # è§£æå‰µå»ºæ™‚é–“
            created_str = clip_data.get("created_at", "")
            try:
                created_time = datetime.strptime(created_str, "%Y-%m-%d %H:%M:%S")
                created_time = created_time.replace(tzinfo=TZ_UTC8)

                if created_time < cutoff_time:
                    clips_to_delete.append(clip_id)
            except:
                continue

        # åˆªé™¤éæœŸç‰‡æ®µ
        for clip_id in clips_to_delete:
            clip_data = audio_clips[clip_id]
            filepath = Path(clip_data["path"])

            if filepath.exists():
                filepath.unlink()

            del audio_clips[clip_id]
            deleted_count += 1

    print(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} å€‹éæœŸéŸ³è¨Šç‰‡æ®µ")

    return JSONResponse({
        "deleted_count": deleted_count,
        "message": f"æˆåŠŸæ¸…ç† {deleted_count} å€‹è¶…é {max_age_hours} å°æ™‚çš„ç‰‡æ®µ"
    })


@app.post("/audio/convert-to-web-format")
async def convert_audio_to_web_format(
    audio_file: UploadFile = File(..., description="è¦è½‰æ›çš„éŸ³æª”")
):
    """
    å°‡éŸ³è¨Šæª”æ¡ˆè½‰æ›ç‚ºç€è¦½å™¨ç›¸å®¹çš„æ ¼å¼ (MP3)
    ç”¨æ–¼è§£æ±ºç€è¦½å™¨ç„¡æ³•è§£ç¢¼æŸäº›æ ¼å¼çš„å•é¡Œ
    """
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_dir_path = Path(temp_dir)

        # å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆ
        temp_input_path = temp_dir_path / audio_file.filename
        with open(temp_input_path, "wb") as f:
            content = await audio_file.read()
            f.write(content)

        try:
            # ä½¿ç”¨ pydub è¼‰å…¥éŸ³è¨Šï¼ˆæ”¯æ´å„ç¨®æ ¼å¼ï¼‰
            print(f"ğŸ”„ æ­£åœ¨è½‰æ›éŸ³è¨Šæ ¼å¼ï¼š{audio_file.filename}")
            audio = AudioSegment.from_file(str(temp_input_path))

            # è½‰æ›ç‚º MP3 æ ¼å¼ï¼ˆç€è¦½å™¨å»£æ³›æ”¯æ´ï¼‰
            # ä½¿ç”¨è¼ƒé«˜çš„ä½å…ƒç‡ä»¥ä¿æŒéŸ³è³ª
            output_filename = f"converted_{Path(audio_file.filename).stem}.mp3"
            output_path = AUDIO_CLIPS_DIR / output_filename

            audio.export(
                str(output_path),
                format="mp3",
                bitrate="192k",
                parameters=["-ar", "44100"]  # 44.1kHz å–æ¨£ç‡
            )

            # å–å¾—éŸ³è¨Šè³‡è¨Š
            duration = len(audio) / 1000.0
            file_size = output_path.stat().st_size

            # å„²å­˜åˆ° clips ç®¡ç†
            clip_id = str(uuid.uuid4())
            with clips_lock:
                audio_clips[clip_id] = {
                    "clip_id": clip_id,
                    "filename": output_filename,
                    "path": str(output_path),
                    "duration": duration,
                    "size": file_size,
                    "created_at": datetime.now(),
                    "original_filename": audio_file.filename
                }

            print(f"âœ… éŸ³è¨Šè½‰æ›å®Œæˆï¼š{output_filename} ({duration:.2f}ç§’, {file_size / 1024 / 1024:.2f}MB)")

            return JSONResponse({
                "clip_id": clip_id,
                "filename": output_filename,
                "duration": duration,
                "size": file_size,
                "format": "mp3",
                "message": "éŸ³è¨Šå·²æˆåŠŸè½‰æ›ç‚ºç€è¦½å™¨ç›¸å®¹æ ¼å¼"
            })

        except Exception as e:
            print(f"âŒ éŸ³è¨Šè½‰æ›å¤±æ•—ï¼š{str(e)}")
            raise HTTPException(status_code=400, detail=f"éŸ³è¨Šè½‰æ›å¤±æ•—ï¼š{str(e)}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Whisper è½‰éŒ„æœå‹™")
    parser.add_argument("--host", default="0.0.0.0", help="ç¶å®šçš„ IP åœ°å€")
    parser.add_argument("--port", type=int, default=8000, help="ç¶å®šçš„ç«¯å£")
    parser.add_argument("--model", default=DEFAULT_MODEL, help="Whisper æ¨¡å‹åç¨±")
    args = parser.parse_args()

    # æ›´æ–°é è¨­æ¨¡å‹
    DEFAULT_MODEL = args.model

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Whisper è½‰éŒ„æœå‹™ - FastAPI ç‰ˆæœ¬   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æœå‹™åœ°å€: http://{args.host}:{args.port}
API æ–‡æª”: http://{args.host}:{args.port}/docs
Whisper æ¨¡å‹: {args.model}
Google API Keys: {len(GOOGLE_API_KEYS)} å€‹å·²è¼‰å…¥

""")

    uvicorn.run(app, host=args.host, port=args.port)
 