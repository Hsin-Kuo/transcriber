"""
PunctuationProcessor - æ¨™é»ç¬¦è™Ÿè™•ç†å™¨
è·è²¬ï¼šä½¿ç”¨ AI æ¨¡å‹ç‚ºè½‰éŒ„æ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿ
"""

from typing import Optional, Tuple, Dict, Any, Callable
import os


class PunctuationProcessor:
    """æ¨™é»ç¬¦è™Ÿè™•ç†å™¨

    ä½¿ç”¨ Gemini æˆ– OpenAI ç‚ºè½‰éŒ„æ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿå’Œåˆ†æ®µ
    """

    def __init__(
        self,
        default_provider: str = "gemini",
        gemini_model: str = "gemini-2.0-flash",
        openai_model: str = "gpt-4o-mini"
    ):
        """åˆå§‹åŒ– PunctuationProcessor

        Args:
            default_provider: é è¨­æä¾›å•†ï¼ˆ"gemini" æˆ– "openai"ï¼‰
            gemini_model: Gemini æ¨¡å‹åç¨±
            openai_model: OpenAI æ¨¡å‹åç¨±
        """
        self.default_provider = default_provider
        self.gemini_model = gemini_model
        self.openai_model = openai_model

        # Gemini å‚™æ´æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
        self.gemini_fallback_models = [
            "gemini-2.0-flash-lite",
            "gemini-flash-lite-latest",
            "gemini-2.5-flash",
            "gemini-flash-latest",
            "gemini-2.5-pro",
        ]

    def process(
        self,
        text: str,
        provider: Optional[str] = None,
        language: str = "zh",
        chunk_size: Optional[int] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> Tuple[str, str, Optional[Dict[str, int]]]:
        """è™•ç†æ–‡å­—ï¼Œæ·»åŠ æ¨™é»ç¬¦è™Ÿå’Œåˆ†æ®µ

        Args:
            text: è¦è™•ç†çš„æ–‡å­—
            provider: API æä¾›å•†ï¼ˆ"gemini" æˆ– "openai"ï¼‰ï¼ŒNone ä½¿ç”¨é è¨­
            language: èªè¨€ä»£ç¢¼ï¼ˆzh/en/ja/ko ç­‰ï¼‰
            chunk_size: åˆ†æ®µå¤§å°ï¼ˆå­—å…ƒæ•¸ï¼‰ï¼ŒNone å‰‡è‡ªå‹•æ±ºå®š
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸ callback(current_chunk, total_chunks)

        Returns:
            (è™•ç†å¾Œçš„æ–‡å­—, ä½¿ç”¨çš„æ¨¡å‹åç¨±, token_usage) å…ƒçµ„
            token_usage: {"total": int, "prompt": int, "completion": int} æˆ– None
        """
        provider = provider or self.default_provider

        if provider == "openai":
            return self._punctuate_with_openai(text, language)
        else:
            return self._punctuate_with_gemini(
                text,
                language,
                chunk_size,
                progress_callback
            )

    # ========== ç§æœ‰æ–¹æ³• ==========

    def _punctuate_with_openai(
        self,
        text: str,
        language: str = "zh"
    ) -> Tuple[str, str, Optional[Dict[str, int]]]:
        """ä½¿ç”¨ OpenAI æ·»åŠ æ¨™é»ç¬¦è™Ÿ

        Args:
            text: è¦è™•ç†çš„æ–‡å­—
            language: èªè¨€ä»£ç¢¼

        Returns:
            (è™•ç†å¾Œçš„æ–‡å­—, ä½¿ç”¨çš„æ¨¡å‹åç¨±, token_usage) å…ƒçµ„
        """
        from openai import OpenAI

        client = OpenAI()

        # ç²å–æç¤ºèª
        system_msg, user_msg = self._get_punctuation_prompt(language, text)

        resp = client.chat.completions.create(
            model=self.openai_model,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.2,
        )

        result = resp.choices[0].message.content.strip()

        # æå– token ä½¿ç”¨é‡
        token_usage = None
        if hasattr(resp, 'usage') and resp.usage:
            token_usage = {
                "total": resp.usage.total_tokens,
                "prompt": resp.usage.prompt_tokens,
                "completion": resp.usage.completion_tokens
            }
            print(f"ğŸ“Š Token ä½¿ç”¨: {token_usage['total']} (è¼¸å…¥: {token_usage['prompt']}, è¼¸å‡º: {token_usage['completion']})")

        return result, self.openai_model, token_usage

    def _punctuate_with_gemini(
        self,
        text: str,
        language: str = "zh",
        chunk_size: Optional[int] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> Tuple[str, str, Optional[Dict[str, int]]]:
        """ä½¿ç”¨ Google Gemini æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼ˆæ”¯æ´é•·æ–‡æœ¬åˆ†æ®µè™•ç†ï¼‰

        Args:
            text: è¦è™•ç†çš„æ–‡å­—
            language: èªè¨€ä»£ç¢¼
            chunk_size: åˆ†æ®µå¤§å°ï¼ˆå­—å…ƒæ•¸ï¼‰ï¼ŒNone å‰‡è‡ªå‹•æ±ºå®š
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸

        Returns:
            (è™•ç†å¾Œçš„æ–‡å­—, ä½¿ç”¨çš„æ¨¡å‹åç¨±, token_usage) å…ƒçµ„
        """
        import google.generativeai as genai

        # è‡ªå‹•æ±ºå®š chunk_size
        if chunk_size is None:
            if language == "zh":
                chunk_size = 4000  # ä¸­æ–‡ï¼š4000 å­—
            else:
                chunk_size = 15000  # å…¶ä»–èªè¨€ï¼š15000 å­—å…ƒ

        # å¦‚æœæ–‡å­—ä¸é•·ï¼Œç›´æ¥è™•ç†
        if len(text) <= chunk_size:
            system_msg, user_msg = self._get_punctuation_prompt(language, text)
            prompt = f"{system_msg}\n\n{user_msg}"
            result, model_used, token_usage = self._call_gemini_with_retry(prompt)
            return result, model_used, token_usage

        # é•·æ–‡æœ¬ï¼šåˆ†æ®µè™•ç†
        print(f"ğŸ“ æ–‡å­—è¼ƒé•·ï¼ˆ{len(text)} å­—ï¼‰ï¼Œå°‡åˆ†æ®µè™•ç†ï¼ˆæ¯æ®µç´„ {chunk_size} å­—ï¼‰...")

        chunks = self._split_text_into_chunks(text, chunk_size)
        total_chunks = len(chunks)
        print(f"ğŸ”„ åˆ†ç‚º {total_chunks} æ®µè™•ç†...")

        results = []
        model_used = None
        # ç´¯åŠ æ‰€æœ‰ chunk çš„ token ä½¿ç”¨é‡
        total_token_usage = {"total": 0, "prompt": 0, "completion": 0}

        for chunk_idx, chunk_text in enumerate(chunks, start=1):
            print(f"ğŸ¯ è™•ç†ç¬¬ {chunk_idx}/{total_chunks} æ®µ...")

            # é€²åº¦å›èª¿
            if progress_callback:
                progress_callback(chunk_idx, total_chunks)

            # ç²å–åˆ†æ®µæç¤ºèª
            system_msg, user_msg = self._get_chunked_punctuation_prompt(
                language, chunk_text, chunk_idx, total_chunks
            )
            prompt = f"{system_msg}\n\n{user_msg}"

            # èª¿ç”¨ Gemini
            result, chunk_model, chunk_token_usage = self._call_gemini_with_retry(prompt)
            results.append(result)

            # è¨˜éŒ„ä½¿ç”¨çš„æ¨¡å‹ï¼ˆä½¿ç”¨ç¬¬ä¸€å€‹æˆåŠŸçš„æ¨¡å‹ï¼‰
            if model_used is None:
                model_used = chunk_model

            # ç´¯åŠ  token ä½¿ç”¨é‡
            if chunk_token_usage:
                total_token_usage["total"] += chunk_token_usage.get("total", 0)
                total_token_usage["prompt"] += chunk_token_usage.get("prompt", 0)
                total_token_usage["completion"] += chunk_token_usage.get("completion", 0)

        # å¦‚æœæœ‰ç´¯è¨ˆçš„ token ä½¿ç”¨é‡ï¼Œè¼¸å‡ºç¸½é‡
        if total_token_usage["total"] > 0:
            print(f"ğŸ“Š ç¸½ Token ä½¿ç”¨: {total_token_usage['total']} (è¼¸å…¥: {total_token_usage['prompt']}, è¼¸å‡º: {total_token_usage['completion']})")

        # åˆä½µçµæœ
        final_token_usage = total_token_usage if total_token_usage["total"] > 0 else None
        return "\n\n".join(results), model_used or self.gemini_model, final_token_usage

    def _call_gemini_with_retry(
        self,
        prompt: str,
        max_retries: Optional[int] = None
    ) -> Tuple[str, str, Optional[Dict[str, int]]]:
        """èª¿ç”¨ Gemini APIï¼Œæ”¯æ´è‡ªå‹•é‡è©¦å’Œæ¨¡å‹å‚™æ´

        Args:
            prompt: æç¤ºæ–‡å­—
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸

        Returns:
            (è™•ç†å¾Œçš„æ–‡å­—, ä½¿ç”¨çš„æ¨¡å‹åç¨±, token_usage) å…ƒçµ„

        Raises:
            RuntimeError: æ‰€æœ‰ API Keys å’Œå‚™æ´æ¨¡å‹éƒ½å¤±æ•—
        """
        import google.generativeai as genai

        # ç²å– Google API Keys
        google_api_keys = self._load_google_api_keys()

        if max_retries is None:
            max_retries = len(google_api_keys)

        last_error = None
        quota_exceeded_count = 0
        current_model = self.gemini_model
        fallback_index = -1
        tried_models = [self.gemini_model]
        current_key_index = 0

        max_attempts = max_retries * (len(self.gemini_fallback_models) + 1)

        for attempt in range(max_attempts):
            try:
                # ç²å–ä¸‹ä¸€å€‹ API Keyï¼ˆè¼ªè©¢ï¼‰
                api_key = google_api_keys[current_key_index % len(google_api_keys)]
                current_key_index += 1

                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(current_model)

                # èª¿ç”¨ API
                resp = model.generate_content(
                    [{"role": "user", "parts": [prompt]}],
                    generation_config={"temperature": 0.2}
                )

                result = (resp.text or "").strip()

                if fallback_index >= 0:
                    print(f"âœ… ä½¿ç”¨å‚™æ´æ¨¡å‹ {current_model} æˆåŠŸ")

                # æå– token ä½¿ç”¨é‡
                token_usage = None
                if hasattr(resp, 'usage_metadata') and resp.usage_metadata:
                    total = getattr(resp.usage_metadata, 'total_token_count', 0)
                    prompt_tokens = getattr(resp.usage_metadata, 'prompt_token_count', 0)
                    completion = getattr(resp.usage_metadata, 'candidates_token_count', 0)
                    token_usage = {
                        "total": total,
                        "prompt": prompt_tokens,
                        "completion": completion
                    }
                    print(f"ğŸ“Š Token ä½¿ç”¨: {total} (è¼¸å…¥: {prompt_tokens}, è¼¸å‡º: {completion})")

                return result, current_model, token_usage

            except Exception as e:
                last_error = e
                error_msg = str(e)

                # æª¢æŸ¥æ˜¯å¦ç‚º 429 é…é¡éŒ¯èª¤
                is_quota_error = (
                    "429" in error_msg or
                    "quota" in error_msg.lower() or
                    "Quota exceeded" in error_msg
                )

                if is_quota_error:
                    quota_exceeded_count += 1
                    print(f"âš ï¸ Google API Key é…é¡å·²ç”¨å®Œ (å˜—è©¦ {attempt + 1}ï¼Œæ¨¡å‹: {current_model})")

                    # å¦‚æœæ‰€æœ‰ keys éƒ½é…é¡è€—ç›¡ï¼Œå˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å‚™æ´æ¨¡å‹
                    if quota_exceeded_count >= len(google_api_keys):
                        fallback_index += 1

                        if fallback_index < len(self.gemini_fallback_models):
                            current_model = self.gemini_fallback_models[fallback_index]
                            print(f"ğŸ’¡ åˆ‡æ›åˆ°å‚™ç”¨æ¨¡å‹ {current_model}")
                            tried_models.append(current_model)
                            quota_exceeded_count = 0
                            current_key_index = 0  # é‡ç½® key ç´¢å¼•
                            continue
                        else:
                            # æ‰€æœ‰å‚™æ´æ¨¡å‹éƒ½ç”¨å®Œäº†
                            print(f"âŒ æ‰€æœ‰æ¨¡å‹çš„é…é¡éƒ½å·²ç”¨å®Œ")
                            raise RuntimeError(
                                f"æ‰€æœ‰ Google API Keys éƒ½èª¿ç”¨å¤±æ•—ã€‚"
                                f"å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}ã€‚"
                                f"æœ€å¾ŒéŒ¯èª¤: {error_msg}"
                            ) from last_error
                else:
                    print(f"âš ï¸ Google API Key èª¿ç”¨å¤±æ•— (å˜—è©¦ {attempt + 1}): {error_msg}")

                # å¦‚æœé‚„æœ‰ key å¯ç”¨ï¼Œç¹¼çºŒå˜—è©¦
                if attempt < max_attempts - 1:
                    print(f"ğŸ”„ åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ API Key...")
                    continue
                else:
                    raise RuntimeError(
                        f"æ‰€æœ‰ Google API Keys éƒ½èª¿ç”¨å¤±æ•—ã€‚"
                        f"å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}ã€‚"
                        f"æœ€å¾ŒéŒ¯èª¤: {error_msg}"
                    ) from last_error

        raise RuntimeError(
            f"ç„¡æ³•èª¿ç”¨ Gemini APIã€‚å·²å˜—è©¦æ¨¡å‹: {', '.join(tried_models)}"
        ) from last_error

    def _get_punctuation_prompt(
        self,
        language: str,
        text: str
    ) -> Tuple[str, str]:
        """æ ¹æ“šèªè¨€ç”Ÿæˆé©ç•¶çš„æ¨™é»æç¤ºèª

        Args:
            language: èªè¨€ä»£ç¢¼ï¼ˆzh/en/ja/ko ç­‰ï¼‰
            text: è¦è™•ç†çš„æ–‡å­—

        Returns:
            (system_message, user_message) å…ƒçµ„
        """
        if language == "zh":
            system_msg = "ä½ æ˜¯åš´è¬¹çš„é€å­—ç¨¿æ½¤é£¾åŠ©æ‰‹ï¼Œåªåšæ¨™é»èˆ‡åˆ†æ®µã€‚"
            user_msg = (
                "è«‹å°‡ä»¥ä¸‹ã€ä¸­æ–‡é€å­—ç¨¿ã€åŠ ä¸Šé©ç•¶æ¨™é»ç¬¦è™Ÿä¸¦åˆç†åˆ†æ®µã€‚"
                "ä¸è¦çœç•¥æˆ–æ·»åŠ å…§å®¹ï¼Œä¸è¦æ„è­¯ï¼Œä¿ç•™å›ºæœ‰åè©èˆ‡æ•¸å­—ã€‚"
                "**é‡è¦ï¼šå¦‚æœæ–‡å­—ä¸­æœ‰èªªè©±è€…æ¨™ç±¤ï¼ˆä¾‹å¦‚ [SPEAKER_00]ã€[Speaker A] ç­‰ï¼‰ï¼Œè«‹å®Œæ•´ä¿ç•™é€™äº›æ¨™ç±¤ï¼Œä¸è¦ä¿®æ”¹æˆ–åˆªé™¤ã€‚**"
                f"è¼¸å‡ºç´”æ–‡å­—å³å¯ï¼š\n\n{text}"
            )
        elif language == "en":
            system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing."
            user_msg = (
                "Please add appropriate punctuation and paragraphing to the following English transcript. "
                "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers. "
                "**Important: If the text contains speaker labels (e.g., [SPEAKER_00], [Speaker A]), preserve them completely without modification or removal.**"
                f"Output plain text only:\n\n{text}"
            )
        elif language == "ja":
            system_msg = "ã‚ãªãŸã¯æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—ç·¨é›†è€…ã§ã™ã€‚å¥èª­ç‚¹ã¨æ®µè½åˆ†ã‘ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚"
            user_msg = (
                "ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«é©åˆ‡ãªå¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
                "å†…å®¹ã®çœç•¥ã‚„è¿½åŠ ã¯ã›ãšã€æ„è¨³ã›ãšã€å›ºæœ‰åè©ã¨æ•°å­—ã¯ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚"
                "**é‡è¦ï¼šè©±è€…ãƒ©ãƒ™ãƒ«ï¼ˆä¾‹ï¼š[SPEAKER_00]ã€[Speaker A]ãªã©ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€å®Œå…¨ã«ä¿æŒã—ã€å¤‰æ›´ã‚„å‰Šé™¤ã‚’ã—ãªã„ã§ãã ã•ã„ã€‚**"
                f"ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n{text}"
            )
        elif language == "ko":
            system_msg = "ë‹¹ì‹ ì€ ì •í™•í•œ ì „ì‚¬ í¸ì§‘ìì…ë‹ˆë‹¤. êµ¬ë‘ì ê³¼ ë‹¨ë½ ë‚˜ëˆ„ê¸°ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤."
            user_msg = (
                "ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— ì ì ˆí•œ êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”. "
                "ë‚´ìš©ì„ ìƒëµí•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜ì—­í•˜ì§€ ë§ê³ , ê³ ìœ ëª…ì‚¬ì™€ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”. "
                "**ì¤‘ìš”: í™”ì ë ˆì´ë¸”(ì˜ˆ: [SPEAKER_00], [Speaker A])ì´ í¬í•¨ëœ ê²½ìš° ì™„ì „íˆ ë³´ì¡´í•˜ê³  ìˆ˜ì •í•˜ê±°ë‚˜ ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”.**"
                f"ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\n\n{text}"
            )
        else:
            # å…¶ä»–èªè¨€ä½¿ç”¨è‹±æ–‡æç¤º
            system_msg = "You are a precise transcript editor. Only add punctuation and paragraphing."
            user_msg = (
                f"Please add appropriate punctuation and paragraphing to the following transcript. "
                "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers. "
                "**Important: If the text contains speaker labels (e.g., [SPEAKER_00], [Speaker A]), preserve them completely without modification or removal.**"
                f"Output plain text only:\n\n{text}"
            )

        return system_msg, user_msg

    def _get_chunked_punctuation_prompt(
        self,
        language: str,
        chunk_text: str,
        chunk_idx: int,
        total_chunks: int
    ) -> Tuple[str, str]:
        """ç‚ºé•·æ–‡æœ¬åˆ†æ®µç”Ÿæˆæç¤ºèª

        Args:
            language: èªè¨€ä»£ç¢¼
            chunk_text: ç•¶å‰åˆ†æ®µæ–‡å­—
            chunk_idx: ç•¶å‰åˆ†æ®µç´¢å¼•ï¼ˆå¾1é–‹å§‹ï¼‰
            total_chunks: ç¸½åˆ†æ®µæ•¸

        Returns:
            (system_message, user_message) å…ƒçµ„
        """
        if language == "zh":
            system_msg = (
                "ä½ æ˜¯åš´è¬¹çš„é€å­—ç¨¿æ½¤é£¾åŠ©æ‰‹ã€‚åªåšã€ä¸­æ–‡æ¨™é»è£œå…¨èˆ‡åˆç†åˆ†æ®µã€ï¼Œ"
                "ä¸è¦çœç•¥æˆ–æ·»åŠ å…§å®¹ï¼Œä¸è¦æ„è­¯ï¼Œéå¿…è¦ä¸è¦ç”¨åˆªç¯€è™Ÿï¼Œä¿ç•™å›ºæœ‰åè©èˆ‡æ•¸å­—ã€‚"
                "**é‡è¦ï¼šå¦‚æœæ–‡å­—ä¸­æœ‰èªªè©±è€…æ¨™ç±¤ï¼ˆä¾‹å¦‚ [SPEAKER_00]ã€[Speaker A] ç­‰ï¼‰ï¼Œè«‹å®Œæ•´ä¿ç•™é€™äº›æ¨™ç±¤ã€‚**"
            )
            if chunk_idx == 1:
                user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯ç¬¬ 1 æ®µï¼‰ï¼š\n\n{chunk_text}"
            elif chunk_idx == total_chunks:
                user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯æœ€å¾Œä¸€æ®µï¼Œæ¥çºŒå‰æ–‡ï¼‰ï¼š\n\n{chunk_text}"
            else:
                user_msg = f"è«‹ç‚ºä»¥ä¸‹ä¸­æ–‡é€å­—ç¨¿åŠ ä¸Šé©ç•¶æ¨™é»ä¸¦åˆ†æ®µï¼ˆé€™æ˜¯ç¬¬ {chunk_idx} æ®µï¼Œæ¥çºŒå‰æ–‡ï¼‰ï¼š\n\n{chunk_text}"
        elif language == "en":
            system_msg = (
                "You are a precise transcript editor. Only add punctuation and paragraphing. "
                "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers. "
                "**Important: Preserve all speaker labels (e.g., [SPEAKER_00], [Speaker A]) completely.**"
            )
            if chunk_idx == 1:
                user_msg = f"Add punctuation and paragraphing to this English transcript (part 1):\n\n{chunk_text}"
            elif chunk_idx == total_chunks:
                user_msg = f"Add punctuation and paragraphing to this English transcript (final part, continuing from previous):\n\n{chunk_text}"
            else:
                user_msg = f"Add punctuation and paragraphing to this English transcript (part {chunk_idx}, continuing from previous):\n\n{chunk_text}"
        elif language == "ja":
            system_msg = (
                "ã‚ãªãŸã¯æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—ç·¨é›†è€…ã§ã™ã€‚å¥èª­ç‚¹ã¨æ®µè½åˆ†ã‘ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚"
                "å†…å®¹ã®çœç•¥ã‚„è¿½åŠ ã¯ã›ãšã€æ„è¨³ã›ãšã€å›ºæœ‰åè©ã¨æ•°å­—ã¯ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚"
                "**é‡è¦ï¼šè©±è€…ãƒ©ãƒ™ãƒ«ï¼ˆä¾‹ï¼š[SPEAKER_00]ã€[Speaker A]ï¼‰ã‚’å®Œå…¨ã«ä¿æŒã—ã¦ãã ã•ã„ã€‚**"
            )
            if chunk_idx == 1:
                user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆç¬¬1éƒ¨åˆ†ï¼‰ï¼š\n\n{chunk_text}"
            elif chunk_idx == total_chunks:
                user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆæœ€å¾Œã®éƒ¨åˆ†ã€å‰ã®ç¶šãï¼‰ï¼š\n\n{chunk_text}"
            else:
                user_msg = f"ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡å­—èµ·ã“ã—ã«å¥èª­ç‚¹ã¨æ®µè½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆç¬¬{chunk_idx}éƒ¨åˆ†ã€å‰ã®ç¶šãï¼‰ï¼š\n\n{chunk_text}"
        elif language == "ko":
            system_msg = (
                "ë‹¹ì‹ ì€ ì •í™•í•œ ì „ì‚¬ í¸ì§‘ìì…ë‹ˆë‹¤. êµ¬ë‘ì ê³¼ ë‹¨ë½ ë‚˜ëˆ„ê¸°ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
                "ë‚´ìš©ì„ ìƒëµí•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜ì—­í•˜ì§€ ë§ê³ , ê³ ìœ ëª…ì‚¬ì™€ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”. "
                "**ì¤‘ìš”: í™”ì ë ˆì´ë¸”(ì˜ˆ: [SPEAKER_00], [Speaker A])ì„ ì™„ì „íˆ ë³´ì¡´í•˜ì„¸ìš”.**"
            )
            if chunk_idx == 1:
                user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” (1ë¶€):\n\n{chunk_text}"
            elif chunk_idx == total_chunks:
                user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” (ë§ˆì§€ë§‰ ë¶€ë¶„, ì´ì „ ê³„ì†):\n\n{chunk_text}"
            else:
                user_msg = f"ë‹¤ìŒ í•œêµ­ì–´ ì „ì‚¬ì— êµ¬ë‘ì ê³¼ ë‹¨ë½ì„ ì¶”ê°€í•´ì£¼ì„¸ìš” ({chunk_idx}ë¶€, ì´ì „ ê³„ì†):\n\n{chunk_text}"
        else:
            # å…¶ä»–èªè¨€ä½¿ç”¨è‹±æ–‡æç¤º
            system_msg = (
                "You are a precise transcript editor. Only add punctuation and paragraphing. "
                "Do not omit or add content, do not paraphrase, preserve proper nouns and numbers."
            )
            if chunk_idx == 1:
                user_msg = f"Add punctuation and paragraphing to this transcript (part 1):\n\n{chunk_text}"
            elif chunk_idx == total_chunks:
                user_msg = f"Add punctuation and paragraphing to this transcript (final part, continuing from previous):\n\n{chunk_text}"
            else:
                user_msg = f"Add punctuation and paragraphing to this transcript (part {chunk_idx}, continuing from previous):\n\n{chunk_text}"

        return system_msg, user_msg

    def _split_text_into_chunks(
        self,
        text: str,
        chunk_size: int
    ) -> list[str]:
        """å°‡æ–‡å­—åˆ†å‰²æˆå¤šå€‹å°æ®µ

        Args:
            text: è¦åˆ†å‰²çš„æ–‡å­—
            chunk_size: æ¯æ®µå¤§å°ï¼ˆå­—å…ƒæ•¸ï¼‰

        Returns:
            åˆ†æ®µåˆ—è¡¨
        """
        chunks = []
        start = 0

        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunks.append(text[start:end])
            start = end

        return chunks

    def _load_google_api_keys(self) -> list[str]:
        """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥æ‰€æœ‰ Google API Keys

        Returns:
            API Keys åˆ—è¡¨
        """
        keys = []
        i = 1

        while True:
            key = os.getenv(f"GOOGLE_API_KEY_{i}")
            if not key:
                break
            keys.append(key)
            i += 1

        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç·¨è™Ÿçš„ keysï¼Œå˜—è©¦ä½¿ç”¨å–®ä¸€çš„ GOOGLE_API_KEY
        if not keys:
            single_key = os.getenv("GOOGLE_API_KEY")
            if single_key:
                keys.append(single_key)

        if not keys:
            raise ValueError("æœªè¨­å®šä»»ä½• GOOGLE_API_KEY")

        return keys
